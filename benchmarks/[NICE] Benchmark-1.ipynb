{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0d5a6e7",
   "metadata": {},
   "source": [
    "# Neural integration for constitutive equations \n",
    "\n",
    "### Benchmark #1: elasto-plastic material\n",
    "\n",
    "Authors: Filippo Masi, Itai Einav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52c2e2f",
   "metadata": {},
   "source": [
    "### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8d1509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 200x160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.optimize import root\n",
    "from torchdiffeq import odeint\n",
    "from nice_module import NICE_reduced, EarlyStopping, slice_data, get_params\n",
    "\n",
    "np.random.seed(6)\n",
    "torch.manual_seed(6)\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('classic')\n",
    "plt.rcParams.update({\"axes.grid\" : False, \"grid.color\": 'black', \"grid.alpha\":0.4})\n",
    "font = {'size'   : 11}\n",
    "matplotlib.rc('font', **font)\n",
    "plt.rcParams['axes.facecolor']='none'\n",
    "plt.rcParams['savefig.facecolor']='none'\n",
    "plt.rcParams['figure.facecolor']='none'\n",
    "plt.rcParams[\"figure.figsize\"] = (2.5,2)\n",
    "plt.tight_layout(pad=2.5, w_pad=3.5, h_pad=3.5)\n",
    "colorb = (0.2,0.4,0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81b4339",
   "metadata": {},
   "source": [
    "#### 1.1 Set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c93ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the frequency in epochs for printing loss during training\n",
    "verbose_frequency = 10\n",
    "\n",
    "# Step size for the training process. If set to 20, it reproduces the original results\n",
    "# otherwise, set to 1 for faster training.\n",
    "step_size = 20\n",
    "\n",
    "# Checking for GPU availability and assigning the device accordingly\n",
    "device = torch.device('cuda:' + str(gpu) if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Boolean flag for adding normally distributed noise to the training dataset\n",
    "corrupted_training_data = False\n",
    "\n",
    "# If corrupted_training_data is True, set the noise amplitude (percentage)\n",
    "delta = 0.  # Noise amplitude (percentage) if corrupted_training_data is True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a50fb4",
   "metadata": {},
   "source": [
    "### 2. Import and prepare data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca061767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the training dataset\n",
    "file = './dataset/benchmark1_data_training'\n",
    "\n",
    "# Loading data from the specified file using pickle\n",
    "with open(file, 'rb') as f_obj:\n",
    "    data = pickle.load(f_obj)\n",
    "\n",
    "# Unpacking data into individual variables\n",
    "[strain_t,strain_tdt,stress_t,dt,n_reset] = data\n",
    "\n",
    "# Setting batch_time equal to n_reset\n",
    "batch_time = n_reset\n",
    "\n",
    "# Setting data_size equal to n_reset\n",
    "data_size = n_reset\n",
    "\n",
    "# Dimensionality of the data\n",
    "dim = 2\n",
    "\n",
    "# Setting prm_dt as the reciprocal of data_size\n",
    "prm_dt = 1 / data_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf87d7",
   "metadata": {},
   "source": [
    "#### 3.1 Reshape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cad77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dstrain = strain_tdt - strain_t\n",
    "dstrain/=prm_dt\n",
    "\n",
    "strain_t = np.reshape(strain_t,(batch_time,-1,dim),order='F')\n",
    "strain_tdt = np.reshape(strain_tdt,(batch_time,-1,dim),order='F')\n",
    "dstrain = np.reshape(dstrain,(batch_time,-1,dim),order='F')\n",
    "\n",
    "stress_t = np.reshape(stress_t,(batch_time,-1,dim),order='F')\n",
    "\n",
    "data_size = strain_t.shape[0]\n",
    "number_IC = strain_t.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb359b07",
   "metadata": {},
   "source": [
    "#### 3.2 Split data in training, validation, and test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a418e711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  24\n",
      "Training samples:  16\n",
      "Validation samples:  4\n",
      "Test samples:  4\n",
      "Total:  24\n"
     ]
    }
   ],
   "source": [
    "# Percentage of data to be used for training\n",
    "train_percentage = 0.65\n",
    "\n",
    "# Calculating the number of samples for training, validation, and testing\n",
    "train = int(round(number_IC * train_percentage))\n",
    "val = int(round(number_IC * 0.5 * (1. - train_percentage)))\n",
    "test = val\n",
    "\n",
    "# Printing information about the data split\n",
    "print(\"Number of samples: \", number_IC)\n",
    "print(\"Training samples: \", train)\n",
    "print(\"Validation samples: \", val)\n",
    "print(\"Test samples: \", test)\n",
    "print(\"Total: \", test + val + train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79ab40b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an array of sequential numbers from 0 to number_IC - 1\n",
    "n = np.arange(0, number_IC, 1)\n",
    "\n",
    "# Creating an array of indices and shuffling it\n",
    "rnd = np.arange(len(n))\n",
    "np.random.shuffle(rnd)\n",
    "n = n[rnd]\n",
    "\n",
    "# Splitting the shuffled indices into training, validation, and test sets\n",
    "ntrain = n[:train]\n",
    "cut = len(ntrain)\n",
    "nval = n[train:]\n",
    "ntrainval = np.hstack((ntrain, nval))\n",
    "ntest = n[train + val:]\n",
    "\n",
    "# Shuffling the indices for training and validation combined set\n",
    "rnd = np.arange(len(ntrainval))\n",
    "np.random.shuffle(rnd)\n",
    "\n",
    "# Splitting the shuffled indices for training and validation sets\n",
    "ntrain = rnd[:train]\n",
    "nval = rnd[val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aae50299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing the strain data into training-validation and test sets\n",
    "strain_t_tv, strain_t_test = slice_data(strain_t, ntrainval, ntest)\n",
    "\n",
    "# Slicing the time derivative of strain data into training-validation and test sets\n",
    "strain_tdt_tv, strain_tdt_test = slice_data(strain_tdt, ntrainval, ntest)\n",
    "\n",
    "# Slicing the incremental strain data into training-validation and test sets\n",
    "dstrain_tv, dstrain_test = slice_data(dstrain, ntrainval, ntest)\n",
    "\n",
    "# Slicing the stress data into training-validation and test sets\n",
    "stress_t_tv, stress_t_test = slice_data(stress_t, ntrainval, ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0797879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if training data needs to be corrupted with noise\n",
    "if corrupted_training_data:\n",
    "\n",
    "    # Generating a stress noise vector\n",
    "    noise = delta/100 * np.random.normal(0, 1, ((data_size+1, number_IC, dim)))\n",
    "    \n",
    "    # Copying the stress data to apply noise\n",
    "    noise_stress_t = stress_t_tv.copy()\n",
    "    \n",
    "    # Adding noise to the stress data\n",
    "    noise_stress_t[:, :, 0] = np.mean(stress_t_tv[:, :, 0]) * noise[:-1, :, 0]\n",
    "    noise_stress_t[:, :, 1] = np.mean(stress_t_tv[:, :, 1]) * noise[:-1, :, 1]\n",
    "    \n",
    "    # Setting the initial time step to zero\n",
    "    noise_stress_t[0] *= 0.0\n",
    "    \n",
    "    # Adding the noise to the original stress data\n",
    "    stress_t_tv += noise_stress_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfbaba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prm_e = get_params(strain_t_tv).to(device)\n",
    "prm_de = get_params(dstrain_tv).to(device)\n",
    "prm_s = get_params(stress_t_tv).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4de2d2a",
   "metadata": {},
   "source": [
    "### 4. Neural integration for constitutive equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78db3bc2",
   "metadata": {},
   "source": [
    "#### 4.1 Constructu neural net and set integration scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fb5fa08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NICE_reduced(\n",
       "  (NeuralNetEvolution): Sequential(\n",
       "    (0): Linear(in_features=4, out_features=24, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (3): GELU(approximate='none')\n",
       "    (4): Linear(in_features=24, out_features=24, bias=True)\n",
       "    (5): GELU(approximate='none')\n",
       "    (6): Linear(in_features=24, out_features=2, bias=True)\n",
       "  )\n",
       "  (NeuralNetEnergy): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "    (1): Softplus(beta=1, threshold=20)\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "    (3): Softplus(beta=1, threshold=20)\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype=torch.float64\n",
    "NNf_params = [2*dim,dim,[6*(2*dim),6*(2*dim),6*(2*dim),],'gelu']\n",
    "NNu_params = [2,1,[2**6,2**6],'softplus']\n",
    "norm_params = [prm_e,prm_de,prm_s,prm_dt]\n",
    "nsvars = 1\n",
    "number_IC = len(ntrainval)\n",
    "NICE_network = NICE_reduced(NNf_params,NNu_params,number_IC,norm_params,dim,dtype).to(device)\n",
    "NICE_network.to(torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a2216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the time step for the simulation\n",
    "prm_dt = 1 / data_size\n",
    "\n",
    "# Creating a time array from 0 to 1 with the calculated time step\n",
    "t = torch.arange(0, 1.0, prm_dt)\n",
    "\n",
    "# Converting stress and incremental strain data to torch tensors and moving them to the specified device\n",
    "stress_tv = torch.from_numpy(np.float64(stress_t_tv)).to(device)\n",
    "dstrain_tv = torch.from_numpy(np.float64(dstrain_tv)).to(device)\n",
    "\n",
    "# Converting test set stress and incremental strain data to torch tensors and moving them to the specified device\n",
    "stress_test = torch.from_numpy(np.float64(stress_t_test)).to(device)\n",
    "dstrain_test = torch.from_numpy(np.float64(dstrain_test)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed30eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the solver type for the NICE network\n",
    "NICE_network.solver = \"midpoint\"\n",
    "\n",
    "# Setting the integration scheme for the NICE network\n",
    "NICE_network.scheme = \"forward\"\n",
    "\n",
    "# Setting the step size for the integration in the NICE network\n",
    "NICE_network.step_size = prm_dt / step_size\n",
    "\n",
    "# Initializing the interpolation function for incremental strain and time in the NICE network\n",
    "NICE_network.init_interp(dstrain_tv, t)\n",
    "\n",
    "# Turning off the inference mode in the NICE network\n",
    "NICE_network.inference = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870363b5",
   "metadata": {},
   "source": [
    "#### 4.2 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab2b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the learning rate for the optimizer\n",
    "learningRate = 1e-2\n",
    "\n",
    "# Initializing the Adam optimizer with the NICE network parameters\n",
    "optimizer = torch.optim.Adam(NICE_network.parameters(), lr=learningRate)\n",
    "\n",
    "# Setting up a learning rate scheduler to adjust the learning rate during training\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.999)\n",
    "\n",
    "# L2 penalty weight for regularization\n",
    "w_reg = 1.e-5\n",
    "\n",
    "# Number of training epochs\n",
    "Nepochs = 1000000\n",
    "\n",
    "# Mean Squared Error (MSE) loss function\n",
    "MSE = torch.nn.MSELoss()\n",
    "\n",
    "# Setting up early stopping with specified criteria\n",
    "checkpoint_path = './checkpoints/checkpoint.pt'\n",
    "early_stopping = EarlyStopping(patience=2000, delta=1.e-9, verbose=False, path=checkpoint_path)\n",
    "\n",
    "# Lists for storing training and validation loss history\n",
    "training_loss_hist = []\n",
    "validation_loss_value_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ded10930",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | training loss: 2.2962e+00 | validation loss: 1.6471e+00\n",
      "Epoch: 20 | training loss: 1.4111e+00 | validation loss: 8.4859e-01\n",
      "Epoch: 30 | training loss: 8.3889e-01 | validation loss: 5.7073e-01\n",
      "Epoch: 40 | training loss: 4.3783e-01 | validation loss: 3.1731e-01\n",
      "Epoch: 50 | training loss: 2.7258e-01 | validation loss: 2.3596e-01\n",
      "Epoch: 60 | training loss: 1.9033e-01 | validation loss: 1.6955e-01\n",
      "Epoch: 70 | training loss: 1.4407e-01 | validation loss: 1.4013e-01\n",
      "Epoch: 80 | training loss: 1.1668e-01 | validation loss: 1.1838e-01\n",
      "Epoch: 90 | training loss: 1.0132e-01 | validation loss: 1.1111e-01\n",
      "Epoch: 100 | training loss: 9.1955e-02 | validation loss: 1.0635e-01\n",
      "Epoch: 110 | training loss: 8.3262e-02 | validation loss: 9.9789e-02\n",
      "Epoch: 120 | training loss: 7.4824e-02 | validation loss: 8.9349e-02\n",
      "Epoch: 130 | training loss: 5.9728e-02 | validation loss: 6.2536e-02\n",
      "Epoch: 140 | training loss: 5.3346e-02 | validation loss: 5.3513e-02\n",
      "Epoch: 150 | training loss: 4.7530e-02 | validation loss: 4.8868e-02\n",
      "Epoch: 160 | training loss: 4.1357e-02 | validation loss: 4.3356e-02\n",
      "Epoch: 170 | training loss: 3.3872e-02 | validation loss: 3.7153e-02\n",
      "Epoch: 180 | training loss: 2.3794e-02 | validation loss: 2.7507e-02\n",
      "Epoch: 190 | training loss: 1.5308e-02 | validation loss: 1.8588e-02\n",
      "Epoch: 200 | training loss: 1.1383e-02 | validation loss: 1.4012e-02\n",
      "Epoch: 210 | training loss: 9.6645e-03 | validation loss: 1.2039e-02\n",
      "Epoch: 220 | training loss: 8.3773e-03 | validation loss: 1.0466e-02\n",
      "Epoch: 230 | training loss: 7.3779e-03 | validation loss: 9.1297e-03\n",
      "Epoch: 240 | training loss: 6.6060e-03 | validation loss: 8.0192e-03\n",
      "Epoch: 250 | training loss: 6.0415e-03 | validation loss: 7.1899e-03\n",
      "Epoch: 260 | training loss: 5.6422e-03 | validation loss: 6.6088e-03\n",
      "Epoch: 270 | training loss: 5.3394e-03 | validation loss: 6.1639e-03\n",
      "Epoch: 280 | training loss: 5.1021e-03 | validation loss: 5.8042e-03\n",
      "Epoch: 290 | training loss: 4.9094e-03 | validation loss: 5.5036e-03\n",
      "Epoch: 300 | training loss: 4.7484e-03 | validation loss: 5.2498e-03\n",
      "Epoch: 310 | training loss: 4.6106e-03 | validation loss: 5.0326e-03\n",
      "Epoch: 320 | training loss: 4.4895e-03 | validation loss: 4.8408e-03\n",
      "Epoch: 330 | training loss: 4.3810e-03 | validation loss: 4.6681e-03\n",
      "Epoch: 340 | training loss: 4.2822e-03 | validation loss: 4.5097e-03\n",
      "Epoch: 350 | training loss: 4.1907e-03 | validation loss: 4.3619e-03\n",
      "Epoch: 360 | training loss: 4.1053e-03 | validation loss: 4.2199e-03\n",
      "Epoch: 370 | training loss: 4.0828e-03 | validation loss: 4.0086e-03\n",
      "Epoch: 380 | training loss: 3.9707e-03 | validation loss: 4.0339e-03\n",
      "Epoch: 390 | training loss: 3.9287e-03 | validation loss: 3.9995e-03\n",
      "Epoch: 400 | training loss: 3.9654e-03 | validation loss: 4.0700e-03\n",
      "Epoch: 410 | training loss: 3.8482e-03 | validation loss: 3.8799e-03\n",
      "Epoch: 420 | training loss: 3.7384e-03 | validation loss: 3.6807e-03\n",
      "Epoch: 430 | training loss: 3.6720e-03 | validation loss: 3.5476e-03\n",
      "Epoch: 440 | training loss: 3.6203e-03 | validation loss: 3.4536e-03\n",
      "Epoch: 450 | training loss: 3.5721e-03 | validation loss: 3.3721e-03\n",
      "Epoch: 460 | training loss: 3.5257e-03 | validation loss: 3.2957e-03\n",
      "Epoch: 470 | training loss: 3.4811e-03 | validation loss: 3.2217e-03\n",
      "Epoch: 480 | training loss: 3.4378e-03 | validation loss: 3.1484e-03\n",
      "Epoch: 490 | training loss: 3.3961e-03 | validation loss: 3.0783e-03\n",
      "Epoch: 500 | training loss: 3.3558e-03 | validation loss: 3.0130e-03\n",
      "Epoch: 510 | training loss: 3.3167e-03 | validation loss: 2.9517e-03\n",
      "Epoch: 520 | training loss: 3.2787e-03 | validation loss: 2.8913e-03\n",
      "Epoch: 530 | training loss: 3.2419e-03 | validation loss: 2.8319e-03\n",
      "Epoch: 540 | training loss: 3.2062e-03 | validation loss: 2.7752e-03\n",
      "Epoch: 550 | training loss: 3.1715e-03 | validation loss: 2.7200e-03\n",
      "Epoch: 560 | training loss: 3.1378e-03 | validation loss: 2.6666e-03\n",
      "Epoch: 570 | training loss: 3.1050e-03 | validation loss: 2.6148e-03\n",
      "Epoch: 580 | training loss: 3.0732e-03 | validation loss: 2.5646e-03\n",
      "Epoch: 590 | training loss: 3.0423e-03 | validation loss: 2.5159e-03\n",
      "Epoch: 600 | training loss: 3.0123e-03 | validation loss: 2.4688e-03\n",
      "Epoch: 610 | training loss: 2.9831e-03 | validation loss: 2.4231e-03\n",
      "Epoch: 620 | training loss: 2.9547e-03 | validation loss: 2.3787e-03\n",
      "Epoch: 630 | training loss: 2.9271e-03 | validation loss: 2.3357e-03\n",
      "Epoch: 640 | training loss: 2.9003e-03 | validation loss: 2.2941e-03\n",
      "Epoch: 650 | training loss: 2.8742e-03 | validation loss: 2.2542e-03\n",
      "Epoch: 660 | training loss: 2.8493e-03 | validation loss: 2.2212e-03\n",
      "Epoch: 670 | training loss: 2.8730e-03 | validation loss: 2.3019e-03\n",
      "Epoch: 680 | training loss: 4.8353e-03 | validation loss: 4.5298e-03\n",
      "Epoch: 690 | training loss: 2.8570e-03 | validation loss: 2.2717e-03\n",
      "Epoch: 700 | training loss: 2.7596e-03 | validation loss: 2.0526e-03\n",
      "Epoch: 710 | training loss: 2.7463e-03 | validation loss: 2.0126e-03\n",
      "Epoch: 720 | training loss: 2.7248e-03 | validation loss: 1.9843e-03\n",
      "Epoch: 730 | training loss: 2.7009e-03 | validation loss: 1.9572e-03\n",
      "Epoch: 740 | training loss: 2.6780e-03 | validation loss: 1.9337e-03\n",
      "Epoch: 750 | training loss: 2.6567e-03 | validation loss: 1.9097e-03\n",
      "Epoch: 760 | training loss: 2.6373e-03 | validation loss: 1.8874e-03\n",
      "Epoch: 770 | training loss: 2.6190e-03 | validation loss: 1.8630e-03\n",
      "Epoch: 780 | training loss: 2.6012e-03 | validation loss: 1.8375e-03\n",
      "Epoch: 790 | training loss: 2.5839e-03 | validation loss: 1.8111e-03\n",
      "Epoch: 800 | training loss: 2.5669e-03 | validation loss: 1.7848e-03\n",
      "Epoch: 810 | training loss: 2.5504e-03 | validation loss: 1.7593e-03\n",
      "Epoch: 820 | training loss: 2.5342e-03 | validation loss: 1.7348e-03\n",
      "Epoch: 830 | training loss: 2.5184e-03 | validation loss: 1.7111e-03\n",
      "Epoch: 840 | training loss: 2.5029e-03 | validation loss: 1.6881e-03\n",
      "Epoch: 850 | training loss: 2.4878e-03 | validation loss: 1.6656e-03\n",
      "Epoch: 860 | training loss: 2.4730e-03 | validation loss: 1.6435e-03\n",
      "Epoch: 870 | training loss: 2.4586e-03 | validation loss: 1.6220e-03\n",
      "Epoch: 880 | training loss: 2.4444e-03 | validation loss: 1.6010e-03\n",
      "Epoch: 890 | training loss: 2.4305e-03 | validation loss: 1.5806e-03\n",
      "Epoch: 900 | training loss: 2.4170e-03 | validation loss: 1.5606e-03\n",
      "Epoch: 910 | training loss: 2.4037e-03 | validation loss: 1.5411e-03\n",
      "Epoch: 920 | training loss: 2.3907e-03 | validation loss: 1.5221e-03\n",
      "Epoch: 930 | training loss: 2.3779e-03 | validation loss: 1.5035e-03\n",
      "Epoch: 940 | training loss: 2.3655e-03 | validation loss: 1.4853e-03\n",
      "Epoch: 950 | training loss: 2.3532e-03 | validation loss: 1.4676e-03\n",
      "Epoch: 960 | training loss: 2.3412e-03 | validation loss: 1.4503e-03\n",
      "Epoch: 970 | training loss: 2.3294e-03 | validation loss: 1.4333e-03\n",
      "Epoch: 980 | training loss: 2.3178e-03 | validation loss: 1.4168e-03\n",
      "Epoch: 990 | training loss: 2.3065e-03 | validation loss: 1.4006e-03\n",
      "Epoch: 1000 | training loss: 2.2954e-03 | validation loss: 1.3849e-03\n",
      "Epoch: 1010 | training loss: 2.2844e-03 | validation loss: 1.3694e-03\n",
      "Epoch: 1020 | training loss: 2.2737e-03 | validation loss: 1.3544e-03\n",
      "Epoch: 1030 | training loss: 2.2631e-03 | validation loss: 1.3396e-03\n",
      "Epoch: 1040 | training loss: 2.2527e-03 | validation loss: 1.3252e-03\n",
      "Epoch: 1050 | training loss: 2.2425e-03 | validation loss: 1.3112e-03\n",
      "Epoch: 1060 | training loss: 2.2325e-03 | validation loss: 1.2974e-03\n",
      "Epoch: 1070 | training loss: 2.2226e-03 | validation loss: 1.2839e-03\n",
      "Epoch: 1080 | training loss: 2.2129e-03 | validation loss: 1.2708e-03\n",
      "Epoch: 1090 | training loss: 2.2034e-03 | validation loss: 1.2579e-03\n",
      "Epoch: 1100 | training loss: 2.1940e-03 | validation loss: 1.2452e-03\n",
      "Epoch: 1110 | training loss: 2.1847e-03 | validation loss: 1.2329e-03\n",
      "Epoch: 1120 | training loss: 2.1756e-03 | validation loss: 1.2207e-03\n",
      "Epoch: 1130 | training loss: 2.1667e-03 | validation loss: 1.2089e-03\n",
      "Epoch: 1140 | training loss: 2.1578e-03 | validation loss: 1.1973e-03\n",
      "Epoch: 1150 | training loss: 2.1491e-03 | validation loss: 1.1859e-03\n",
      "Epoch: 1160 | training loss: 2.1405e-03 | validation loss: 1.1747e-03\n",
      "Epoch: 1170 | training loss: 2.1321e-03 | validation loss: 1.1638e-03\n",
      "Epoch: 1180 | training loss: 2.1238e-03 | validation loss: 1.1530e-03\n",
      "Epoch: 1190 | training loss: 2.1156e-03 | validation loss: 1.1425e-03\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1200 | training loss: 2.1075e-03 | validation loss: 1.1322e-03\n",
      "Epoch: 1210 | training loss: 2.0995e-03 | validation loss: 1.1221e-03\n",
      "Epoch: 1220 | training loss: 2.0916e-03 | validation loss: 1.1122e-03\n",
      "Epoch: 1230 | training loss: 2.0838e-03 | validation loss: 1.1024e-03\n",
      "Epoch: 1240 | training loss: 2.0762e-03 | validation loss: 1.0929e-03\n",
      "Epoch: 1250 | training loss: 2.0686e-03 | validation loss: 1.0835e-03\n",
      "Epoch: 1260 | training loss: 2.0612e-03 | validation loss: 1.0742e-03\n",
      "Epoch: 1270 | training loss: 2.0538e-03 | validation loss: 1.0652e-03\n",
      "Epoch: 1280 | training loss: 2.0466e-03 | validation loss: 1.0563e-03\n",
      "Epoch: 1290 | training loss: 2.0394e-03 | validation loss: 1.0476e-03\n",
      "Epoch: 1300 | training loss: 2.0324e-03 | validation loss: 1.0390e-03\n",
      "Epoch: 1310 | training loss: 2.0254e-03 | validation loss: 1.0306e-03\n",
      "Epoch: 1320 | training loss: 2.0185e-03 | validation loss: 1.0223e-03\n",
      "Epoch: 1330 | training loss: 2.0118e-03 | validation loss: 1.0142e-03\n",
      "Epoch: 1340 | training loss: 2.0051e-03 | validation loss: 1.0063e-03\n",
      "Epoch: 1350 | training loss: 1.9985e-03 | validation loss: 9.9846e-04\n",
      "Epoch: 1360 | training loss: 1.9919e-03 | validation loss: 9.9078e-04\n",
      "Epoch: 1370 | training loss: 1.9855e-03 | validation loss: 9.8324e-04\n",
      "Epoch: 1380 | training loss: 1.9792e-03 | validation loss: 9.7583e-04\n",
      "Epoch: 1390 | training loss: 1.9729e-03 | validation loss: 9.6855e-04\n",
      "Epoch: 1400 | training loss: 1.9667e-03 | validation loss: 9.6140e-04\n",
      "Epoch: 1410 | training loss: 1.9606e-03 | validation loss: 9.5437e-04\n",
      "Epoch: 1420 | training loss: 1.9546e-03 | validation loss: 9.4745e-04\n",
      "Epoch: 1430 | training loss: 1.9486e-03 | validation loss: 9.4066e-04\n",
      "Epoch: 1440 | training loss: 1.9428e-03 | validation loss: 9.3398e-04\n",
      "Epoch: 1450 | training loss: 1.9370e-03 | validation loss: 9.2740e-04\n",
      "Epoch: 1460 | training loss: 1.9312e-03 | validation loss: 9.2094e-04\n",
      "Epoch: 1470 | training loss: 1.9256e-03 | validation loss: 9.1459e-04\n",
      "Epoch: 1480 | training loss: 1.9200e-03 | validation loss: 9.0834e-04\n",
      "Epoch: 1490 | training loss: 1.9145e-03 | validation loss: 9.0219e-04\n",
      "Epoch: 1500 | training loss: 1.9091e-03 | validation loss: 8.9615e-04\n",
      "Epoch: 1510 | training loss: 1.9037e-03 | validation loss: 8.9021e-04\n",
      "Epoch: 1520 | training loss: 1.8984e-03 | validation loss: 8.8436e-04\n",
      "Epoch: 1530 | training loss: 1.8931e-03 | validation loss: 8.7862e-04\n",
      "Epoch: 1540 | training loss: 1.8880e-03 | validation loss: 8.7297e-04\n",
      "Epoch: 1550 | training loss: 1.8829e-03 | validation loss: 8.6741e-04\n",
      "Epoch: 1560 | training loss: 1.8778e-03 | validation loss: 8.6194e-04\n",
      "Epoch: 1570 | training loss: 1.8729e-03 | validation loss: 8.5656e-04\n",
      "Epoch: 1580 | training loss: 1.8680e-03 | validation loss: 8.5127e-04\n",
      "Epoch: 1590 | training loss: 1.8631e-03 | validation loss: 8.4606e-04\n",
      "Epoch: 1600 | training loss: 1.8583e-03 | validation loss: 8.4095e-04\n",
      "Epoch: 1610 | training loss: 1.8536e-03 | validation loss: 8.3592e-04\n",
      "Epoch: 1620 | training loss: 1.8489e-03 | validation loss: 8.3097e-04\n",
      "Epoch: 1630 | training loss: 1.8443e-03 | validation loss: 8.2611e-04\n",
      "Epoch: 1640 | training loss: 1.8398e-03 | validation loss: 8.2133e-04\n",
      "Epoch: 1650 | training loss: 1.8353e-03 | validation loss: 8.1663e-04\n",
      "Epoch: 1660 | training loss: 1.8309e-03 | validation loss: 8.1201e-04\n",
      "Epoch: 1670 | training loss: 1.8265e-03 | validation loss: 8.0747e-04\n",
      "Epoch: 1680 | training loss: 1.8222e-03 | validation loss: 8.0300e-04\n",
      "Epoch: 1690 | training loss: 1.8180e-03 | validation loss: 7.9862e-04\n",
      "Epoch: 1700 | training loss: 1.8138e-03 | validation loss: 7.9431e-04\n",
      "Epoch: 1710 | training loss: 1.8097e-03 | validation loss: 7.9008e-04\n",
      "Epoch: 1720 | training loss: 1.8056e-03 | validation loss: 7.8591e-04\n",
      "Epoch: 1730 | training loss: 1.8016e-03 | validation loss: 7.8183e-04\n",
      "Epoch: 1740 | training loss: 1.7976e-03 | validation loss: 7.7781e-04\n",
      "Epoch: 1750 | training loss: 1.7937e-03 | validation loss: 7.7387e-04\n",
      "Epoch: 1760 | training loss: 1.7898e-03 | validation loss: 7.7000e-04\n",
      "Epoch: 1770 | training loss: 1.7860e-03 | validation loss: 7.6620e-04\n",
      "Epoch: 1780 | training loss: 1.7822e-03 | validation loss: 7.6247e-04\n",
      "Epoch: 1790 | training loss: 1.7785e-03 | validation loss: 7.5880e-04\n",
      "Epoch: 1800 | training loss: 1.7749e-03 | validation loss: 7.5521e-04\n",
      "Epoch: 1810 | training loss: 1.7713e-03 | validation loss: 7.5167e-04\n",
      "Epoch: 1820 | training loss: 1.7677e-03 | validation loss: 7.4821e-04\n",
      "Epoch: 1830 | training loss: 1.7642e-03 | validation loss: 7.4480e-04\n",
      "Epoch: 1840 | training loss: 1.7607e-03 | validation loss: 7.4146e-04\n",
      "Epoch: 1850 | training loss: 1.7573e-03 | validation loss: 7.3818e-04\n",
      "Epoch: 1860 | training loss: 1.7539e-03 | validation loss: 7.3495e-04\n",
      "Epoch: 1870 | training loss: 1.7506e-03 | validation loss: 7.3179e-04\n",
      "Epoch: 1880 | training loss: 1.7473e-03 | validation loss: 7.2868e-04\n",
      "Epoch: 1890 | training loss: 1.7441e-03 | validation loss: 7.2561e-04\n",
      "Epoch: 1900 | training loss: 1.7409e-03 | validation loss: 7.2259e-04\n",
      "Epoch: 1910 | training loss: 1.7377e-03 | validation loss: 7.1961e-04\n",
      "Epoch: 1920 | training loss: 1.7346e-03 | validation loss: 7.1669e-04\n",
      "Epoch: 1930 | training loss: 1.7315e-03 | validation loss: 7.1382e-04\n",
      "Epoch: 1940 | training loss: 1.7285e-03 | validation loss: 7.1100e-04\n",
      "Epoch: 1950 | training loss: 1.7255e-03 | validation loss: 7.0823e-04\n",
      "Epoch: 1960 | training loss: 1.7225e-03 | validation loss: 7.0551e-04\n",
      "Epoch: 1970 | training loss: 1.7196e-03 | validation loss: 7.0284e-04\n",
      "Epoch: 1980 | training loss: 1.7167e-03 | validation loss: 7.0022e-04\n",
      "Epoch: 1990 | training loss: 1.7138e-03 | validation loss: 6.9764e-04\n",
      "Epoch: 2000 | training loss: 1.7110e-03 | validation loss: 6.9511e-04\n",
      "Epoch: 2010 | training loss: 1.7082e-03 | validation loss: 6.9262e-04\n",
      "Epoch: 2020 | training loss: 1.7055e-03 | validation loss: 6.9017e-04\n",
      "Epoch: 2030 | training loss: 1.7028e-03 | validation loss: 6.8777e-04\n",
      "Epoch: 2040 | training loss: 1.7001e-03 | validation loss: 6.8541e-04\n",
      "Epoch: 2050 | training loss: 1.6974e-03 | validation loss: 6.8310e-04\n",
      "Epoch: 2060 | training loss: 1.6948e-03 | validation loss: 6.8082e-04\n",
      "Epoch: 2070 | training loss: 1.6922e-03 | validation loss: 6.7858e-04\n",
      "Epoch: 2080 | training loss: 1.6897e-03 | validation loss: 6.7638e-04\n",
      "Epoch: 2090 | training loss: 1.6872e-03 | validation loss: 6.7422e-04\n",
      "Epoch: 2100 | training loss: 1.6847e-03 | validation loss: 6.7209e-04\n",
      "Epoch: 2110 | training loss: 1.6822e-03 | validation loss: 6.7001e-04\n",
      "Epoch: 2120 | training loss: 1.6798e-03 | validation loss: 6.6795e-04\n",
      "Epoch: 2130 | training loss: 1.6774e-03 | validation loss: 6.6594e-04\n",
      "Epoch: 2140 | training loss: 1.6751e-03 | validation loss: 6.6395e-04\n",
      "Epoch: 2150 | training loss: 1.6727e-03 | validation loss: 6.6200e-04\n",
      "Epoch: 2160 | training loss: 1.6702e-03 | validation loss: 6.5971e-04\n",
      "Epoch: 2170 | training loss: 1.6677e-03 | validation loss: 6.5744e-04\n",
      "Epoch: 2180 | training loss: 1.6653e-03 | validation loss: 6.5520e-04\n",
      "Epoch: 2190 | training loss: 1.6628e-03 | validation loss: 6.5301e-04\n",
      "Epoch: 2200 | training loss: 1.6604e-03 | validation loss: 6.5086e-04\n",
      "Epoch: 2210 | training loss: 1.6580e-03 | validation loss: 6.4875e-04\n",
      "Epoch: 2220 | training loss: 1.6557e-03 | validation loss: 6.4667e-04\n",
      "Epoch: 2230 | training loss: 1.6534e-03 | validation loss: 6.4463e-04\n",
      "Epoch: 2240 | training loss: 1.6511e-03 | validation loss: 6.4262e-04\n",
      "Epoch: 2250 | training loss: 1.6488e-03 | validation loss: 6.4064e-04\n",
      "Epoch: 2260 | training loss: 1.6466e-03 | validation loss: 6.3870e-04\n",
      "Epoch: 2270 | training loss: 1.6444e-03 | validation loss: 6.3679e-04\n",
      "Epoch: 2280 | training loss: 1.6422e-03 | validation loss: 6.3491e-04\n",
      "Epoch: 2290 | training loss: 1.6401e-03 | validation loss: 6.3306e-04\n",
      "Epoch: 2300 | training loss: 1.6379e-03 | validation loss: 6.3124e-04\n",
      "Epoch: 2310 | training loss: 1.6358e-03 | validation loss: 6.2945e-04\n",
      "Epoch: 2320 | training loss: 1.6338e-03 | validation loss: 6.2768e-04\n",
      "Epoch: 2330 | training loss: 1.6317e-03 | validation loss: 6.2595e-04\n",
      "Epoch: 2340 | training loss: 1.6297e-03 | validation loss: 6.2424e-04\n",
      "Epoch: 2350 | training loss: 1.6277e-03 | validation loss: 6.2256e-04\n",
      "Epoch: 2360 | training loss: 1.6257e-03 | validation loss: 6.2090e-04\n",
      "Epoch: 2370 | training loss: 1.6237e-03 | validation loss: 6.1928e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2380 | training loss: 1.6218e-03 | validation loss: 6.1767e-04\n",
      "Epoch: 2390 | training loss: 1.6199e-03 | validation loss: 6.1609e-04\n",
      "Epoch: 2400 | training loss: 1.6180e-03 | validation loss: 6.1454e-04\n",
      "Epoch: 2410 | training loss: 1.6161e-03 | validation loss: 6.1300e-04\n",
      "Epoch: 2420 | training loss: 1.6143e-03 | validation loss: 6.1149e-04\n",
      "Epoch: 2430 | training loss: 1.6124e-03 | validation loss: 6.1001e-04\n",
      "Epoch: 2440 | training loss: 1.6106e-03 | validation loss: 6.0854e-04\n",
      "Epoch: 2450 | training loss: 1.6088e-03 | validation loss: 6.0710e-04\n",
      "Epoch: 2460 | training loss: 1.6071e-03 | validation loss: 6.0568e-04\n",
      "Epoch: 2470 | training loss: 1.6053e-03 | validation loss: 6.0428e-04\n",
      "Epoch: 2480 | training loss: 1.6036e-03 | validation loss: 6.0289e-04\n",
      "Epoch: 2490 | training loss: 1.6019e-03 | validation loss: 6.0153e-04\n",
      "Epoch: 2500 | training loss: 1.6002e-03 | validation loss: 6.0019e-04\n",
      "Epoch: 2510 | training loss: 1.5985e-03 | validation loss: 5.9887e-04\n",
      "Epoch: 2520 | training loss: 1.5969e-03 | validation loss: 5.9756e-04\n",
      "Epoch: 2530 | training loss: 1.5952e-03 | validation loss: 5.9628e-04\n",
      "Epoch: 2540 | training loss: 1.5936e-03 | validation loss: 5.9501e-04\n",
      "Epoch: 2550 | training loss: 1.5920e-03 | validation loss: 5.9376e-04\n",
      "Epoch: 2560 | training loss: 1.5904e-03 | validation loss: 5.9252e-04\n",
      "Epoch: 2570 | training loss: 1.5888e-03 | validation loss: 5.9130e-04\n",
      "Epoch: 2580 | training loss: 1.5873e-03 | validation loss: 5.9010e-04\n",
      "Epoch: 2590 | training loss: 1.5857e-03 | validation loss: 5.8892e-04\n",
      "Epoch: 2600 | training loss: 1.5842e-03 | validation loss: 5.8775e-04\n",
      "Epoch: 2610 | training loss: 1.5827e-03 | validation loss: 5.8660e-04\n",
      "Epoch: 2620 | training loss: 1.5812e-03 | validation loss: 5.8546e-04\n",
      "Epoch: 2630 | training loss: 1.5798e-03 | validation loss: 5.8433e-04\n",
      "Epoch: 2640 | training loss: 1.5783e-03 | validation loss: 5.8322e-04\n",
      "Epoch: 2650 | training loss: 1.5768e-03 | validation loss: 5.8213e-04\n",
      "Epoch: 2660 | training loss: 1.5754e-03 | validation loss: 5.8105e-04\n",
      "Epoch: 2670 | training loss: 1.5740e-03 | validation loss: 5.7998e-04\n",
      "Epoch: 2680 | training loss: 1.5726e-03 | validation loss: 5.7893e-04\n",
      "Epoch: 2690 | training loss: 1.5712e-03 | validation loss: 5.7788e-04\n",
      "Epoch: 2700 | training loss: 1.5698e-03 | validation loss: 5.7686e-04\n",
      "Epoch: 2710 | training loss: 1.5685e-03 | validation loss: 5.7584e-04\n",
      "Epoch: 2720 | training loss: 1.5671e-03 | validation loss: 5.7484e-04\n",
      "Epoch: 2730 | training loss: 1.5658e-03 | validation loss: 5.7385e-04\n",
      "Epoch: 2740 | training loss: 1.5645e-03 | validation loss: 5.7287e-04\n",
      "Epoch: 2750 | training loss: 1.5631e-03 | validation loss: 5.7190e-04\n",
      "Epoch: 2760 | training loss: 1.5619e-03 | validation loss: 5.7095e-04\n",
      "Epoch: 2770 | training loss: 1.5606e-03 | validation loss: 5.7000e-04\n",
      "Epoch: 2780 | training loss: 1.5593e-03 | validation loss: 5.6907e-04\n",
      "Epoch: 2790 | training loss: 1.5580e-03 | validation loss: 5.6815e-04\n",
      "Epoch: 2800 | training loss: 1.5568e-03 | validation loss: 5.6724e-04\n",
      "Epoch: 2810 | training loss: 1.5555e-03 | validation loss: 5.6633e-04\n",
      "Epoch: 2820 | training loss: 1.5543e-03 | validation loss: 5.6544e-04\n",
      "Epoch: 2830 | training loss: 1.5531e-03 | validation loss: 5.6456e-04\n",
      "Epoch: 2840 | training loss: 1.5519e-03 | validation loss: 5.6369e-04\n",
      "Epoch: 2850 | training loss: 1.5507e-03 | validation loss: 5.6283e-04\n",
      "Epoch: 2860 | training loss: 1.5495e-03 | validation loss: 5.6198e-04\n",
      "Epoch: 2870 | training loss: 1.5484e-03 | validation loss: 5.6114e-04\n",
      "Epoch: 2880 | training loss: 1.5472e-03 | validation loss: 5.6031e-04\n",
      "Epoch: 2890 | training loss: 1.5460e-03 | validation loss: 5.5948e-04\n",
      "Epoch: 2900 | training loss: 1.5449e-03 | validation loss: 5.5867e-04\n",
      "Epoch: 2910 | training loss: 1.5438e-03 | validation loss: 5.5786e-04\n",
      "Epoch: 2920 | training loss: 1.5427e-03 | validation loss: 5.5707e-04\n",
      "Epoch: 2930 | training loss: 1.5416e-03 | validation loss: 5.5628e-04\n",
      "Epoch: 2940 | training loss: 1.5405e-03 | validation loss: 5.5550e-04\n",
      "Epoch: 2950 | training loss: 1.5394e-03 | validation loss: 5.5473e-04\n",
      "Epoch: 2960 | training loss: 1.5383e-03 | validation loss: 5.5396e-04\n",
      "Epoch: 2970 | training loss: 1.5372e-03 | validation loss: 5.5321e-04\n",
      "Epoch: 2980 | training loss: 1.5362e-03 | validation loss: 5.5246e-04\n",
      "Epoch: 2990 | training loss: 1.5351e-03 | validation loss: 5.5172e-04\n",
      "Epoch: 3000 | training loss: 1.5341e-03 | validation loss: 5.5099e-04\n",
      "Epoch: 3010 | training loss: 1.5330e-03 | validation loss: 5.5026e-04\n",
      "Epoch: 3020 | training loss: 1.5320e-03 | validation loss: 5.4954e-04\n",
      "Epoch: 3030 | training loss: 1.5310e-03 | validation loss: 5.4883e-04\n",
      "Epoch: 3040 | training loss: 1.5300e-03 | validation loss: 5.4813e-04\n",
      "Epoch: 3050 | training loss: 1.5290e-03 | validation loss: 5.4743e-04\n",
      "Epoch: 3060 | training loss: 1.5280e-03 | validation loss: 5.4674e-04\n",
      "Epoch: 3070 | training loss: 1.5270e-03 | validation loss: 5.4606e-04\n",
      "Epoch: 3080 | training loss: 1.5260e-03 | validation loss: 5.4538e-04\n",
      "Epoch: 3090 | training loss: 1.5251e-03 | validation loss: 5.4471e-04\n",
      "Epoch: 3100 | training loss: 1.5241e-03 | validation loss: 5.4405e-04\n",
      "Epoch: 3110 | training loss: 1.5232e-03 | validation loss: 5.4339e-04\n",
      "Epoch: 3120 | training loss: 1.5222e-03 | validation loss: 5.4274e-04\n",
      "Epoch: 3130 | training loss: 1.5213e-03 | validation loss: 5.4209e-04\n",
      "Epoch: 3140 | training loss: 1.5203e-03 | validation loss: 5.4145e-04\n",
      "Epoch: 3150 | training loss: 1.5194e-03 | validation loss: 5.4082e-04\n",
      "Epoch: 3160 | training loss: 1.5185e-03 | validation loss: 5.4019e-04\n",
      "Epoch: 3170 | training loss: 1.5176e-03 | validation loss: 5.3957e-04\n",
      "Epoch: 3180 | training loss: 1.5167e-03 | validation loss: 5.3895e-04\n",
      "Epoch: 3190 | training loss: 1.5158e-03 | validation loss: 5.3834e-04\n",
      "Epoch: 3200 | training loss: 1.5149e-03 | validation loss: 5.3774e-04\n",
      "Epoch: 3210 | training loss: 1.5141e-03 | validation loss: 5.3714e-04\n",
      "Epoch: 3220 | training loss: 1.5132e-03 | validation loss: 5.3655e-04\n",
      "Epoch: 3230 | training loss: 1.5123e-03 | validation loss: 5.3596e-04\n",
      "Epoch: 3240 | training loss: 1.5115e-03 | validation loss: 5.3537e-04\n",
      "Epoch: 3250 | training loss: 1.5106e-03 | validation loss: 5.3480e-04\n",
      "Epoch: 3260 | training loss: 1.5098e-03 | validation loss: 5.3422e-04\n",
      "Epoch: 3270 | training loss: 1.5090e-03 | validation loss: 5.3365e-04\n",
      "Epoch: 3280 | training loss: 1.5081e-03 | validation loss: 5.3309e-04\n",
      "Epoch: 3290 | training loss: 1.5073e-03 | validation loss: 5.3253e-04\n",
      "Epoch: 3300 | training loss: 1.5065e-03 | validation loss: 5.3198e-04\n",
      "Epoch: 3310 | training loss: 1.5057e-03 | validation loss: 5.3143e-04\n",
      "Epoch: 3320 | training loss: 1.5049e-03 | validation loss: 5.3089e-04\n",
      "Epoch: 3330 | training loss: 1.5041e-03 | validation loss: 5.3035e-04\n",
      "Epoch: 3340 | training loss: 1.5033e-03 | validation loss: 5.2982e-04\n",
      "Epoch: 3350 | training loss: 1.5025e-03 | validation loss: 5.2929e-04\n",
      "Epoch: 3360 | training loss: 1.5017e-03 | validation loss: 5.2876e-04\n",
      "Epoch: 3370 | training loss: 1.5009e-03 | validation loss: 5.2824e-04\n",
      "Epoch: 3380 | training loss: 1.5002e-03 | validation loss: 5.2772e-04\n",
      "Epoch: 3390 | training loss: 1.4994e-03 | validation loss: 5.2721e-04\n",
      "Epoch: 3400 | training loss: 1.4986e-03 | validation loss: 5.2670e-04\n",
      "Epoch: 3410 | training loss: 1.4979e-03 | validation loss: 5.2620e-04\n",
      "Epoch: 3420 | training loss: 1.4972e-03 | validation loss: 5.2570e-04\n",
      "Epoch: 3430 | training loss: 1.4964e-03 | validation loss: 5.2520e-04\n",
      "Epoch: 3440 | training loss: 1.4957e-03 | validation loss: 5.2471e-04\n",
      "Epoch: 3450 | training loss: 1.4949e-03 | validation loss: 5.2422e-04\n",
      "Epoch: 3460 | training loss: 1.4942e-03 | validation loss: 5.2374e-04\n",
      "Epoch: 3470 | training loss: 1.4935e-03 | validation loss: 5.2326e-04\n",
      "Epoch: 3480 | training loss: 1.4928e-03 | validation loss: 5.2278e-04\n",
      "Epoch: 3490 | training loss: 1.4921e-03 | validation loss: 5.2231e-04\n",
      "Epoch: 3500 | training loss: 1.4914e-03 | validation loss: 5.2184e-04\n",
      "Epoch: 3510 | training loss: 1.4907e-03 | validation loss: 5.2138e-04\n",
      "Epoch: 3520 | training loss: 1.4900e-03 | validation loss: 5.2092e-04\n",
      "Epoch: 3530 | training loss: 1.4893e-03 | validation loss: 5.2046e-04\n",
      "Epoch: 3540 | training loss: 1.4886e-03 | validation loss: 5.2001e-04\n",
      "Epoch: 3550 | training loss: 1.4879e-03 | validation loss: 5.1956e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3560 | training loss: 1.4873e-03 | validation loss: 5.1911e-04\n",
      "Epoch: 3570 | training loss: 1.4866e-03 | validation loss: 5.1867e-04\n",
      "Epoch: 3580 | training loss: 1.4859e-03 | validation loss: 5.1823e-04\n",
      "Epoch: 3590 | training loss: 1.4853e-03 | validation loss: 5.1779e-04\n",
      "Epoch: 3600 | training loss: 1.4846e-03 | validation loss: 5.1736e-04\n",
      "Epoch: 3610 | training loss: 1.4840e-03 | validation loss: 5.1693e-04\n",
      "Epoch: 3620 | training loss: 1.4833e-03 | validation loss: 5.1650e-04\n",
      "Epoch: 3630 | training loss: 1.4827e-03 | validation loss: 5.1608e-04\n",
      "Epoch: 3640 | training loss: 1.4820e-03 | validation loss: 5.1565e-04\n",
      "Epoch: 3650 | training loss: 1.4814e-03 | validation loss: 5.1524e-04\n",
      "Epoch: 3660 | training loss: 1.4808e-03 | validation loss: 5.1482e-04\n",
      "Epoch: 3670 | training loss: 1.4802e-03 | validation loss: 5.1441e-04\n",
      "Epoch: 3680 | training loss: 1.4795e-03 | validation loss: 5.1400e-04\n",
      "Epoch: 3690 | training loss: 1.4789e-03 | validation loss: 5.1360e-04\n",
      "Epoch: 3700 | training loss: 1.4783e-03 | validation loss: 5.1320e-04\n",
      "Epoch: 3710 | training loss: 1.4777e-03 | validation loss: 5.1280e-04\n",
      "Epoch: 3720 | training loss: 1.4771e-03 | validation loss: 5.1240e-04\n",
      "Epoch: 3730 | training loss: 1.4765e-03 | validation loss: 5.1201e-04\n",
      "Epoch: 3740 | training loss: 1.4759e-03 | validation loss: 5.1162e-04\n",
      "Epoch: 3750 | training loss: 1.4753e-03 | validation loss: 5.1123e-04\n",
      "Epoch: 3760 | training loss: 1.4747e-03 | validation loss: 5.1084e-04\n",
      "Epoch: 3770 | training loss: 1.4742e-03 | validation loss: 5.1046e-04\n",
      "Epoch: 3780 | training loss: 1.4736e-03 | validation loss: 5.1008e-04\n",
      "Epoch: 3790 | training loss: 1.4730e-03 | validation loss: 5.0971e-04\n",
      "Epoch: 3800 | training loss: 1.4724e-03 | validation loss: 5.0933e-04\n",
      "Epoch: 3810 | training loss: 1.4719e-03 | validation loss: 5.0896e-04\n",
      "Epoch: 3820 | training loss: 1.4713e-03 | validation loss: 5.0859e-04\n",
      "Epoch: 3830 | training loss: 1.4707e-03 | validation loss: 5.0823e-04\n",
      "Epoch: 3840 | training loss: 1.4702e-03 | validation loss: 5.0787e-04\n",
      "Epoch: 3850 | training loss: 1.4696e-03 | validation loss: 5.0750e-04\n",
      "Epoch: 3860 | training loss: 1.4691e-03 | validation loss: 5.0715e-04\n",
      "Epoch: 3870 | training loss: 1.4686e-03 | validation loss: 5.0679e-04\n",
      "Epoch: 3880 | training loss: 1.4680e-03 | validation loss: 5.0644e-04\n",
      "Epoch: 3890 | training loss: 1.4675e-03 | validation loss: 5.0609e-04\n",
      "Epoch: 3900 | training loss: 1.4669e-03 | validation loss: 5.0574e-04\n",
      "Epoch: 3910 | training loss: 1.4664e-03 | validation loss: 5.0539e-04\n",
      "Epoch: 3920 | training loss: 1.4659e-03 | validation loss: 5.0505e-04\n",
      "Epoch: 3930 | training loss: 1.4654e-03 | validation loss: 5.0471e-04\n",
      "Epoch: 3940 | training loss: 1.4648e-03 | validation loss: 5.0437e-04\n",
      "Epoch: 3950 | training loss: 1.4643e-03 | validation loss: 5.0404e-04\n",
      "Epoch: 3960 | training loss: 1.4638e-03 | validation loss: 5.0370e-04\n",
      "Epoch: 3970 | training loss: 1.4633e-03 | validation loss: 5.0337e-04\n",
      "Epoch: 3980 | training loss: 1.4628e-03 | validation loss: 5.0304e-04\n",
      "Epoch: 3990 | training loss: 1.4623e-03 | validation loss: 5.0272e-04\n",
      "Epoch: 4000 | training loss: 1.4618e-03 | validation loss: 5.0239e-04\n",
      "Epoch: 4010 | training loss: 1.4613e-03 | validation loss: 5.0207e-04\n",
      "Epoch: 4020 | training loss: 1.4608e-03 | validation loss: 5.0175e-04\n",
      "Epoch: 4030 | training loss: 1.4603e-03 | validation loss: 5.0143e-04\n",
      "Epoch: 4040 | training loss: 1.4598e-03 | validation loss: 5.0112e-04\n",
      "Epoch: 4050 | training loss: 1.4593e-03 | validation loss: 5.0080e-04\n",
      "Epoch: 4060 | training loss: 1.4589e-03 | validation loss: 5.0049e-04\n",
      "Epoch: 4070 | training loss: 1.4584e-03 | validation loss: 5.0018e-04\n",
      "Epoch: 4080 | training loss: 1.4579e-03 | validation loss: 4.9987e-04\n",
      "Epoch: 4090 | training loss: 1.4574e-03 | validation loss: 4.9957e-04\n",
      "Epoch: 4100 | training loss: 1.4570e-03 | validation loss: 4.9927e-04\n",
      "Epoch: 4110 | training loss: 1.4565e-03 | validation loss: 4.9896e-04\n",
      "Epoch: 4120 | training loss: 1.4560e-03 | validation loss: 4.9867e-04\n",
      "Epoch: 4130 | training loss: 1.4556e-03 | validation loss: 4.9837e-04\n",
      "Epoch: 4140 | training loss: 1.4551e-03 | validation loss: 4.9807e-04\n",
      "Epoch: 4150 | training loss: 1.4547e-03 | validation loss: 4.9778e-04\n",
      "Epoch: 4160 | training loss: 1.4542e-03 | validation loss: 4.9749e-04\n",
      "Epoch: 4170 | training loss: 1.4538e-03 | validation loss: 4.9720e-04\n",
      "Epoch: 4180 | training loss: 1.4533e-03 | validation loss: 4.9691e-04\n",
      "Epoch: 4190 | training loss: 1.4529e-03 | validation loss: 4.9663e-04\n",
      "Epoch: 4200 | training loss: 1.4524e-03 | validation loss: 4.9634e-04\n",
      "Epoch: 4210 | training loss: 1.4520e-03 | validation loss: 4.9606e-04\n",
      "Epoch: 4220 | training loss: 1.4516e-03 | validation loss: 4.9578e-04\n",
      "Epoch: 4230 | training loss: 1.4511e-03 | validation loss: 4.9551e-04\n",
      "Epoch: 4240 | training loss: 1.4507e-03 | validation loss: 4.9523e-04\n",
      "Epoch: 4250 | training loss: 1.4503e-03 | validation loss: 4.9496e-04\n",
      "Epoch: 4260 | training loss: 1.4499e-03 | validation loss: 4.9468e-04\n",
      "Epoch: 4270 | training loss: 1.4494e-03 | validation loss: 4.9441e-04\n",
      "Epoch: 4280 | training loss: 1.4490e-03 | validation loss: 4.9414e-04\n",
      "Epoch: 4290 | training loss: 1.4486e-03 | validation loss: 4.9388e-04\n",
      "Epoch: 4300 | training loss: 1.4482e-03 | validation loss: 4.9361e-04\n",
      "Epoch: 4310 | training loss: 1.4478e-03 | validation loss: 4.9335e-04\n",
      "Epoch: 4320 | training loss: 1.4474e-03 | validation loss: 4.9309e-04\n",
      "Epoch: 4330 | training loss: 1.4470e-03 | validation loss: 4.9283e-04\n",
      "Epoch: 4340 | training loss: 1.4466e-03 | validation loss: 4.9257e-04\n",
      "Epoch: 4350 | training loss: 1.4462e-03 | validation loss: 4.9231e-04\n",
      "Epoch: 4360 | training loss: 1.4458e-03 | validation loss: 4.9206e-04\n",
      "Epoch: 4370 | training loss: 1.4454e-03 | validation loss: 4.9180e-04\n",
      "Epoch: 4380 | training loss: 1.4450e-03 | validation loss: 4.9155e-04\n",
      "Epoch: 4390 | training loss: 1.4446e-03 | validation loss: 4.9130e-04\n",
      "Epoch: 4400 | training loss: 1.4442e-03 | validation loss: 4.9105e-04\n",
      "Epoch: 4410 | training loss: 1.4438e-03 | validation loss: 4.9080e-04\n",
      "Epoch: 4420 | training loss: 1.4434e-03 | validation loss: 4.9056e-04\n",
      "Epoch: 4430 | training loss: 1.4431e-03 | validation loss: 4.9032e-04\n",
      "Epoch: 4440 | training loss: 1.4427e-03 | validation loss: 4.9007e-04\n",
      "Epoch: 4450 | training loss: 1.4423e-03 | validation loss: 4.8983e-04\n",
      "Epoch: 4460 | training loss: 1.4419e-03 | validation loss: 4.8959e-04\n",
      "Epoch: 4470 | training loss: 1.4416e-03 | validation loss: 4.8936e-04\n",
      "Epoch: 4480 | training loss: 1.4412e-03 | validation loss: 4.8912e-04\n",
      "Epoch: 4490 | training loss: 1.4408e-03 | validation loss: 4.8888e-04\n",
      "Epoch: 4500 | training loss: 1.4405e-03 | validation loss: 4.8865e-04\n",
      "Epoch: 4510 | training loss: 1.4401e-03 | validation loss: 4.8842e-04\n",
      "Epoch: 4520 | training loss: 1.4397e-03 | validation loss: 4.8819e-04\n",
      "Epoch: 4530 | training loss: 1.4394e-03 | validation loss: 4.8796e-04\n",
      "Epoch: 4540 | training loss: 1.4390e-03 | validation loss: 4.8773e-04\n",
      "Epoch: 4550 | training loss: 1.4387e-03 | validation loss: 4.8751e-04\n",
      "Epoch: 4560 | training loss: 1.4383e-03 | validation loss: 4.8728e-04\n",
      "Epoch: 4570 | training loss: 1.4380e-03 | validation loss: 4.8706e-04\n",
      "Epoch: 4580 | training loss: 1.4376e-03 | validation loss: 4.8684e-04\n",
      "Epoch: 4590 | training loss: 1.4373e-03 | validation loss: 4.8662e-04\n",
      "Epoch: 4600 | training loss: 1.4369e-03 | validation loss: 4.8640e-04\n",
      "Epoch: 4610 | training loss: 1.4366e-03 | validation loss: 4.8618e-04\n",
      "Epoch: 4620 | training loss: 1.4362e-03 | validation loss: 4.8596e-04\n",
      "Epoch: 4630 | training loss: 1.4359e-03 | validation loss: 4.8574e-04\n",
      "Epoch: 4640 | training loss: 1.4356e-03 | validation loss: 4.8552e-04\n",
      "Epoch: 4650 | training loss: 1.4352e-03 | validation loss: 4.8530e-04\n",
      "Epoch: 4660 | training loss: 1.4349e-03 | validation loss: 4.8508e-04\n",
      "Epoch: 4670 | training loss: 1.4345e-03 | validation loss: 4.8486e-04\n",
      "Epoch: 4680 | training loss: 1.4342e-03 | validation loss: 4.8463e-04\n",
      "Epoch: 4690 | training loss: 1.4338e-03 | validation loss: 4.8441e-04\n",
      "Epoch: 4700 | training loss: 1.4334e-03 | validation loss: 4.8418e-04\n",
      "Epoch: 4710 | training loss: 1.4331e-03 | validation loss: 4.8396e-04\n",
      "Epoch: 4720 | training loss: 1.4327e-03 | validation loss: 4.8373e-04\n",
      "Epoch: 4730 | training loss: 1.4324e-03 | validation loss: 4.8350e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4740 | training loss: 1.4320e-03 | validation loss: 4.8327e-04\n",
      "Epoch: 4750 | training loss: 1.4317e-03 | validation loss: 4.8304e-04\n",
      "Epoch: 4760 | training loss: 1.4313e-03 | validation loss: 4.8281e-04\n",
      "Epoch: 4770 | training loss: 1.4309e-03 | validation loss: 4.8258e-04\n",
      "Epoch: 4780 | training loss: 1.4306e-03 | validation loss: 4.8235e-04\n",
      "Epoch: 4790 | training loss: 1.4302e-03 | validation loss: 4.8212e-04\n",
      "Epoch: 4800 | training loss: 1.4298e-03 | validation loss: 4.8188e-04\n",
      "Epoch: 4810 | training loss: 1.4295e-03 | validation loss: 4.8165e-04\n",
      "Epoch: 4820 | training loss: 1.4291e-03 | validation loss: 4.8141e-04\n",
      "Epoch: 4830 | training loss: 1.4287e-03 | validation loss: 4.8118e-04\n",
      "Epoch: 4840 | training loss: 1.4283e-03 | validation loss: 4.8094e-04\n",
      "Epoch: 4850 | training loss: 1.4280e-03 | validation loss: 4.8070e-04\n",
      "Epoch: 4860 | training loss: 1.4276e-03 | validation loss: 4.8046e-04\n",
      "Epoch: 4870 | training loss: 1.4272e-03 | validation loss: 4.8022e-04\n",
      "Epoch: 4880 | training loss: 1.4268e-03 | validation loss: 4.7998e-04\n",
      "Epoch: 4890 | training loss: 1.4264e-03 | validation loss: 4.7974e-04\n",
      "Epoch: 4900 | training loss: 1.4261e-03 | validation loss: 4.7950e-04\n",
      "Epoch: 4910 | training loss: 1.4257e-03 | validation loss: 4.7926e-04\n",
      "Epoch: 4920 | training loss: 1.4253e-03 | validation loss: 4.7901e-04\n",
      "Epoch: 4930 | training loss: 1.4249e-03 | validation loss: 4.7877e-04\n",
      "Epoch: 4940 | training loss: 1.4245e-03 | validation loss: 4.7852e-04\n",
      "Epoch: 4950 | training loss: 1.4241e-03 | validation loss: 4.7827e-04\n",
      "Epoch: 4960 | training loss: 1.4237e-03 | validation loss: 4.7803e-04\n",
      "Epoch: 4970 | training loss: 1.4233e-03 | validation loss: 4.7778e-04\n",
      "Epoch: 4980 | training loss: 1.4229e-03 | validation loss: 4.7753e-04\n",
      "Epoch: 4990 | training loss: 1.4226e-03 | validation loss: 4.7728e-04\n",
      "Epoch: 5000 | training loss: 1.4222e-03 | validation loss: 4.7703e-04\n",
      "Epoch: 5010 | training loss: 1.4218e-03 | validation loss: 4.7677e-04\n",
      "Epoch: 5020 | training loss: 1.4214e-03 | validation loss: 4.7652e-04\n",
      "Epoch: 5030 | training loss: 1.4210e-03 | validation loss: 4.7627e-04\n",
      "Epoch: 5040 | training loss: 1.4205e-03 | validation loss: 4.7601e-04\n",
      "Epoch: 5050 | training loss: 1.4201e-03 | validation loss: 4.7576e-04\n",
      "Epoch: 5060 | training loss: 1.4197e-03 | validation loss: 4.7550e-04\n",
      "Epoch: 5070 | training loss: 1.4193e-03 | validation loss: 4.7524e-04\n",
      "Epoch: 5080 | training loss: 1.4189e-03 | validation loss: 4.7498e-04\n",
      "Epoch: 5090 | training loss: 1.4185e-03 | validation loss: 4.7472e-04\n",
      "Epoch: 5100 | training loss: 1.4181e-03 | validation loss: 4.7446e-04\n",
      "Epoch: 5110 | training loss: 1.4177e-03 | validation loss: 4.7420e-04\n",
      "Epoch: 5120 | training loss: 1.4173e-03 | validation loss: 4.7394e-04\n",
      "Epoch: 5130 | training loss: 1.4168e-03 | validation loss: 4.7368e-04\n",
      "Epoch: 5140 | training loss: 1.4164e-03 | validation loss: 4.7341e-04\n",
      "Epoch: 5150 | training loss: 1.4160e-03 | validation loss: 4.7315e-04\n",
      "Epoch: 5160 | training loss: 1.4156e-03 | validation loss: 4.7288e-04\n",
      "Epoch: 5170 | training loss: 1.4152e-03 | validation loss: 4.7261e-04\n",
      "Epoch: 5180 | training loss: 1.4147e-03 | validation loss: 4.7235e-04\n",
      "Epoch: 5190 | training loss: 1.4143e-03 | validation loss: 4.7208e-04\n",
      "Epoch: 5200 | training loss: 1.4139e-03 | validation loss: 4.7181e-04\n",
      "Epoch: 5210 | training loss: 1.4134e-03 | validation loss: 4.7154e-04\n",
      "Epoch: 5220 | training loss: 1.4130e-03 | validation loss: 4.7127e-04\n",
      "Epoch: 5230 | training loss: 1.4126e-03 | validation loss: 4.7099e-04\n",
      "Epoch: 5240 | training loss: 1.4121e-03 | validation loss: 4.7072e-04\n",
      "Epoch: 5250 | training loss: 1.4117e-03 | validation loss: 4.7045e-04\n",
      "Epoch: 5260 | training loss: 1.4113e-03 | validation loss: 4.7017e-04\n",
      "Epoch: 5270 | training loss: 1.4108e-03 | validation loss: 4.6989e-04\n",
      "Epoch: 5280 | training loss: 1.4104e-03 | validation loss: 4.6962e-04\n",
      "Epoch: 5290 | training loss: 1.4099e-03 | validation loss: 4.6934e-04\n",
      "Epoch: 5300 | training loss: 1.4095e-03 | validation loss: 4.6906e-04\n",
      "Epoch: 5310 | training loss: 1.4090e-03 | validation loss: 4.6878e-04\n",
      "Epoch: 5320 | training loss: 1.4086e-03 | validation loss: 4.6850e-04\n",
      "Epoch: 5330 | training loss: 1.4081e-03 | validation loss: 4.6822e-04\n",
      "Epoch: 5340 | training loss: 1.4077e-03 | validation loss: 4.6793e-04\n",
      "Epoch: 5350 | training loss: 1.4072e-03 | validation loss: 4.6765e-04\n",
      "Epoch: 5360 | training loss: 1.4068e-03 | validation loss: 4.6736e-04\n",
      "Epoch: 5370 | training loss: 1.4063e-03 | validation loss: 4.6708e-04\n",
      "Epoch: 5380 | training loss: 1.4059e-03 | validation loss: 4.6679e-04\n",
      "Epoch: 5390 | training loss: 1.4054e-03 | validation loss: 4.6650e-04\n",
      "Epoch: 5400 | training loss: 1.4049e-03 | validation loss: 4.6621e-04\n",
      "Epoch: 5410 | training loss: 1.4045e-03 | validation loss: 4.6592e-04\n",
      "Epoch: 5420 | training loss: 1.4040e-03 | validation loss: 4.6563e-04\n",
      "Epoch: 5430 | training loss: 1.4035e-03 | validation loss: 4.6534e-04\n",
      "Epoch: 5440 | training loss: 1.4031e-03 | validation loss: 4.6505e-04\n",
      "Epoch: 5450 | training loss: 1.4026e-03 | validation loss: 4.6476e-04\n",
      "Epoch: 5460 | training loss: 1.4021e-03 | validation loss: 4.6446e-04\n",
      "Epoch: 5470 | training loss: 1.4017e-03 | validation loss: 4.6417e-04\n",
      "Epoch: 5480 | training loss: 1.4012e-03 | validation loss: 4.6387e-04\n",
      "Epoch: 5490 | training loss: 1.4007e-03 | validation loss: 4.6357e-04\n",
      "Epoch: 5500 | training loss: 1.4002e-03 | validation loss: 4.6327e-04\n",
      "Epoch: 5510 | training loss: 1.3997e-03 | validation loss: 4.6297e-04\n",
      "Epoch: 5520 | training loss: 1.3993e-03 | validation loss: 4.6267e-04\n",
      "Epoch: 5530 | training loss: 1.3988e-03 | validation loss: 4.6237e-04\n",
      "Epoch: 5540 | training loss: 1.3983e-03 | validation loss: 4.6207e-04\n",
      "Epoch: 5550 | training loss: 1.3978e-03 | validation loss: 4.6176e-04\n",
      "Epoch: 5560 | training loss: 1.3973e-03 | validation loss: 4.6146e-04\n",
      "Epoch: 5570 | training loss: 1.3968e-03 | validation loss: 4.6115e-04\n",
      "Epoch: 5580 | training loss: 1.3963e-03 | validation loss: 4.6085e-04\n",
      "Epoch: 5590 | training loss: 1.3958e-03 | validation loss: 4.6054e-04\n",
      "Epoch: 5600 | training loss: 1.3953e-03 | validation loss: 4.6023e-04\n",
      "Epoch: 5610 | training loss: 1.3948e-03 | validation loss: 4.5992e-04\n",
      "Epoch: 5620 | training loss: 1.3943e-03 | validation loss: 4.5961e-04\n",
      "Epoch: 5630 | training loss: 1.3938e-03 | validation loss: 4.5930e-04\n",
      "Epoch: 5640 | training loss: 1.3933e-03 | validation loss: 4.5899e-04\n",
      "Epoch: 5650 | training loss: 1.3928e-03 | validation loss: 4.5867e-04\n",
      "Epoch: 5660 | training loss: 1.3923e-03 | validation loss: 4.5836e-04\n",
      "Epoch: 5670 | training loss: 1.3918e-03 | validation loss: 4.5804e-04\n",
      "Epoch: 5680 | training loss: 1.3913e-03 | validation loss: 4.5772e-04\n",
      "Epoch: 5690 | training loss: 1.3908e-03 | validation loss: 4.5741e-04\n",
      "Epoch: 5700 | training loss: 1.3903e-03 | validation loss: 4.5709e-04\n",
      "Epoch: 5710 | training loss: 1.3898e-03 | validation loss: 4.5677e-04\n",
      "Epoch: 5720 | training loss: 1.3892e-03 | validation loss: 4.5645e-04\n",
      "Epoch: 5730 | training loss: 1.3887e-03 | validation loss: 4.5613e-04\n",
      "Epoch: 5740 | training loss: 1.3882e-03 | validation loss: 4.5580e-04\n",
      "Epoch: 5750 | training loss: 1.3877e-03 | validation loss: 4.5548e-04\n",
      "Epoch: 5760 | training loss: 1.3872e-03 | validation loss: 4.5515e-04\n",
      "Epoch: 5770 | training loss: 1.3866e-03 | validation loss: 4.5483e-04\n",
      "Epoch: 5780 | training loss: 1.3861e-03 | validation loss: 4.5450e-04\n",
      "Epoch: 5790 | training loss: 1.3856e-03 | validation loss: 4.5417e-04\n",
      "Epoch: 5800 | training loss: 1.3850e-03 | validation loss: 4.5384e-04\n",
      "Epoch: 5810 | training loss: 1.3845e-03 | validation loss: 4.5351e-04\n",
      "Epoch: 5820 | training loss: 1.3840e-03 | validation loss: 4.5318e-04\n",
      "Epoch: 5830 | training loss: 1.3834e-03 | validation loss: 4.5285e-04\n",
      "Epoch: 5840 | training loss: 1.3829e-03 | validation loss: 4.5252e-04\n",
      "Epoch: 5850 | training loss: 1.3823e-03 | validation loss: 4.5218e-04\n",
      "Epoch: 5860 | training loss: 1.3818e-03 | validation loss: 4.5185e-04\n",
      "Epoch: 5870 | training loss: 1.3813e-03 | validation loss: 4.5151e-04\n",
      "Epoch: 5880 | training loss: 1.3807e-03 | validation loss: 4.5117e-04\n",
      "Epoch: 5890 | training loss: 1.3802e-03 | validation loss: 4.5083e-04\n",
      "Epoch: 5900 | training loss: 1.3796e-03 | validation loss: 4.5049e-04\n",
      "Epoch: 5910 | training loss: 1.3791e-03 | validation loss: 4.5015e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5920 | training loss: 1.3785e-03 | validation loss: 4.4981e-04\n",
      "Epoch: 5930 | training loss: 1.3779e-03 | validation loss: 4.4947e-04\n",
      "Epoch: 5940 | training loss: 1.3774e-03 | validation loss: 4.4912e-04\n",
      "Epoch: 5950 | training loss: 1.3768e-03 | validation loss: 4.4878e-04\n",
      "Epoch: 5960 | training loss: 1.3763e-03 | validation loss: 4.4843e-04\n",
      "Epoch: 5970 | training loss: 1.3757e-03 | validation loss: 4.4808e-04\n",
      "Epoch: 5980 | training loss: 1.3751e-03 | validation loss: 4.4774e-04\n",
      "Epoch: 5990 | training loss: 1.3746e-03 | validation loss: 4.4739e-04\n",
      "Epoch: 6000 | training loss: 1.3740e-03 | validation loss: 4.4704e-04\n",
      "Epoch: 6010 | training loss: 1.3734e-03 | validation loss: 4.4668e-04\n",
      "Epoch: 6020 | training loss: 1.3729e-03 | validation loss: 4.4633e-04\n",
      "Epoch: 6030 | training loss: 1.3723e-03 | validation loss: 4.4598e-04\n",
      "Epoch: 6040 | training loss: 1.3717e-03 | validation loss: 4.4562e-04\n",
      "Epoch: 6050 | training loss: 1.3711e-03 | validation loss: 4.4527e-04\n",
      "Epoch: 6060 | training loss: 1.3705e-03 | validation loss: 4.4491e-04\n",
      "Epoch: 6070 | training loss: 1.3700e-03 | validation loss: 4.4455e-04\n",
      "Epoch: 6080 | training loss: 1.3694e-03 | validation loss: 4.4419e-04\n",
      "Epoch: 6090 | training loss: 1.3688e-03 | validation loss: 4.4383e-04\n",
      "Epoch: 6100 | training loss: 1.3682e-03 | validation loss: 4.4347e-04\n",
      "Epoch: 6110 | training loss: 1.3676e-03 | validation loss: 4.4311e-04\n",
      "Epoch: 6120 | training loss: 1.3670e-03 | validation loss: 4.4274e-04\n",
      "Epoch: 6130 | training loss: 1.3664e-03 | validation loss: 4.4238e-04\n",
      "Epoch: 6140 | training loss: 1.3658e-03 | validation loss: 4.4201e-04\n",
      "Epoch: 6150 | training loss: 1.3652e-03 | validation loss: 4.4165e-04\n",
      "Epoch: 6160 | training loss: 1.3646e-03 | validation loss: 4.4128e-04\n",
      "Epoch: 6170 | training loss: 1.3640e-03 | validation loss: 4.4091e-04\n",
      "Epoch: 6180 | training loss: 1.3634e-03 | validation loss: 4.4054e-04\n",
      "Epoch: 6190 | training loss: 1.3628e-03 | validation loss: 4.4017e-04\n",
      "Epoch: 6200 | training loss: 1.3622e-03 | validation loss: 4.3980e-04\n",
      "Epoch: 6210 | training loss: 1.3616e-03 | validation loss: 4.3942e-04\n",
      "Epoch: 6220 | training loss: 1.3610e-03 | validation loss: 4.3905e-04\n",
      "Epoch: 6230 | training loss: 1.3604e-03 | validation loss: 4.3867e-04\n",
      "Epoch: 6240 | training loss: 1.3597e-03 | validation loss: 4.3830e-04\n",
      "Epoch: 6250 | training loss: 1.3591e-03 | validation loss: 4.3792e-04\n",
      "Epoch: 6260 | training loss: 1.3585e-03 | validation loss: 4.3754e-04\n",
      "Epoch: 6270 | training loss: 1.3579e-03 | validation loss: 4.3716e-04\n",
      "Epoch: 6280 | training loss: 1.3573e-03 | validation loss: 4.3678e-04\n",
      "Epoch: 6290 | training loss: 1.3566e-03 | validation loss: 4.3640e-04\n",
      "Epoch: 6300 | training loss: 1.3560e-03 | validation loss: 4.3601e-04\n",
      "Epoch: 6310 | training loss: 1.3554e-03 | validation loss: 4.3563e-04\n",
      "Epoch: 6320 | training loss: 1.3547e-03 | validation loss: 4.3524e-04\n",
      "Epoch: 6330 | training loss: 1.3541e-03 | validation loss: 4.3486e-04\n",
      "Epoch: 6340 | training loss: 1.3535e-03 | validation loss: 4.3447e-04\n",
      "Epoch: 6350 | training loss: 1.3528e-03 | validation loss: 4.3408e-04\n",
      "Epoch: 6360 | training loss: 1.3522e-03 | validation loss: 4.3369e-04\n",
      "Epoch: 6370 | training loss: 1.3515e-03 | validation loss: 4.3330e-04\n",
      "Epoch: 6380 | training loss: 1.3509e-03 | validation loss: 4.3291e-04\n",
      "Epoch: 6390 | training loss: 1.3503e-03 | validation loss: 4.3252e-04\n",
      "Epoch: 6400 | training loss: 1.3496e-03 | validation loss: 4.3212e-04\n",
      "Epoch: 6410 | training loss: 1.3490e-03 | validation loss: 4.3173e-04\n",
      "Epoch: 6420 | training loss: 1.3483e-03 | validation loss: 4.3133e-04\n",
      "Epoch: 6430 | training loss: 1.3476e-03 | validation loss: 4.3093e-04\n",
      "Epoch: 6440 | training loss: 1.3470e-03 | validation loss: 4.3054e-04\n",
      "Epoch: 6450 | training loss: 1.3463e-03 | validation loss: 4.3014e-04\n",
      "Epoch: 6460 | training loss: 1.3457e-03 | validation loss: 4.2974e-04\n",
      "Epoch: 6470 | training loss: 1.3450e-03 | validation loss: 4.2933e-04\n",
      "Epoch: 6480 | training loss: 1.3443e-03 | validation loss: 4.2893e-04\n",
      "Epoch: 6490 | training loss: 1.3437e-03 | validation loss: 4.2853e-04\n",
      "Epoch: 6500 | training loss: 1.3430e-03 | validation loss: 4.2812e-04\n",
      "Epoch: 6510 | training loss: 1.3423e-03 | validation loss: 4.2772e-04\n",
      "Epoch: 6520 | training loss: 1.3417e-03 | validation loss: 4.2731e-04\n",
      "Epoch: 6530 | training loss: 1.3410e-03 | validation loss: 4.2690e-04\n",
      "Epoch: 6540 | training loss: 1.3403e-03 | validation loss: 4.2649e-04\n",
      "Epoch: 6550 | training loss: 1.3396e-03 | validation loss: 4.2608e-04\n",
      "Epoch: 6560 | training loss: 1.3390e-03 | validation loss: 4.2567e-04\n",
      "Epoch: 6570 | training loss: 1.3383e-03 | validation loss: 4.2526e-04\n",
      "Epoch: 6580 | training loss: 1.3376e-03 | validation loss: 4.2484e-04\n",
      "Epoch: 6590 | training loss: 1.3369e-03 | validation loss: 4.2443e-04\n",
      "Epoch: 6600 | training loss: 1.3362e-03 | validation loss: 4.2401e-04\n",
      "Epoch: 6610 | training loss: 1.3355e-03 | validation loss: 4.2360e-04\n",
      "Epoch: 6620 | training loss: 1.3348e-03 | validation loss: 4.2318e-04\n",
      "Epoch: 6630 | training loss: 1.3341e-03 | validation loss: 4.2276e-04\n",
      "Epoch: 6640 | training loss: 1.3334e-03 | validation loss: 4.2234e-04\n",
      "Epoch: 6650 | training loss: 1.3327e-03 | validation loss: 4.2192e-04\n",
      "Epoch: 6660 | training loss: 1.3320e-03 | validation loss: 4.2149e-04\n",
      "Epoch: 6670 | training loss: 1.3313e-03 | validation loss: 4.2107e-04\n",
      "Epoch: 6680 | training loss: 1.3306e-03 | validation loss: 4.2065e-04\n",
      "Epoch: 6690 | training loss: 1.3299e-03 | validation loss: 4.2022e-04\n",
      "Epoch: 6700 | training loss: 1.3292e-03 | validation loss: 4.1979e-04\n",
      "Epoch: 6710 | training loss: 1.3285e-03 | validation loss: 4.1937e-04\n",
      "Epoch: 6720 | training loss: 1.3278e-03 | validation loss: 4.1894e-04\n",
      "Epoch: 6730 | training loss: 1.3271e-03 | validation loss: 4.1851e-04\n",
      "Epoch: 6740 | training loss: 1.3263e-03 | validation loss: 4.1808e-04\n",
      "Epoch: 6750 | training loss: 1.3256e-03 | validation loss: 4.1764e-04\n",
      "Epoch: 6760 | training loss: 1.3249e-03 | validation loss: 4.1721e-04\n",
      "Epoch: 6770 | training loss: 1.3242e-03 | validation loss: 4.1678e-04\n",
      "Epoch: 6780 | training loss: 1.3235e-03 | validation loss: 4.1634e-04\n",
      "Epoch: 6790 | training loss: 1.3227e-03 | validation loss: 4.1590e-04\n",
      "Epoch: 6800 | training loss: 1.3220e-03 | validation loss: 4.1547e-04\n",
      "Epoch: 6810 | training loss: 1.3213e-03 | validation loss: 4.1503e-04\n",
      "Epoch: 6820 | training loss: 1.3205e-03 | validation loss: 4.1459e-04\n",
      "Epoch: 6830 | training loss: 1.3198e-03 | validation loss: 4.1415e-04\n",
      "Epoch: 6840 | training loss: 1.3190e-03 | validation loss: 4.1371e-04\n",
      "Epoch: 6850 | training loss: 1.3183e-03 | validation loss: 4.1326e-04\n",
      "Epoch: 6860 | training loss: 1.3176e-03 | validation loss: 4.1282e-04\n",
      "Epoch: 6870 | training loss: 1.3168e-03 | validation loss: 4.1237e-04\n",
      "Epoch: 6880 | training loss: 1.3161e-03 | validation loss: 4.1193e-04\n",
      "Epoch: 6890 | training loss: 1.3153e-03 | validation loss: 4.1148e-04\n",
      "Epoch: 6900 | training loss: 1.3146e-03 | validation loss: 4.1103e-04\n",
      "Epoch: 6910 | training loss: 1.3138e-03 | validation loss: 4.1058e-04\n",
      "Epoch: 6920 | training loss: 1.3131e-03 | validation loss: 4.1013e-04\n",
      "Epoch: 6930 | training loss: 1.3123e-03 | validation loss: 4.0968e-04\n",
      "Epoch: 6940 | training loss: 1.3115e-03 | validation loss: 4.0923e-04\n",
      "Epoch: 6950 | training loss: 1.3108e-03 | validation loss: 4.0877e-04\n",
      "Epoch: 6960 | training loss: 1.3100e-03 | validation loss: 4.0832e-04\n",
      "Epoch: 6970 | training loss: 1.3092e-03 | validation loss: 4.0786e-04\n",
      "Epoch: 6980 | training loss: 1.3085e-03 | validation loss: 4.0741e-04\n",
      "Epoch: 6990 | training loss: 1.3077e-03 | validation loss: 4.0695e-04\n",
      "Epoch: 7000 | training loss: 1.3069e-03 | validation loss: 4.0649e-04\n",
      "Epoch: 7010 | training loss: 1.3062e-03 | validation loss: 4.0603e-04\n",
      "Epoch: 7020 | training loss: 1.3054e-03 | validation loss: 4.0557e-04\n",
      "Epoch: 7030 | training loss: 1.3046e-03 | validation loss: 4.0510e-04\n",
      "Epoch: 7040 | training loss: 1.3038e-03 | validation loss: 4.0464e-04\n",
      "Epoch: 7050 | training loss: 1.3030e-03 | validation loss: 4.0418e-04\n",
      "Epoch: 7060 | training loss: 1.3023e-03 | validation loss: 4.0371e-04\n",
      "Epoch: 7070 | training loss: 1.3015e-03 | validation loss: 4.0324e-04\n",
      "Epoch: 7080 | training loss: 1.3007e-03 | validation loss: 4.0278e-04\n",
      "Epoch: 7090 | training loss: 1.2999e-03 | validation loss: 4.0231e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7100 | training loss: 1.2991e-03 | validation loss: 4.0184e-04\n",
      "Epoch: 7110 | training loss: 1.2983e-03 | validation loss: 4.0137e-04\n",
      "Epoch: 7120 | training loss: 1.2975e-03 | validation loss: 4.0089e-04\n",
      "Epoch: 7130 | training loss: 1.2967e-03 | validation loss: 4.0042e-04\n",
      "Epoch: 7140 | training loss: 1.2959e-03 | validation loss: 3.9995e-04\n",
      "Epoch: 7150 | training loss: 1.2951e-03 | validation loss: 3.9947e-04\n",
      "Epoch: 7160 | training loss: 1.2943e-03 | validation loss: 3.9900e-04\n",
      "Epoch: 7170 | training loss: 1.2935e-03 | validation loss: 3.9852e-04\n",
      "Epoch: 7180 | training loss: 1.2927e-03 | validation loss: 3.9804e-04\n",
      "Epoch: 7190 | training loss: 1.2919e-03 | validation loss: 3.9756e-04\n",
      "Epoch: 7200 | training loss: 1.2910e-03 | validation loss: 3.9708e-04\n",
      "Epoch: 7210 | training loss: 1.2902e-03 | validation loss: 3.9660e-04\n",
      "Epoch: 7220 | training loss: 1.2894e-03 | validation loss: 3.9612e-04\n",
      "Epoch: 7230 | training loss: 1.2886e-03 | validation loss: 3.9564e-04\n",
      "Epoch: 7240 | training loss: 1.2878e-03 | validation loss: 3.9515e-04\n",
      "Epoch: 7250 | training loss: 1.2869e-03 | validation loss: 3.9467e-04\n",
      "Epoch: 7260 | training loss: 1.2861e-03 | validation loss: 3.9418e-04\n",
      "Epoch: 7270 | training loss: 1.2853e-03 | validation loss: 3.9369e-04\n",
      "Epoch: 7280 | training loss: 1.2845e-03 | validation loss: 3.9321e-04\n",
      "Epoch: 7290 | training loss: 1.2836e-03 | validation loss: 3.9272e-04\n",
      "Epoch: 7300 | training loss: 1.2828e-03 | validation loss: 3.9223e-04\n",
      "Epoch: 7310 | training loss: 1.2819e-03 | validation loss: 3.9174e-04\n",
      "Epoch: 7320 | training loss: 1.2811e-03 | validation loss: 3.9125e-04\n",
      "Epoch: 7330 | training loss: 1.2803e-03 | validation loss: 3.9075e-04\n",
      "Epoch: 7340 | training loss: 1.2794e-03 | validation loss: 3.9026e-04\n",
      "Epoch: 7350 | training loss: 1.2786e-03 | validation loss: 3.8977e-04\n",
      "Epoch: 7360 | training loss: 1.2777e-03 | validation loss: 3.8927e-04\n",
      "Epoch: 7370 | training loss: 1.2769e-03 | validation loss: 3.8877e-04\n",
      "Epoch: 7380 | training loss: 1.2760e-03 | validation loss: 3.8828e-04\n",
      "Epoch: 7390 | training loss: 1.2752e-03 | validation loss: 3.8778e-04\n",
      "Epoch: 7400 | training loss: 1.2743e-03 | validation loss: 3.8728e-04\n",
      "Epoch: 7410 | training loss: 1.2734e-03 | validation loss: 3.8678e-04\n",
      "Epoch: 7420 | training loss: 1.2726e-03 | validation loss: 3.8628e-04\n",
      "Epoch: 7430 | training loss: 1.2717e-03 | validation loss: 3.8578e-04\n",
      "Epoch: 7440 | training loss: 1.2709e-03 | validation loss: 3.8527e-04\n",
      "Epoch: 7450 | training loss: 1.2700e-03 | validation loss: 3.8477e-04\n",
      "Epoch: 7460 | training loss: 1.2691e-03 | validation loss: 3.8426e-04\n",
      "Epoch: 7470 | training loss: 1.2683e-03 | validation loss: 3.8376e-04\n",
      "Epoch: 7480 | training loss: 1.2674e-03 | validation loss: 3.8319e-04\n",
      "Epoch: 7490 | training loss: 1.2677e-03 | validation loss: 3.7960e-04\n",
      "Epoch: 7500 | training loss: 1.2669e-03 | validation loss: 3.8761e-04\n",
      "Epoch: 7510 | training loss: 1.2653e-03 | validation loss: 3.7931e-04\n",
      "Epoch: 7520 | training loss: 1.2641e-03 | validation loss: 3.7998e-04\n",
      "Epoch: 7530 | training loss: 1.2633e-03 | validation loss: 3.8233e-04\n",
      "Epoch: 7540 | training loss: 1.2623e-03 | validation loss: 3.8063e-04\n",
      "Epoch: 7550 | training loss: 1.2615e-03 | validation loss: 3.7945e-04\n",
      "Epoch: 7560 | training loss: 1.2607e-03 | validation loss: 3.7940e-04\n",
      "Epoch: 7570 | training loss: 1.2598e-03 | validation loss: 3.7918e-04\n",
      "Epoch: 7580 | training loss: 1.2590e-03 | validation loss: 3.7863e-04\n",
      "Epoch: 7590 | training loss: 1.2581e-03 | validation loss: 3.7807e-04\n",
      "Epoch: 7600 | training loss: 1.2573e-03 | validation loss: 3.7757e-04\n",
      "Epoch: 7610 | training loss: 1.2564e-03 | validation loss: 3.7711e-04\n",
      "Epoch: 7620 | training loss: 1.2556e-03 | validation loss: 3.7665e-04\n",
      "Epoch: 7630 | training loss: 1.2547e-03 | validation loss: 3.7618e-04\n",
      "Epoch: 7640 | training loss: 1.2539e-03 | validation loss: 3.7571e-04\n",
      "Epoch: 7650 | training loss: 1.2530e-03 | validation loss: 3.7523e-04\n",
      "Epoch: 7660 | training loss: 1.2522e-03 | validation loss: 3.7475e-04\n",
      "Epoch: 7670 | training loss: 1.2513e-03 | validation loss: 3.7427e-04\n",
      "Epoch: 7680 | training loss: 1.2505e-03 | validation loss: 3.7379e-04\n",
      "Epoch: 7690 | training loss: 1.2496e-03 | validation loss: 3.7330e-04\n",
      "Epoch: 7700 | training loss: 1.2487e-03 | validation loss: 3.7282e-04\n",
      "Epoch: 7710 | training loss: 1.2479e-03 | validation loss: 3.7233e-04\n",
      "Epoch: 7720 | training loss: 1.2470e-03 | validation loss: 3.7184e-04\n",
      "Epoch: 7730 | training loss: 1.2461e-03 | validation loss: 3.7135e-04\n",
      "Epoch: 7740 | training loss: 1.2453e-03 | validation loss: 3.7086e-04\n",
      "Epoch: 7750 | training loss: 1.2444e-03 | validation loss: 3.7037e-04\n",
      "Epoch: 7760 | training loss: 1.2435e-03 | validation loss: 3.6988e-04\n",
      "Epoch: 7770 | training loss: 1.2426e-03 | validation loss: 3.6939e-04\n",
      "Epoch: 7780 | training loss: 1.2417e-03 | validation loss: 3.6889e-04\n",
      "Epoch: 7790 | training loss: 1.2409e-03 | validation loss: 3.6840e-04\n",
      "Epoch: 7800 | training loss: 1.2400e-03 | validation loss: 3.6790e-04\n",
      "Epoch: 7810 | training loss: 1.2391e-03 | validation loss: 3.6740e-04\n",
      "Epoch: 7820 | training loss: 1.2382e-03 | validation loss: 3.6690e-04\n",
      "Epoch: 7830 | training loss: 1.2373e-03 | validation loss: 3.6640e-04\n",
      "Epoch: 7840 | training loss: 1.2364e-03 | validation loss: 3.6590e-04\n",
      "Epoch: 7850 | training loss: 1.2355e-03 | validation loss: 3.6539e-04\n",
      "Epoch: 7860 | training loss: 1.2346e-03 | validation loss: 3.6489e-04\n",
      "Epoch: 7870 | training loss: 1.2337e-03 | validation loss: 3.6438e-04\n",
      "Epoch: 7880 | training loss: 1.2328e-03 | validation loss: 3.6387e-04\n",
      "Epoch: 7890 | training loss: 1.2319e-03 | validation loss: 3.6336e-04\n",
      "Epoch: 7900 | training loss: 1.2310e-03 | validation loss: 3.6261e-04\n",
      "Epoch: 7910 | training loss: 1.2331e-03 | validation loss: 3.5830e-04\n",
      "Epoch: 7920 | training loss: 1.2305e-03 | validation loss: 3.6720e-04\n",
      "Epoch: 7930 | training loss: 1.2284e-03 | validation loss: 3.6146e-04\n",
      "Epoch: 7940 | training loss: 1.2278e-03 | validation loss: 3.5913e-04\n",
      "Epoch: 7950 | training loss: 1.2268e-03 | validation loss: 3.5917e-04\n",
      "Epoch: 7960 | training loss: 1.2258e-03 | validation loss: 3.5970e-04\n",
      "Epoch: 7970 | training loss: 1.2249e-03 | validation loss: 3.5970e-04\n",
      "Epoch: 7980 | training loss: 1.2241e-03 | validation loss: 3.5926e-04\n",
      "Epoch: 7990 | training loss: 1.2232e-03 | validation loss: 3.5870e-04\n",
      "Epoch: 8000 | training loss: 1.2223e-03 | validation loss: 3.5815e-04\n",
      "Epoch: 8010 | training loss: 1.2214e-03 | validation loss: 3.5762e-04\n",
      "Epoch: 8020 | training loss: 1.2206e-03 | validation loss: 3.5711e-04\n",
      "Epoch: 8030 | training loss: 1.2197e-03 | validation loss: 3.5662e-04\n",
      "Epoch: 8040 | training loss: 1.2188e-03 | validation loss: 3.5612e-04\n",
      "Epoch: 8050 | training loss: 1.2179e-03 | validation loss: 3.5563e-04\n",
      "Epoch: 8060 | training loss: 1.2170e-03 | validation loss: 3.5514e-04\n",
      "Epoch: 8070 | training loss: 1.2161e-03 | validation loss: 3.5464e-04\n",
      "Epoch: 8080 | training loss: 1.2153e-03 | validation loss: 3.5416e-04\n",
      "Epoch: 8090 | training loss: 1.2144e-03 | validation loss: 3.5367e-04\n",
      "Epoch: 8100 | training loss: 1.2135e-03 | validation loss: 3.5317e-04\n",
      "Epoch: 8110 | training loss: 1.2126e-03 | validation loss: 3.5268e-04\n",
      "Epoch: 8120 | training loss: 1.2117e-03 | validation loss: 3.5218e-04\n",
      "Epoch: 8130 | training loss: 1.2108e-03 | validation loss: 3.5169e-04\n",
      "Epoch: 8140 | training loss: 1.2099e-03 | validation loss: 3.5119e-04\n",
      "Epoch: 8150 | training loss: 1.2090e-03 | validation loss: 3.5069e-04\n",
      "Epoch: 8160 | training loss: 1.2081e-03 | validation loss: 3.5019e-04\n",
      "Epoch: 8170 | training loss: 1.2072e-03 | validation loss: 3.4969e-04\n",
      "Epoch: 8180 | training loss: 1.2063e-03 | validation loss: 3.4918e-04\n",
      "Epoch: 8190 | training loss: 1.2054e-03 | validation loss: 3.4868e-04\n",
      "Epoch: 8200 | training loss: 1.2044e-03 | validation loss: 3.4817e-04\n",
      "Epoch: 8210 | training loss: 1.2035e-03 | validation loss: 3.4767e-04\n",
      "Epoch: 8220 | training loss: 1.2026e-03 | validation loss: 3.4716e-04\n",
      "Epoch: 8230 | training loss: 1.2017e-03 | validation loss: 3.4665e-04\n",
      "Epoch: 8240 | training loss: 1.2008e-03 | validation loss: 3.4614e-04\n",
      "Epoch: 8250 | training loss: 1.1999e-03 | validation loss: 3.4560e-04\n",
      "Epoch: 8260 | training loss: 1.1990e-03 | validation loss: 3.4452e-04\n",
      "Epoch: 8270 | training loss: 1.2080e-03 | validation loss: 3.4113e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8280 | training loss: 1.1995e-03 | validation loss: 3.4021e-04\n",
      "Epoch: 8290 | training loss: 1.1972e-03 | validation loss: 3.4088e-04\n",
      "Epoch: 8300 | training loss: 1.1954e-03 | validation loss: 3.4268e-04\n",
      "Epoch: 8310 | training loss: 1.1946e-03 | validation loss: 3.4377e-04\n",
      "Epoch: 8320 | training loss: 1.1937e-03 | validation loss: 3.4301e-04\n",
      "Epoch: 8330 | training loss: 1.1928e-03 | validation loss: 3.4202e-04\n",
      "Epoch: 8340 | training loss: 1.1919e-03 | validation loss: 3.4124e-04\n",
      "Epoch: 8350 | training loss: 1.1910e-03 | validation loss: 3.4070e-04\n",
      "Epoch: 8360 | training loss: 1.1901e-03 | validation loss: 3.4022e-04\n",
      "Epoch: 8370 | training loss: 1.1892e-03 | validation loss: 3.3976e-04\n",
      "Epoch: 8380 | training loss: 1.1883e-03 | validation loss: 3.3930e-04\n",
      "Epoch: 8390 | training loss: 1.1875e-03 | validation loss: 3.3883e-04\n",
      "Epoch: 8400 | training loss: 1.1866e-03 | validation loss: 3.3836e-04\n",
      "Epoch: 8410 | training loss: 1.1857e-03 | validation loss: 3.3788e-04\n",
      "Epoch: 8420 | training loss: 1.1848e-03 | validation loss: 3.3740e-04\n",
      "Epoch: 8430 | training loss: 1.1839e-03 | validation loss: 3.3691e-04\n",
      "Epoch: 8440 | training loss: 1.1830e-03 | validation loss: 3.3642e-04\n",
      "Epoch: 8450 | training loss: 1.1821e-03 | validation loss: 3.3592e-04\n",
      "Epoch: 8460 | training loss: 1.1812e-03 | validation loss: 3.3543e-04\n",
      "Epoch: 8470 | training loss: 1.1803e-03 | validation loss: 3.3494e-04\n",
      "Epoch: 8480 | training loss: 1.1794e-03 | validation loss: 3.3444e-04\n",
      "Epoch: 8490 | training loss: 1.1785e-03 | validation loss: 3.3395e-04\n",
      "Epoch: 8500 | training loss: 1.1776e-03 | validation loss: 3.3345e-04\n",
      "Epoch: 8510 | training loss: 1.1767e-03 | validation loss: 3.3295e-04\n",
      "Epoch: 8520 | training loss: 1.1757e-03 | validation loss: 3.3245e-04\n",
      "Epoch: 8530 | training loss: 1.1748e-03 | validation loss: 3.3195e-04\n",
      "Epoch: 8540 | training loss: 1.1739e-03 | validation loss: 3.3145e-04\n",
      "Epoch: 8550 | training loss: 1.1730e-03 | validation loss: 3.3095e-04\n",
      "Epoch: 8560 | training loss: 1.1721e-03 | validation loss: 3.3044e-04\n",
      "Epoch: 8570 | training loss: 1.1711e-03 | validation loss: 3.2994e-04\n",
      "Epoch: 8580 | training loss: 1.1702e-03 | validation loss: 3.2943e-04\n",
      "Epoch: 8590 | training loss: 1.1693e-03 | validation loss: 3.2893e-04\n",
      "Epoch: 8600 | training loss: 1.1684e-03 | validation loss: 3.2842e-04\n",
      "Epoch: 8610 | training loss: 1.1674e-03 | validation loss: 3.2790e-04\n",
      "Epoch: 8620 | training loss: 1.1665e-03 | validation loss: 3.2724e-04\n",
      "Epoch: 8630 | training loss: 1.1673e-03 | validation loss: 3.2391e-04\n",
      "Epoch: 8640 | training loss: 1.1708e-03 | validation loss: 3.3981e-04\n",
      "Epoch: 8650 | training loss: 1.1649e-03 | validation loss: 3.3098e-04\n",
      "Epoch: 8660 | training loss: 1.1630e-03 | validation loss: 3.2443e-04\n",
      "Epoch: 8670 | training loss: 1.1623e-03 | validation loss: 3.2328e-04\n",
      "Epoch: 8680 | training loss: 1.1612e-03 | validation loss: 3.2427e-04\n",
      "Epoch: 8690 | training loss: 1.1603e-03 | validation loss: 3.2448e-04\n",
      "Epoch: 8700 | training loss: 1.1594e-03 | validation loss: 3.2387e-04\n",
      "Epoch: 8710 | training loss: 1.1586e-03 | validation loss: 3.2321e-04\n",
      "Epoch: 8720 | training loss: 1.1577e-03 | validation loss: 3.2265e-04\n",
      "Epoch: 8730 | training loss: 1.1568e-03 | validation loss: 3.2215e-04\n",
      "Epoch: 8740 | training loss: 1.1559e-03 | validation loss: 3.2166e-04\n",
      "Epoch: 8750 | training loss: 1.1550e-03 | validation loss: 3.2119e-04\n",
      "Epoch: 8760 | training loss: 1.1541e-03 | validation loss: 3.2072e-04\n",
      "Epoch: 8770 | training loss: 1.1533e-03 | validation loss: 3.2025e-04\n",
      "Epoch: 8780 | training loss: 1.1524e-03 | validation loss: 3.1978e-04\n",
      "Epoch: 8790 | training loss: 1.1515e-03 | validation loss: 3.1930e-04\n",
      "Epoch: 8800 | training loss: 1.1506e-03 | validation loss: 3.1882e-04\n",
      "Epoch: 8810 | training loss: 1.1497e-03 | validation loss: 3.1834e-04\n",
      "Epoch: 8820 | training loss: 1.1488e-03 | validation loss: 3.1785e-04\n",
      "Epoch: 8830 | training loss: 1.1479e-03 | validation loss: 3.1737e-04\n",
      "Epoch: 8840 | training loss: 1.1470e-03 | validation loss: 3.1689e-04\n",
      "Epoch: 8850 | training loss: 1.1461e-03 | validation loss: 3.1640e-04\n",
      "Epoch: 8860 | training loss: 1.1452e-03 | validation loss: 3.1591e-04\n",
      "Epoch: 8870 | training loss: 1.1443e-03 | validation loss: 3.1543e-04\n",
      "Epoch: 8880 | training loss: 1.1434e-03 | validation loss: 3.1494e-04\n",
      "Epoch: 8890 | training loss: 1.1425e-03 | validation loss: 3.1445e-04\n",
      "Epoch: 8900 | training loss: 1.1416e-03 | validation loss: 3.1396e-04\n",
      "Epoch: 8910 | training loss: 1.1406e-03 | validation loss: 3.1346e-04\n",
      "Epoch: 8920 | training loss: 1.1397e-03 | validation loss: 3.1297e-04\n",
      "Epoch: 8930 | training loss: 1.1388e-03 | validation loss: 3.1248e-04\n",
      "Epoch: 8940 | training loss: 1.1379e-03 | validation loss: 3.1198e-04\n",
      "Epoch: 8950 | training loss: 1.1370e-03 | validation loss: 3.1149e-04\n",
      "Epoch: 8960 | training loss: 1.1361e-03 | validation loss: 3.1099e-04\n",
      "Epoch: 8970 | training loss: 1.1351e-03 | validation loss: 3.1049e-04\n",
      "Epoch: 8980 | training loss: 1.1342e-03 | validation loss: 3.1000e-04\n",
      "Epoch: 8990 | training loss: 1.1333e-03 | validation loss: 3.0950e-04\n",
      "Epoch: 9000 | training loss: 1.1324e-03 | validation loss: 3.0901e-04\n",
      "Epoch: 9010 | training loss: 1.1315e-03 | validation loss: 3.0884e-04\n",
      "Epoch: 9020 | training loss: 1.1464e-03 | validation loss: 3.3071e-04\n",
      "Epoch: 9030 | training loss: 1.1322e-03 | validation loss: 3.1438e-04\n",
      "Epoch: 9040 | training loss: 1.1296e-03 | validation loss: 3.1107e-04\n",
      "Epoch: 9050 | training loss: 1.1281e-03 | validation loss: 3.0546e-04\n",
      "Epoch: 9060 | training loss: 1.1272e-03 | validation loss: 3.0531e-04\n",
      "Epoch: 9070 | training loss: 1.1263e-03 | validation loss: 3.0583e-04\n",
      "Epoch: 9080 | training loss: 1.1255e-03 | validation loss: 3.0559e-04\n",
      "Epoch: 9090 | training loss: 1.1246e-03 | validation loss: 3.0506e-04\n",
      "Epoch: 9100 | training loss: 1.1238e-03 | validation loss: 3.0437e-04\n",
      "Epoch: 9110 | training loss: 1.1229e-03 | validation loss: 3.0390e-04\n",
      "Epoch: 9120 | training loss: 1.1221e-03 | validation loss: 3.0346e-04\n",
      "Epoch: 9130 | training loss: 1.1212e-03 | validation loss: 3.0302e-04\n",
      "Epoch: 9140 | training loss: 1.1204e-03 | validation loss: 3.0260e-04\n",
      "Epoch: 9150 | training loss: 1.1195e-03 | validation loss: 3.0215e-04\n",
      "Epoch: 9160 | training loss: 1.1187e-03 | validation loss: 3.0171e-04\n",
      "Epoch: 9170 | training loss: 1.1178e-03 | validation loss: 3.0125e-04\n",
      "Epoch: 9180 | training loss: 1.1169e-03 | validation loss: 3.0080e-04\n",
      "Epoch: 9190 | training loss: 1.1161e-03 | validation loss: 3.0035e-04\n",
      "Epoch: 9200 | training loss: 1.1152e-03 | validation loss: 2.9990e-04\n",
      "Epoch: 9210 | training loss: 1.1144e-03 | validation loss: 2.9944e-04\n",
      "Epoch: 9220 | training loss: 1.1135e-03 | validation loss: 2.9899e-04\n",
      "Epoch: 9230 | training loss: 1.1126e-03 | validation loss: 2.9853e-04\n",
      "Epoch: 9240 | training loss: 1.1118e-03 | validation loss: 2.9807e-04\n",
      "Epoch: 9250 | training loss: 1.1109e-03 | validation loss: 2.9761e-04\n",
      "Epoch: 9260 | training loss: 1.1100e-03 | validation loss: 2.9715e-04\n",
      "Epoch: 9270 | training loss: 1.1092e-03 | validation loss: 2.9669e-04\n",
      "Epoch: 9280 | training loss: 1.1083e-03 | validation loss: 2.9623e-04\n",
      "Epoch: 9290 | training loss: 1.1074e-03 | validation loss: 2.9577e-04\n",
      "Epoch: 9300 | training loss: 1.1065e-03 | validation loss: 2.9530e-04\n",
      "Epoch: 9310 | training loss: 1.1057e-03 | validation loss: 2.9484e-04\n",
      "Epoch: 9320 | training loss: 1.1048e-03 | validation loss: 2.9437e-04\n",
      "Epoch: 9330 | training loss: 1.1039e-03 | validation loss: 2.9391e-04\n",
      "Epoch: 9340 | training loss: 1.1030e-03 | validation loss: 2.9344e-04\n",
      "Epoch: 9350 | training loss: 1.1021e-03 | validation loss: 2.9297e-04\n",
      "Epoch: 9360 | training loss: 1.1012e-03 | validation loss: 2.9250e-04\n",
      "Epoch: 9370 | training loss: 1.1004e-03 | validation loss: 2.9203e-04\n",
      "Epoch: 9380 | training loss: 1.0995e-03 | validation loss: 2.9156e-04\n",
      "Epoch: 9390 | training loss: 1.0986e-03 | validation loss: 2.9108e-04\n",
      "Epoch: 9400 | training loss: 1.0977e-03 | validation loss: 2.9051e-04\n",
      "Epoch: 9410 | training loss: 1.0977e-03 | validation loss: 2.8791e-04\n",
      "Epoch: 9420 | training loss: 1.1003e-03 | validation loss: 2.9933e-04\n",
      "Epoch: 9430 | training loss: 1.0981e-03 | validation loss: 2.9689e-04\n",
      "Epoch: 9440 | training loss: 1.0943e-03 | validation loss: 2.8962e-04\n",
      "Epoch: 9450 | training loss: 1.0938e-03 | validation loss: 2.8692e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9460 | training loss: 1.0927e-03 | validation loss: 2.8740e-04\n",
      "Epoch: 9470 | training loss: 1.0918e-03 | validation loss: 2.8799e-04\n",
      "Epoch: 9480 | training loss: 1.0910e-03 | validation loss: 2.8750e-04\n",
      "Epoch: 9490 | training loss: 1.0901e-03 | validation loss: 2.8674e-04\n",
      "Epoch: 9500 | training loss: 1.0893e-03 | validation loss: 2.8618e-04\n",
      "Epoch: 9510 | training loss: 1.0885e-03 | validation loss: 2.8575e-04\n",
      "Epoch: 9520 | training loss: 1.0876e-03 | validation loss: 2.8536e-04\n",
      "Epoch: 9530 | training loss: 1.0868e-03 | validation loss: 2.8496e-04\n",
      "Epoch: 9540 | training loss: 1.0860e-03 | validation loss: 2.8454e-04\n",
      "Epoch: 9550 | training loss: 1.0851e-03 | validation loss: 2.8411e-04\n",
      "Epoch: 9560 | training loss: 1.0843e-03 | validation loss: 2.8368e-04\n",
      "Epoch: 9570 | training loss: 1.0835e-03 | validation loss: 2.8325e-04\n",
      "Epoch: 9580 | training loss: 1.0826e-03 | validation loss: 2.8281e-04\n",
      "Epoch: 9590 | training loss: 1.0818e-03 | validation loss: 2.8238e-04\n",
      "Epoch: 9600 | training loss: 1.0809e-03 | validation loss: 2.8194e-04\n",
      "Epoch: 9610 | training loss: 1.0801e-03 | validation loss: 2.8150e-04\n",
      "Epoch: 9620 | training loss: 1.0792e-03 | validation loss: 2.8107e-04\n",
      "Epoch: 9630 | training loss: 1.0784e-03 | validation loss: 2.8063e-04\n",
      "Epoch: 9640 | training loss: 1.0775e-03 | validation loss: 2.8019e-04\n",
      "Epoch: 9650 | training loss: 1.0767e-03 | validation loss: 2.7974e-04\n",
      "Epoch: 9660 | training loss: 1.0758e-03 | validation loss: 2.7930e-04\n",
      "Epoch: 9670 | training loss: 1.0750e-03 | validation loss: 2.7886e-04\n",
      "Epoch: 9680 | training loss: 1.0741e-03 | validation loss: 2.7841e-04\n",
      "Epoch: 9690 | training loss: 1.0733e-03 | validation loss: 2.7797e-04\n",
      "Epoch: 9700 | training loss: 1.0724e-03 | validation loss: 2.7752e-04\n",
      "Epoch: 9710 | training loss: 1.0715e-03 | validation loss: 2.7708e-04\n",
      "Epoch: 9720 | training loss: 1.0707e-03 | validation loss: 2.7663e-04\n",
      "Epoch: 9730 | training loss: 1.0698e-03 | validation loss: 2.7618e-04\n",
      "Epoch: 9740 | training loss: 1.0690e-03 | validation loss: 2.7573e-04\n",
      "Epoch: 9750 | training loss: 1.0681e-03 | validation loss: 2.7528e-04\n",
      "Epoch: 9760 | training loss: 1.0672e-03 | validation loss: 2.7483e-04\n",
      "Epoch: 9770 | training loss: 1.0663e-03 | validation loss: 2.7438e-04\n",
      "Epoch: 9780 | training loss: 1.0655e-03 | validation loss: 2.7396e-04\n",
      "Epoch: 9790 | training loss: 1.0654e-03 | validation loss: 2.7478e-04\n",
      "Epoch: 9800 | training loss: 1.0689e-03 | validation loss: 2.8193e-04\n",
      "Epoch: 9810 | training loss: 1.0638e-03 | validation loss: 2.7617e-04\n",
      "Epoch: 9820 | training loss: 1.0627e-03 | validation loss: 2.7298e-04\n",
      "Epoch: 9830 | training loss: 1.0616e-03 | validation loss: 2.7296e-04\n",
      "Epoch: 9840 | training loss: 1.0606e-03 | validation loss: 2.7093e-04\n",
      "Epoch: 9850 | training loss: 1.0598e-03 | validation loss: 2.7071e-04\n",
      "Epoch: 9860 | training loss: 1.0590e-03 | validation loss: 2.7059e-04\n",
      "Epoch: 9870 | training loss: 1.0582e-03 | validation loss: 2.7018e-04\n",
      "Epoch: 9880 | training loss: 1.0574e-03 | validation loss: 2.6985e-04\n",
      "Epoch: 9890 | training loss: 1.0565e-03 | validation loss: 2.6937e-04\n",
      "Epoch: 9900 | training loss: 1.0557e-03 | validation loss: 2.6895e-04\n",
      "Epoch: 9910 | training loss: 1.0549e-03 | validation loss: 2.6856e-04\n",
      "Epoch: 9920 | training loss: 1.0541e-03 | validation loss: 2.6814e-04\n",
      "Epoch: 9930 | training loss: 1.0533e-03 | validation loss: 2.6775e-04\n",
      "Epoch: 9940 | training loss: 1.0525e-03 | validation loss: 2.6732e-04\n",
      "Epoch: 9950 | training loss: 1.0517e-03 | validation loss: 2.6691e-04\n",
      "Epoch: 9960 | training loss: 1.0509e-03 | validation loss: 2.6650e-04\n",
      "Epoch: 9970 | training loss: 1.0501e-03 | validation loss: 2.6608e-04\n",
      "Epoch: 9980 | training loss: 1.0492e-03 | validation loss: 2.6567e-04\n",
      "Epoch: 9990 | training loss: 1.0484e-03 | validation loss: 2.6525e-04\n",
      "Epoch: 10000 | training loss: 1.0476e-03 | validation loss: 2.6484e-04\n",
      "Epoch: 10010 | training loss: 1.0468e-03 | validation loss: 2.6443e-04\n",
      "Epoch: 10020 | training loss: 1.0460e-03 | validation loss: 2.6415e-04\n",
      "Epoch: 10030 | training loss: 1.0456e-03 | validation loss: 2.6582e-04\n",
      "Epoch: 10040 | training loss: 1.0469e-03 | validation loss: 2.6944e-04\n",
      "Epoch: 10050 | training loss: 1.0458e-03 | validation loss: 2.6855e-04\n",
      "Epoch: 10060 | training loss: 1.0436e-03 | validation loss: 2.6546e-04\n",
      "Epoch: 10070 | training loss: 1.0423e-03 | validation loss: 2.6369e-04\n",
      "Epoch: 10080 | training loss: 1.0413e-03 | validation loss: 2.6252e-04\n",
      "Epoch: 10090 | training loss: 1.0405e-03 | validation loss: 2.6164e-04\n",
      "Epoch: 10100 | training loss: 1.0397e-03 | validation loss: 2.6094e-04\n",
      "Epoch: 10110 | training loss: 1.0389e-03 | validation loss: 2.6037e-04\n",
      "Epoch: 10120 | training loss: 1.0381e-03 | validation loss: 2.5994e-04\n",
      "Epoch: 10130 | training loss: 1.0373e-03 | validation loss: 2.5961e-04\n",
      "Epoch: 10140 | training loss: 1.0365e-03 | validation loss: 2.5929e-04\n",
      "Epoch: 10150 | training loss: 1.0357e-03 | validation loss: 2.5889e-04\n",
      "Epoch: 10160 | training loss: 1.0350e-03 | validation loss: 2.5847e-04\n",
      "Epoch: 10170 | training loss: 1.0342e-03 | validation loss: 2.5808e-04\n",
      "Epoch: 10180 | training loss: 1.0334e-03 | validation loss: 2.5770e-04\n",
      "Epoch: 10190 | training loss: 1.0326e-03 | validation loss: 2.5729e-04\n",
      "Epoch: 10200 | training loss: 1.0318e-03 | validation loss: 2.5690e-04\n",
      "Epoch: 10210 | training loss: 1.0310e-03 | validation loss: 2.5650e-04\n",
      "Epoch: 10220 | training loss: 1.0302e-03 | validation loss: 2.5610e-04\n",
      "Epoch: 10230 | training loss: 1.0294e-03 | validation loss: 2.5570e-04\n",
      "Epoch: 10240 | training loss: 1.0286e-03 | validation loss: 2.5530e-04\n",
      "Epoch: 10250 | training loss: 1.0278e-03 | validation loss: 2.5490e-04\n",
      "Epoch: 10260 | training loss: 1.0270e-03 | validation loss: 2.5450e-04\n",
      "Epoch: 10270 | training loss: 1.0262e-03 | validation loss: 2.5410e-04\n",
      "Epoch: 10280 | training loss: 1.0254e-03 | validation loss: 2.5370e-04\n",
      "Epoch: 10290 | training loss: 1.0246e-03 | validation loss: 2.5335e-04\n",
      "Epoch: 10300 | training loss: 1.0239e-03 | validation loss: 2.5382e-04\n",
      "Epoch: 10310 | training loss: 1.0350e-03 | validation loss: 2.6987e-04\n",
      "Epoch: 10320 | training loss: 1.0243e-03 | validation loss: 2.5657e-04\n",
      "Epoch: 10330 | training loss: 1.0223e-03 | validation loss: 2.5395e-04\n",
      "Epoch: 10340 | training loss: 1.0211e-03 | validation loss: 2.5252e-04\n",
      "Epoch: 10350 | training loss: 1.0201e-03 | validation loss: 2.5150e-04\n",
      "Epoch: 10360 | training loss: 1.0193e-03 | validation loss: 2.5079e-04\n",
      "Epoch: 10370 | training loss: 1.0185e-03 | validation loss: 2.5028e-04\n",
      "Epoch: 10380 | training loss: 1.0177e-03 | validation loss: 2.4988e-04\n",
      "Epoch: 10390 | training loss: 1.0170e-03 | validation loss: 2.4953e-04\n",
      "Epoch: 10400 | training loss: 1.0162e-03 | validation loss: 2.4919e-04\n",
      "Epoch: 10410 | training loss: 1.0154e-03 | validation loss: 2.4881e-04\n",
      "Epoch: 10420 | training loss: 1.0147e-03 | validation loss: 2.4841e-04\n",
      "Epoch: 10430 | training loss: 1.0139e-03 | validation loss: 2.4802e-04\n",
      "Epoch: 10440 | training loss: 1.0132e-03 | validation loss: 2.4766e-04\n",
      "Epoch: 10450 | training loss: 1.0124e-03 | validation loss: 2.4729e-04\n",
      "Epoch: 10460 | training loss: 1.0116e-03 | validation loss: 2.4691e-04\n",
      "Epoch: 10470 | training loss: 1.0109e-03 | validation loss: 2.4654e-04\n",
      "Epoch: 10480 | training loss: 1.0101e-03 | validation loss: 2.4616e-04\n",
      "Epoch: 10490 | training loss: 1.0093e-03 | validation loss: 2.4578e-04\n",
      "Epoch: 10500 | training loss: 1.0086e-03 | validation loss: 2.4540e-04\n",
      "Epoch: 10510 | training loss: 1.0078e-03 | validation loss: 2.4502e-04\n",
      "Epoch: 10520 | training loss: 1.0070e-03 | validation loss: 2.4464e-04\n",
      "Epoch: 10530 | training loss: 1.0062e-03 | validation loss: 2.4426e-04\n",
      "Epoch: 10540 | training loss: 1.0055e-03 | validation loss: 2.4388e-04\n",
      "Epoch: 10550 | training loss: 1.0047e-03 | validation loss: 2.4350e-04\n",
      "Epoch: 10560 | training loss: 1.0039e-03 | validation loss: 2.4311e-04\n",
      "Epoch: 10570 | training loss: 1.0031e-03 | validation loss: 2.4272e-04\n",
      "Epoch: 10580 | training loss: 1.0024e-03 | validation loss: 2.4221e-04\n",
      "Epoch: 10590 | training loss: 1.0024e-03 | validation loss: 2.4024e-04\n",
      "Epoch: 10600 | training loss: 1.0041e-03 | validation loss: 2.4351e-04\n",
      "Epoch: 10610 | training loss: 1.0010e-03 | validation loss: 2.4457e-04\n",
      "Epoch: 10620 | training loss: 9.9979e-04 | validation loss: 2.4172e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10630 | training loss: 9.9868e-04 | validation loss: 2.4136e-04\n",
      "Epoch: 10640 | training loss: 9.9789e-04 | validation loss: 2.3994e-04\n",
      "Epoch: 10650 | training loss: 9.9716e-04 | validation loss: 2.3957e-04\n",
      "Epoch: 10660 | training loss: 9.9643e-04 | validation loss: 2.3948e-04\n",
      "Epoch: 10670 | training loss: 9.9569e-04 | validation loss: 2.3900e-04\n",
      "Epoch: 10680 | training loss: 9.9495e-04 | validation loss: 2.3860e-04\n",
      "Epoch: 10690 | training loss: 9.9422e-04 | validation loss: 2.3815e-04\n",
      "Epoch: 10700 | training loss: 9.9366e-04 | validation loss: 2.3720e-04\n",
      "Epoch: 10710 | training loss: 9.9673e-04 | validation loss: 2.3622e-04\n",
      "Epoch: 10720 | training loss: 9.9353e-04 | validation loss: 2.4124e-04\n",
      "Epoch: 10730 | training loss: 9.9169e-04 | validation loss: 2.3589e-04\n",
      "Epoch: 10740 | training loss: 9.9059e-04 | validation loss: 2.3684e-04\n",
      "Epoch: 10750 | training loss: 9.8988e-04 | validation loss: 2.3658e-04\n",
      "Epoch: 10760 | training loss: 9.8917e-04 | validation loss: 2.3570e-04\n",
      "Epoch: 10770 | training loss: 9.8844e-04 | validation loss: 2.3579e-04\n",
      "Epoch: 10780 | training loss: 9.8771e-04 | validation loss: 2.3519e-04\n",
      "Epoch: 10790 | training loss: 9.8699e-04 | validation loss: 2.3490e-04\n",
      "Epoch: 10800 | training loss: 9.8627e-04 | validation loss: 2.3464e-04\n",
      "Epoch: 10810 | training loss: 9.8555e-04 | validation loss: 2.3423e-04\n",
      "Epoch: 10820 | training loss: 9.8482e-04 | validation loss: 2.3385e-04\n",
      "Epoch: 10830 | training loss: 9.8410e-04 | validation loss: 2.3344e-04\n",
      "Epoch: 10840 | training loss: 9.8340e-04 | validation loss: 2.3279e-04\n",
      "Epoch: 10850 | training loss: 9.8468e-04 | validation loss: 2.3132e-04\n",
      "Epoch: 10860 | training loss: 9.8229e-04 | validation loss: 2.3396e-04\n",
      "Epoch: 10870 | training loss: 9.8232e-04 | validation loss: 2.3062e-04\n",
      "Epoch: 10880 | training loss: 9.8054e-04 | validation loss: 2.3154e-04\n",
      "Epoch: 10890 | training loss: 9.7997e-04 | validation loss: 2.3239e-04\n",
      "Epoch: 10900 | training loss: 9.7913e-04 | validation loss: 2.3108e-04\n",
      "Epoch: 10910 | training loss: 9.7844e-04 | validation loss: 2.3059e-04\n",
      "Epoch: 10920 | training loss: 9.7773e-04 | validation loss: 2.3066e-04\n",
      "Epoch: 10930 | training loss: 9.7702e-04 | validation loss: 2.3006e-04\n",
      "Epoch: 10940 | training loss: 9.7632e-04 | validation loss: 2.2984e-04\n",
      "Epoch: 10950 | training loss: 9.7561e-04 | validation loss: 2.2944e-04\n",
      "Epoch: 10960 | training loss: 9.7491e-04 | validation loss: 2.2915e-04\n",
      "Epoch: 10970 | training loss: 9.7420e-04 | validation loss: 2.2878e-04\n",
      "Epoch: 10980 | training loss: 9.7349e-04 | validation loss: 2.2845e-04\n",
      "Epoch: 10990 | training loss: 9.7278e-04 | validation loss: 2.2812e-04\n",
      "Epoch: 11000 | training loss: 9.7207e-04 | validation loss: 2.2778e-04\n",
      "Epoch: 11010 | training loss: 9.7136e-04 | validation loss: 2.2748e-04\n",
      "Epoch: 11020 | training loss: 9.7067e-04 | validation loss: 2.2742e-04\n",
      "Epoch: 11030 | training loss: 9.7229e-04 | validation loss: 2.3138e-04\n",
      "Epoch: 11040 | training loss: 9.7048e-04 | validation loss: 2.2567e-04\n",
      "Epoch: 11050 | training loss: 9.6915e-04 | validation loss: 2.2849e-04\n",
      "Epoch: 11060 | training loss: 9.6825e-04 | validation loss: 2.2671e-04\n",
      "Epoch: 11070 | training loss: 9.6728e-04 | validation loss: 2.2509e-04\n",
      "Epoch: 11080 | training loss: 9.6652e-04 | validation loss: 2.2500e-04\n",
      "Epoch: 11090 | training loss: 9.6585e-04 | validation loss: 2.2496e-04\n",
      "Epoch: 11100 | training loss: 9.6515e-04 | validation loss: 2.2441e-04\n",
      "Epoch: 11110 | training loss: 9.6447e-04 | validation loss: 2.2417e-04\n",
      "Epoch: 11120 | training loss: 9.6379e-04 | validation loss: 2.2385e-04\n",
      "Epoch: 11130 | training loss: 9.6310e-04 | validation loss: 2.2350e-04\n",
      "Epoch: 11140 | training loss: 9.6242e-04 | validation loss: 2.2319e-04\n",
      "Epoch: 11150 | training loss: 9.6173e-04 | validation loss: 2.2286e-04\n",
      "Epoch: 11160 | training loss: 9.6104e-04 | validation loss: 2.2253e-04\n",
      "Epoch: 11170 | training loss: 9.6035e-04 | validation loss: 2.2221e-04\n",
      "Epoch: 11180 | training loss: 9.5966e-04 | validation loss: 2.2188e-04\n",
      "Epoch: 11190 | training loss: 9.5897e-04 | validation loss: 2.2155e-04\n",
      "Epoch: 11200 | training loss: 9.5828e-04 | validation loss: 2.2123e-04\n",
      "Epoch: 11210 | training loss: 9.5759e-04 | validation loss: 2.2098e-04\n",
      "Epoch: 11220 | training loss: 9.5699e-04 | validation loss: 2.2148e-04\n",
      "Epoch: 11230 | training loss: 9.6183e-04 | validation loss: 2.3085e-04\n",
      "Epoch: 11240 | training loss: 9.5569e-04 | validation loss: 2.1968e-04\n",
      "Epoch: 11250 | training loss: 9.5503e-04 | validation loss: 2.2029e-04\n",
      "Epoch: 11260 | training loss: 9.5429e-04 | validation loss: 2.1903e-04\n",
      "Epoch: 11270 | training loss: 9.5360e-04 | validation loss: 2.1937e-04\n",
      "Epoch: 11280 | training loss: 9.5294e-04 | validation loss: 2.1870e-04\n",
      "Epoch: 11290 | training loss: 9.5228e-04 | validation loss: 2.1850e-04\n",
      "Epoch: 11300 | training loss: 9.5163e-04 | validation loss: 2.1801e-04\n",
      "Epoch: 11310 | training loss: 9.5097e-04 | validation loss: 2.1776e-04\n",
      "Epoch: 11320 | training loss: 9.5032e-04 | validation loss: 2.1744e-04\n",
      "Epoch: 11330 | training loss: 9.4966e-04 | validation loss: 2.1712e-04\n",
      "Epoch: 11340 | training loss: 9.4900e-04 | validation loss: 2.1682e-04\n",
      "Epoch: 11350 | training loss: 9.4835e-04 | validation loss: 2.1646e-04\n",
      "Epoch: 11360 | training loss: 9.4778e-04 | validation loss: 2.1577e-04\n",
      "Epoch: 11370 | training loss: 9.5287e-04 | validation loss: 2.1607e-04\n",
      "Epoch: 11380 | training loss: 9.4909e-04 | validation loss: 2.2087e-04\n",
      "Epoch: 11390 | training loss: 9.4592e-04 | validation loss: 2.1620e-04\n",
      "Epoch: 11400 | training loss: 9.4532e-04 | validation loss: 2.1434e-04\n",
      "Epoch: 11410 | training loss: 9.4458e-04 | validation loss: 2.1423e-04\n",
      "Epoch: 11420 | training loss: 9.4389e-04 | validation loss: 2.1464e-04\n",
      "Epoch: 11430 | training loss: 9.4325e-04 | validation loss: 2.1428e-04\n",
      "Epoch: 11440 | training loss: 9.4261e-04 | validation loss: 2.1370e-04\n",
      "Epoch: 11450 | training loss: 9.4198e-04 | validation loss: 2.1357e-04\n",
      "Epoch: 11460 | training loss: 9.4134e-04 | validation loss: 2.1326e-04\n",
      "Epoch: 11470 | training loss: 9.4071e-04 | validation loss: 2.1293e-04\n",
      "Epoch: 11480 | training loss: 9.4007e-04 | validation loss: 2.1266e-04\n",
      "Epoch: 11490 | training loss: 9.3943e-04 | validation loss: 2.1234e-04\n",
      "Epoch: 11500 | training loss: 9.3879e-04 | validation loss: 2.1204e-04\n",
      "Epoch: 11510 | training loss: 9.3816e-04 | validation loss: 2.1175e-04\n",
      "Epoch: 11520 | training loss: 9.3752e-04 | validation loss: 2.1144e-04\n",
      "Epoch: 11530 | training loss: 9.3687e-04 | validation loss: 2.1114e-04\n",
      "Epoch: 11540 | training loss: 9.3623e-04 | validation loss: 2.1084e-04\n",
      "Epoch: 11550 | training loss: 9.3559e-04 | validation loss: 2.1059e-04\n",
      "Epoch: 11560 | training loss: 9.3508e-04 | validation loss: 2.1090e-04\n",
      "Epoch: 11570 | training loss: 9.4374e-04 | validation loss: 2.2199e-04\n",
      "Epoch: 11580 | training loss: 9.3428e-04 | validation loss: 2.0809e-04\n",
      "Epoch: 11590 | training loss: 9.3371e-04 | validation loss: 2.0829e-04\n",
      "Epoch: 11600 | training loss: 9.3270e-04 | validation loss: 2.0906e-04\n",
      "Epoch: 11610 | training loss: 9.3199e-04 | validation loss: 2.0931e-04\n",
      "Epoch: 11620 | training loss: 9.3129e-04 | validation loss: 2.0874e-04\n",
      "Epoch: 11630 | training loss: 9.3066e-04 | validation loss: 2.0811e-04\n",
      "Epoch: 11640 | training loss: 9.3005e-04 | validation loss: 2.0786e-04\n",
      "Epoch: 11650 | training loss: 9.2944e-04 | validation loss: 2.0769e-04\n",
      "Epoch: 11660 | training loss: 9.2883e-04 | validation loss: 2.0734e-04\n",
      "Epoch: 11670 | training loss: 9.2822e-04 | validation loss: 2.0707e-04\n",
      "Epoch: 11680 | training loss: 9.2761e-04 | validation loss: 2.0678e-04\n",
      "Epoch: 11690 | training loss: 9.2700e-04 | validation loss: 2.0648e-04\n",
      "Epoch: 11700 | training loss: 9.2639e-04 | validation loss: 2.0620e-04\n",
      "Epoch: 11710 | training loss: 9.2577e-04 | validation loss: 2.0591e-04\n",
      "Epoch: 11720 | training loss: 9.2516e-04 | validation loss: 2.0562e-04\n",
      "Epoch: 11730 | training loss: 9.2454e-04 | validation loss: 2.0532e-04\n",
      "Epoch: 11740 | training loss: 9.2392e-04 | validation loss: 2.0503e-04\n",
      "Epoch: 11750 | training loss: 9.2330e-04 | validation loss: 2.0474e-04\n",
      "Epoch: 11760 | training loss: 9.2269e-04 | validation loss: 2.0445e-04\n",
      "Epoch: 11770 | training loss: 9.2207e-04 | validation loss: 2.0421e-04\n",
      "Epoch: 11780 | training loss: 9.2151e-04 | validation loss: 2.0455e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11790 | training loss: 9.2804e-04 | validation loss: 2.1540e-04\n",
      "Epoch: 11800 | training loss: 9.2128e-04 | validation loss: 2.0237e-04\n",
      "Epoch: 11810 | training loss: 9.1975e-04 | validation loss: 2.0289e-04\n",
      "Epoch: 11820 | training loss: 9.1915e-04 | validation loss: 2.0330e-04\n",
      "Epoch: 11830 | training loss: 9.1857e-04 | validation loss: 2.0285e-04\n",
      "Epoch: 11840 | training loss: 9.1797e-04 | validation loss: 2.0255e-04\n",
      "Epoch: 11850 | training loss: 9.1738e-04 | validation loss: 2.0229e-04\n",
      "Epoch: 11860 | training loss: 9.1680e-04 | validation loss: 2.0178e-04\n",
      "Epoch: 11870 | training loss: 9.1622e-04 | validation loss: 2.0151e-04\n",
      "Epoch: 11880 | training loss: 9.1564e-04 | validation loss: 2.0116e-04\n",
      "Epoch: 11890 | training loss: 9.1506e-04 | validation loss: 2.0088e-04\n",
      "Epoch: 11900 | training loss: 9.1448e-04 | validation loss: 2.0057e-04\n",
      "Epoch: 11910 | training loss: 9.1390e-04 | validation loss: 2.0029e-04\n",
      "Epoch: 11920 | training loss: 9.1332e-04 | validation loss: 2.0002e-04\n",
      "Epoch: 11930 | training loss: 9.1274e-04 | validation loss: 1.9975e-04\n",
      "Epoch: 11940 | training loss: 9.1216e-04 | validation loss: 1.9949e-04\n",
      "Epoch: 11950 | training loss: 9.1158e-04 | validation loss: 1.9929e-04\n",
      "Epoch: 11960 | training loss: 9.1147e-04 | validation loss: 2.0008e-04\n",
      "Epoch: 11970 | training loss: 9.1465e-04 | validation loss: 2.0504e-04\n",
      "Epoch: 11980 | training loss: 9.1052e-04 | validation loss: 1.9993e-04\n",
      "Epoch: 11990 | training loss: 9.0950e-04 | validation loss: 1.9732e-04\n",
      "Epoch: 12000 | training loss: 9.0900e-04 | validation loss: 1.9705e-04\n",
      "Epoch: 12010 | training loss: 9.0820e-04 | validation loss: 1.9738e-04\n",
      "Epoch: 12020 | training loss: 9.0767e-04 | validation loss: 1.9755e-04\n",
      "Epoch: 12030 | training loss: 9.0708e-04 | validation loss: 1.9708e-04\n",
      "Epoch: 12040 | training loss: 9.0653e-04 | validation loss: 1.9673e-04\n",
      "Epoch: 12050 | training loss: 9.0597e-04 | validation loss: 1.9662e-04\n",
      "Epoch: 12060 | training loss: 9.0541e-04 | validation loss: 1.9629e-04\n",
      "Epoch: 12070 | training loss: 9.0485e-04 | validation loss: 1.9601e-04\n",
      "Epoch: 12080 | training loss: 9.0429e-04 | validation loss: 1.9576e-04\n",
      "Epoch: 12090 | training loss: 9.0372e-04 | validation loss: 1.9549e-04\n",
      "Epoch: 12100 | training loss: 9.0316e-04 | validation loss: 1.9522e-04\n",
      "Epoch: 12110 | training loss: 9.0260e-04 | validation loss: 1.9496e-04\n",
      "Epoch: 12120 | training loss: 9.0203e-04 | validation loss: 1.9469e-04\n",
      "Epoch: 12130 | training loss: 9.0147e-04 | validation loss: 1.9442e-04\n",
      "Epoch: 12140 | training loss: 9.0090e-04 | validation loss: 1.9415e-04\n",
      "Epoch: 12150 | training loss: 9.0034e-04 | validation loss: 1.9387e-04\n",
      "Epoch: 12160 | training loss: 8.9977e-04 | validation loss: 1.9357e-04\n",
      "Epoch: 12170 | training loss: 8.9930e-04 | validation loss: 1.9298e-04\n",
      "Epoch: 12180 | training loss: 9.1110e-04 | validation loss: 1.9711e-04\n",
      "Epoch: 12190 | training loss: 8.9881e-04 | validation loss: 1.9452e-04\n",
      "Epoch: 12200 | training loss: 8.9815e-04 | validation loss: 1.9434e-04\n",
      "Epoch: 12210 | training loss: 8.9740e-04 | validation loss: 1.9347e-04\n",
      "Epoch: 12220 | training loss: 8.9668e-04 | validation loss: 1.9259e-04\n",
      "Epoch: 12230 | training loss: 8.9605e-04 | validation loss: 1.9192e-04\n",
      "Epoch: 12240 | training loss: 8.9550e-04 | validation loss: 1.9152e-04\n",
      "Epoch: 12250 | training loss: 8.9496e-04 | validation loss: 1.9132e-04\n",
      "Epoch: 12260 | training loss: 8.9443e-04 | validation loss: 1.9114e-04\n",
      "Epoch: 12270 | training loss: 8.9391e-04 | validation loss: 1.9087e-04\n",
      "Epoch: 12280 | training loss: 8.9338e-04 | validation loss: 1.9057e-04\n",
      "Epoch: 12290 | training loss: 8.9285e-04 | validation loss: 1.9033e-04\n",
      "Epoch: 12300 | training loss: 8.9232e-04 | validation loss: 1.9008e-04\n",
      "Epoch: 12310 | training loss: 8.9179e-04 | validation loss: 1.8982e-04\n",
      "Epoch: 12320 | training loss: 8.9126e-04 | validation loss: 1.8957e-04\n",
      "Epoch: 12330 | training loss: 8.9073e-04 | validation loss: 1.8932e-04\n",
      "Epoch: 12340 | training loss: 8.9020e-04 | validation loss: 1.8906e-04\n",
      "Epoch: 12350 | training loss: 8.8966e-04 | validation loss: 1.8881e-04\n",
      "Epoch: 12360 | training loss: 8.8913e-04 | validation loss: 1.8855e-04\n",
      "Epoch: 12370 | training loss: 8.8860e-04 | validation loss: 1.8829e-04\n",
      "Epoch: 12380 | training loss: 8.8806e-04 | validation loss: 1.8803e-04\n",
      "Epoch: 12390 | training loss: 8.8752e-04 | validation loss: 1.8778e-04\n",
      "Epoch: 12400 | training loss: 8.8699e-04 | validation loss: 1.8752e-04\n",
      "Epoch: 12410 | training loss: 8.8645e-04 | validation loss: 1.8725e-04\n",
      "Epoch: 12420 | training loss: 8.8591e-04 | validation loss: 1.8693e-04\n",
      "Epoch: 12430 | training loss: 8.8567e-04 | validation loss: 1.8573e-04\n",
      "Epoch: 12440 | training loss: 8.9138e-04 | validation loss: 1.8708e-04\n",
      "Epoch: 12450 | training loss: 8.8512e-04 | validation loss: 1.8496e-04\n",
      "Epoch: 12460 | training loss: 8.8421e-04 | validation loss: 1.8747e-04\n",
      "Epoch: 12470 | training loss: 8.8365e-04 | validation loss: 1.8723e-04\n",
      "Epoch: 12480 | training loss: 8.8293e-04 | validation loss: 1.8562e-04\n",
      "Epoch: 12490 | training loss: 8.8245e-04 | validation loss: 1.8503e-04\n",
      "Epoch: 12500 | training loss: 8.8193e-04 | validation loss: 1.8495e-04\n",
      "Epoch: 12510 | training loss: 8.8144e-04 | validation loss: 1.8489e-04\n",
      "Epoch: 12520 | training loss: 8.8095e-04 | validation loss: 1.8472e-04\n",
      "Epoch: 12530 | training loss: 8.8046e-04 | validation loss: 1.8445e-04\n",
      "Epoch: 12540 | training loss: 8.7997e-04 | validation loss: 1.8417e-04\n",
      "Epoch: 12550 | training loss: 8.7949e-04 | validation loss: 1.8393e-04\n",
      "Epoch: 12560 | training loss: 8.7900e-04 | validation loss: 1.8369e-04\n",
      "Epoch: 12570 | training loss: 8.7850e-04 | validation loss: 1.8345e-04\n",
      "Epoch: 12580 | training loss: 8.7801e-04 | validation loss: 1.8322e-04\n",
      "Epoch: 12590 | training loss: 8.7752e-04 | validation loss: 1.8299e-04\n",
      "Epoch: 12600 | training loss: 8.7703e-04 | validation loss: 1.8275e-04\n",
      "Epoch: 12610 | training loss: 8.7653e-04 | validation loss: 1.8251e-04\n",
      "Epoch: 12620 | training loss: 8.7604e-04 | validation loss: 1.8228e-04\n",
      "Epoch: 12630 | training loss: 8.7554e-04 | validation loss: 1.8204e-04\n",
      "Epoch: 12640 | training loss: 8.7505e-04 | validation loss: 1.8180e-04\n",
      "Epoch: 12650 | training loss: 8.7455e-04 | validation loss: 1.8158e-04\n",
      "Epoch: 12660 | training loss: 8.7411e-04 | validation loss: 1.8161e-04\n",
      "Epoch: 12670 | training loss: 8.8203e-04 | validation loss: 1.9039e-04\n",
      "Epoch: 12680 | training loss: 8.7549e-04 | validation loss: 1.7984e-04\n",
      "Epoch: 12690 | training loss: 8.7403e-04 | validation loss: 1.7946e-04\n",
      "Epoch: 12700 | training loss: 8.7268e-04 | validation loss: 1.7943e-04\n",
      "Epoch: 12710 | training loss: 8.7184e-04 | validation loss: 1.7957e-04\n",
      "Epoch: 12720 | training loss: 8.7125e-04 | validation loss: 1.7971e-04\n",
      "Epoch: 12730 | training loss: 8.7077e-04 | validation loss: 1.7974e-04\n",
      "Epoch: 12740 | training loss: 8.7031e-04 | validation loss: 1.7962e-04\n",
      "Epoch: 12750 | training loss: 8.6984e-04 | validation loss: 1.7935e-04\n",
      "Epoch: 12760 | training loss: 8.6937e-04 | validation loss: 1.7906e-04\n",
      "Epoch: 12770 | training loss: 8.6890e-04 | validation loss: 1.7884e-04\n",
      "Epoch: 12780 | training loss: 8.6843e-04 | validation loss: 1.7866e-04\n",
      "Epoch: 12790 | training loss: 8.6796e-04 | validation loss: 1.7844e-04\n",
      "Epoch: 12800 | training loss: 8.6750e-04 | validation loss: 1.7820e-04\n",
      "Epoch: 12810 | training loss: 8.6703e-04 | validation loss: 1.7798e-04\n",
      "Epoch: 12820 | training loss: 8.6655e-04 | validation loss: 1.7775e-04\n",
      "Epoch: 12830 | training loss: 8.6608e-04 | validation loss: 1.7753e-04\n",
      "Epoch: 12840 | training loss: 8.6561e-04 | validation loss: 1.7730e-04\n",
      "Epoch: 12850 | training loss: 8.6514e-04 | validation loss: 1.7708e-04\n",
      "Epoch: 12860 | training loss: 8.6466e-04 | validation loss: 1.7685e-04\n",
      "Epoch: 12870 | training loss: 8.6419e-04 | validation loss: 1.7662e-04\n",
      "Epoch: 12880 | training loss: 8.6371e-04 | validation loss: 1.7639e-04\n",
      "Epoch: 12890 | training loss: 8.6324e-04 | validation loss: 1.7616e-04\n",
      "Epoch: 12900 | training loss: 8.6276e-04 | validation loss: 1.7592e-04\n",
      "Epoch: 12910 | training loss: 8.6229e-04 | validation loss: 1.7563e-04\n",
      "Epoch: 12920 | training loss: 8.6268e-04 | validation loss: 1.7505e-04\n",
      "Epoch: 12930 | training loss: 8.6202e-04 | validation loss: 1.7386e-04\n",
      "Epoch: 12940 | training loss: 8.6203e-04 | validation loss: 1.7384e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12950 | training loss: 8.6065e-04 | validation loss: 1.7404e-04\n",
      "Epoch: 12960 | training loss: 8.6005e-04 | validation loss: 1.7431e-04\n",
      "Epoch: 12970 | training loss: 8.5962e-04 | validation loss: 1.7442e-04\n",
      "Epoch: 12980 | training loss: 8.5917e-04 | validation loss: 1.7431e-04\n",
      "Epoch: 12990 | training loss: 8.5872e-04 | validation loss: 1.7403e-04\n",
      "Epoch: 13000 | training loss: 8.5827e-04 | validation loss: 1.7373e-04\n",
      "Epoch: 13010 | training loss: 8.5783e-04 | validation loss: 1.7354e-04\n",
      "Epoch: 13020 | training loss: 8.5739e-04 | validation loss: 1.7340e-04\n",
      "Epoch: 13030 | training loss: 8.5694e-04 | validation loss: 1.7319e-04\n",
      "Epoch: 13040 | training loss: 8.5650e-04 | validation loss: 1.7296e-04\n",
      "Epoch: 13050 | training loss: 8.5606e-04 | validation loss: 1.7277e-04\n",
      "Epoch: 13060 | training loss: 8.5562e-04 | validation loss: 1.7255e-04\n",
      "Epoch: 13070 | training loss: 8.5517e-04 | validation loss: 1.7233e-04\n",
      "Epoch: 13080 | training loss: 8.5473e-04 | validation loss: 1.7212e-04\n",
      "Epoch: 13090 | training loss: 8.5428e-04 | validation loss: 1.7191e-04\n",
      "Epoch: 13100 | training loss: 8.5384e-04 | validation loss: 1.7170e-04\n",
      "Epoch: 13110 | training loss: 8.5339e-04 | validation loss: 1.7148e-04\n",
      "Epoch: 13120 | training loss: 8.5294e-04 | validation loss: 1.7127e-04\n",
      "Epoch: 13130 | training loss: 8.5249e-04 | validation loss: 1.7105e-04\n",
      "Epoch: 13140 | training loss: 8.5204e-04 | validation loss: 1.7084e-04\n",
      "Epoch: 13150 | training loss: 8.5159e-04 | validation loss: 1.7063e-04\n",
      "Epoch: 13160 | training loss: 8.5114e-04 | validation loss: 1.7046e-04\n",
      "Epoch: 13170 | training loss: 8.5084e-04 | validation loss: 1.7107e-04\n",
      "Epoch: 13180 | training loss: 8.6253e-04 | validation loss: 1.8550e-04\n",
      "Epoch: 13190 | training loss: 8.5211e-04 | validation loss: 1.7427e-04\n",
      "Epoch: 13200 | training loss: 8.5045e-04 | validation loss: 1.7156e-04\n",
      "Epoch: 13210 | training loss: 8.4914e-04 | validation loss: 1.6942e-04\n",
      "Epoch: 13220 | training loss: 8.4867e-04 | validation loss: 1.6871e-04\n",
      "Epoch: 13230 | training loss: 8.4825e-04 | validation loss: 1.6869e-04\n",
      "Epoch: 13240 | training loss: 8.4782e-04 | validation loss: 1.6872e-04\n",
      "Epoch: 13250 | training loss: 8.4740e-04 | validation loss: 1.6859e-04\n",
      "Epoch: 13260 | training loss: 8.4699e-04 | validation loss: 1.6843e-04\n",
      "Epoch: 13270 | training loss: 8.4658e-04 | validation loss: 1.6828e-04\n",
      "Epoch: 13280 | training loss: 8.4617e-04 | validation loss: 1.6807e-04\n",
      "Epoch: 13290 | training loss: 8.4576e-04 | validation loss: 1.6786e-04\n",
      "Epoch: 13300 | training loss: 8.4535e-04 | validation loss: 1.6767e-04\n",
      "Epoch: 13310 | training loss: 8.4494e-04 | validation loss: 1.6746e-04\n",
      "Epoch: 13320 | training loss: 8.4453e-04 | validation loss: 1.6727e-04\n",
      "Epoch: 13330 | training loss: 8.4412e-04 | validation loss: 1.6707e-04\n",
      "Epoch: 13340 | training loss: 8.4371e-04 | validation loss: 1.6687e-04\n",
      "Epoch: 13350 | training loss: 8.4329e-04 | validation loss: 1.6668e-04\n",
      "Epoch: 13360 | training loss: 8.4288e-04 | validation loss: 1.6648e-04\n",
      "Epoch: 13370 | training loss: 8.4246e-04 | validation loss: 1.6628e-04\n",
      "Epoch: 13380 | training loss: 8.4205e-04 | validation loss: 1.6609e-04\n",
      "Epoch: 13390 | training loss: 8.4163e-04 | validation loss: 1.6594e-04\n",
      "Epoch: 13400 | training loss: 8.4186e-04 | validation loss: 1.6685e-04\n",
      "Epoch: 13410 | training loss: 8.4314e-04 | validation loss: 1.6957e-04\n",
      "Epoch: 13420 | training loss: 8.4286e-04 | validation loss: 1.6948e-04\n",
      "Epoch: 13430 | training loss: 8.4066e-04 | validation loss: 1.6688e-04\n",
      "Epoch: 13440 | training loss: 8.3974e-04 | validation loss: 1.6559e-04\n",
      "Epoch: 13450 | training loss: 8.3926e-04 | validation loss: 1.6490e-04\n",
      "Epoch: 13460 | training loss: 8.3889e-04 | validation loss: 1.6451e-04\n",
      "Epoch: 13470 | training loss: 8.3850e-04 | validation loss: 1.6431e-04\n",
      "Epoch: 13480 | training loss: 8.3810e-04 | validation loss: 1.6422e-04\n",
      "Epoch: 13490 | training loss: 8.3771e-04 | validation loss: 1.6409e-04\n",
      "Epoch: 13500 | training loss: 8.3732e-04 | validation loss: 1.6388e-04\n",
      "Epoch: 13510 | training loss: 8.3693e-04 | validation loss: 1.6367e-04\n",
      "Epoch: 13520 | training loss: 8.3654e-04 | validation loss: 1.6352e-04\n",
      "Epoch: 13530 | training loss: 8.3615e-04 | validation loss: 1.6335e-04\n",
      "Epoch: 13540 | training loss: 8.3576e-04 | validation loss: 1.6315e-04\n",
      "Epoch: 13550 | training loss: 8.3537e-04 | validation loss: 1.6297e-04\n",
      "Epoch: 13560 | training loss: 8.3498e-04 | validation loss: 1.6279e-04\n",
      "Epoch: 13570 | training loss: 8.3458e-04 | validation loss: 1.6260e-04\n",
      "Epoch: 13580 | training loss: 8.3419e-04 | validation loss: 1.6242e-04\n",
      "Epoch: 13590 | training loss: 8.3379e-04 | validation loss: 1.6223e-04\n",
      "Epoch: 13600 | training loss: 8.3340e-04 | validation loss: 1.6205e-04\n",
      "Epoch: 13610 | training loss: 8.3300e-04 | validation loss: 1.6186e-04\n",
      "Epoch: 13620 | training loss: 8.3261e-04 | validation loss: 1.6167e-04\n",
      "Epoch: 13630 | training loss: 8.3221e-04 | validation loss: 1.6148e-04\n",
      "Epoch: 13640 | training loss: 8.3181e-04 | validation loss: 1.6123e-04\n",
      "Epoch: 13650 | training loss: 8.3238e-04 | validation loss: 1.6080e-04\n",
      "Epoch: 13660 | training loss: 8.3149e-04 | validation loss: 1.5978e-04\n",
      "Epoch: 13670 | training loss: 8.3150e-04 | validation loss: 1.5970e-04\n",
      "Epoch: 13680 | training loss: 8.3042e-04 | validation loss: 1.5994e-04\n",
      "Epoch: 13690 | training loss: 8.2999e-04 | validation loss: 1.6021e-04\n",
      "Epoch: 13700 | training loss: 8.2964e-04 | validation loss: 1.6030e-04\n",
      "Epoch: 13710 | training loss: 8.2925e-04 | validation loss: 1.6019e-04\n",
      "Epoch: 13720 | training loss: 8.2886e-04 | validation loss: 1.5994e-04\n",
      "Epoch: 13730 | training loss: 8.2849e-04 | validation loss: 1.5971e-04\n",
      "Epoch: 13740 | training loss: 8.2812e-04 | validation loss: 1.5957e-04\n",
      "Epoch: 13750 | training loss: 8.2776e-04 | validation loss: 1.5945e-04\n",
      "Epoch: 13760 | training loss: 8.2739e-04 | validation loss: 1.5928e-04\n",
      "Epoch: 13770 | training loss: 8.2703e-04 | validation loss: 1.5911e-04\n",
      "Epoch: 13780 | training loss: 8.2666e-04 | validation loss: 1.5895e-04\n",
      "Epoch: 13790 | training loss: 8.2629e-04 | validation loss: 1.5877e-04\n",
      "Epoch: 13800 | training loss: 8.2593e-04 | validation loss: 1.5860e-04\n",
      "Epoch: 13810 | training loss: 8.2556e-04 | validation loss: 1.5843e-04\n",
      "Epoch: 13820 | training loss: 8.2519e-04 | validation loss: 1.5826e-04\n",
      "Epoch: 13830 | training loss: 8.2482e-04 | validation loss: 1.5809e-04\n",
      "Epoch: 13840 | training loss: 8.2445e-04 | validation loss: 1.5792e-04\n",
      "Epoch: 13850 | training loss: 8.2408e-04 | validation loss: 1.5775e-04\n",
      "Epoch: 13860 | training loss: 8.2370e-04 | validation loss: 1.5758e-04\n",
      "Epoch: 13870 | training loss: 8.2333e-04 | validation loss: 1.5740e-04\n",
      "Epoch: 13880 | training loss: 8.2296e-04 | validation loss: 1.5722e-04\n",
      "Epoch: 13890 | training loss: 8.2259e-04 | validation loss: 1.5699e-04\n",
      "Epoch: 13900 | training loss: 8.2243e-04 | validation loss: 1.5612e-04\n",
      "Epoch: 13910 | training loss: 8.3035e-04 | validation loss: 1.5818e-04\n",
      "Epoch: 13920 | training loss: 8.2315e-04 | validation loss: 1.5554e-04\n",
      "Epoch: 13930 | training loss: 8.2168e-04 | validation loss: 1.5658e-04\n",
      "Epoch: 13940 | training loss: 8.2085e-04 | validation loss: 1.5664e-04\n",
      "Epoch: 13950 | training loss: 8.2060e-04 | validation loss: 1.5647e-04\n",
      "Epoch: 13960 | training loss: 8.2018e-04 | validation loss: 1.5623e-04\n",
      "Epoch: 13970 | training loss: 8.1982e-04 | validation loss: 1.5598e-04\n",
      "Epoch: 13980 | training loss: 8.1948e-04 | validation loss: 1.5562e-04\n",
      "Epoch: 13990 | training loss: 8.1914e-04 | validation loss: 1.5545e-04\n",
      "Epoch: 14000 | training loss: 8.1880e-04 | validation loss: 1.5531e-04\n",
      "Epoch: 14010 | training loss: 8.1846e-04 | validation loss: 1.5514e-04\n",
      "Epoch: 14020 | training loss: 8.1812e-04 | validation loss: 1.5500e-04\n",
      "Epoch: 14030 | training loss: 8.1778e-04 | validation loss: 1.5484e-04\n",
      "Epoch: 14040 | training loss: 8.1743e-04 | validation loss: 1.5468e-04\n",
      "Epoch: 14050 | training loss: 8.1709e-04 | validation loss: 1.5453e-04\n",
      "Epoch: 14060 | training loss: 8.1675e-04 | validation loss: 1.5437e-04\n",
      "Epoch: 14070 | training loss: 8.1640e-04 | validation loss: 1.5421e-04\n",
      "Epoch: 14080 | training loss: 8.1606e-04 | validation loss: 1.5406e-04\n",
      "Epoch: 14090 | training loss: 8.1573e-04 | validation loss: 1.5400e-04\n",
      "Epoch: 14100 | training loss: 8.1663e-04 | validation loss: 1.5570e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14110 | training loss: 8.1519e-04 | validation loss: 1.5444e-04\n",
      "Epoch: 14120 | training loss: 8.1673e-04 | validation loss: 1.5685e-04\n",
      "Epoch: 14130 | training loss: 8.1494e-04 | validation loss: 1.5472e-04\n",
      "Epoch: 14140 | training loss: 8.1408e-04 | validation loss: 1.5339e-04\n",
      "Epoch: 14150 | training loss: 8.1379e-04 | validation loss: 1.5286e-04\n",
      "Epoch: 14160 | training loss: 8.1345e-04 | validation loss: 1.5271e-04\n",
      "Epoch: 14170 | training loss: 8.1310e-04 | validation loss: 1.5273e-04\n",
      "Epoch: 14180 | training loss: 8.1278e-04 | validation loss: 1.5264e-04\n",
      "Epoch: 14190 | training loss: 8.1245e-04 | validation loss: 1.5241e-04\n",
      "Epoch: 14200 | training loss: 8.1212e-04 | validation loss: 1.5226e-04\n",
      "Epoch: 14210 | training loss: 8.1180e-04 | validation loss: 1.5215e-04\n",
      "Epoch: 14220 | training loss: 8.1147e-04 | validation loss: 1.5199e-04\n",
      "Epoch: 14230 | training loss: 8.1114e-04 | validation loss: 1.5185e-04\n",
      "Epoch: 14240 | training loss: 8.1082e-04 | validation loss: 1.5170e-04\n",
      "Epoch: 14250 | training loss: 8.1049e-04 | validation loss: 1.5155e-04\n",
      "Epoch: 14260 | training loss: 8.1016e-04 | validation loss: 1.5140e-04\n",
      "Epoch: 14270 | training loss: 8.0983e-04 | validation loss: 1.5126e-04\n",
      "Epoch: 14280 | training loss: 8.0950e-04 | validation loss: 1.5111e-04\n",
      "Epoch: 14290 | training loss: 8.0917e-04 | validation loss: 1.5096e-04\n",
      "Epoch: 14300 | training loss: 8.0884e-04 | validation loss: 1.5081e-04\n",
      "Epoch: 14310 | training loss: 8.0850e-04 | validation loss: 1.5068e-04\n",
      "Epoch: 14320 | training loss: 8.0820e-04 | validation loss: 1.5068e-04\n",
      "Epoch: 14330 | training loss: 8.1192e-04 | validation loss: 1.5516e-04\n",
      "Epoch: 14340 | training loss: 8.1211e-04 | validation loss: 1.5179e-04\n",
      "Epoch: 14350 | training loss: 8.0793e-04 | validation loss: 1.5118e-04\n",
      "Epoch: 14360 | training loss: 8.0716e-04 | validation loss: 1.5095e-04\n",
      "Epoch: 14370 | training loss: 8.0664e-04 | validation loss: 1.5020e-04\n",
      "Epoch: 14380 | training loss: 8.0629e-04 | validation loss: 1.4961e-04\n",
      "Epoch: 14390 | training loss: 8.0600e-04 | validation loss: 1.4940e-04\n",
      "Epoch: 14400 | training loss: 8.0569e-04 | validation loss: 1.4940e-04\n",
      "Epoch: 14410 | training loss: 8.0538e-04 | validation loss: 1.4930e-04\n",
      "Epoch: 14420 | training loss: 8.0506e-04 | validation loss: 1.4913e-04\n",
      "Epoch: 14430 | training loss: 8.0475e-04 | validation loss: 1.4903e-04\n",
      "Epoch: 14440 | training loss: 8.0445e-04 | validation loss: 1.4890e-04\n",
      "Epoch: 14450 | training loss: 8.0413e-04 | validation loss: 1.4874e-04\n",
      "Epoch: 14460 | training loss: 8.0382e-04 | validation loss: 1.4861e-04\n",
      "Epoch: 14470 | training loss: 8.0351e-04 | validation loss: 1.4848e-04\n",
      "Epoch: 14480 | training loss: 8.0320e-04 | validation loss: 1.4834e-04\n",
      "Epoch: 14490 | training loss: 8.0289e-04 | validation loss: 1.4820e-04\n",
      "Epoch: 14500 | training loss: 8.0257e-04 | validation loss: 1.4806e-04\n",
      "Epoch: 14510 | training loss: 8.0226e-04 | validation loss: 1.4793e-04\n",
      "Epoch: 14520 | training loss: 8.0194e-04 | validation loss: 1.4779e-04\n",
      "Epoch: 14530 | training loss: 8.0163e-04 | validation loss: 1.4764e-04\n",
      "Epoch: 14540 | training loss: 8.0131e-04 | validation loss: 1.4747e-04\n",
      "Epoch: 14550 | training loss: 8.0104e-04 | validation loss: 1.4702e-04\n",
      "Epoch: 14560 | training loss: 8.0639e-04 | validation loss: 1.4711e-04\n",
      "Epoch: 14570 | training loss: 8.0187e-04 | validation loss: 1.5029e-04\n",
      "Epoch: 14580 | training loss: 8.0058e-04 | validation loss: 1.4754e-04\n",
      "Epoch: 14590 | training loss: 7.9984e-04 | validation loss: 1.4665e-04\n",
      "Epoch: 14600 | training loss: 7.9961e-04 | validation loss: 1.4663e-04\n",
      "Epoch: 14610 | training loss: 7.9927e-04 | validation loss: 1.4628e-04\n",
      "Epoch: 14620 | training loss: 7.9897e-04 | validation loss: 1.4622e-04\n",
      "Epoch: 14630 | training loss: 7.9867e-04 | validation loss: 1.4627e-04\n",
      "Epoch: 14640 | training loss: 7.9838e-04 | validation loss: 1.4612e-04\n",
      "Epoch: 14650 | training loss: 7.9809e-04 | validation loss: 1.4607e-04\n",
      "Epoch: 14660 | training loss: 7.9780e-04 | validation loss: 1.4593e-04\n",
      "Epoch: 14670 | training loss: 7.9751e-04 | validation loss: 1.4584e-04\n",
      "Epoch: 14680 | training loss: 7.9722e-04 | validation loss: 1.4572e-04\n",
      "Epoch: 14690 | training loss: 7.9692e-04 | validation loss: 1.4559e-04\n",
      "Epoch: 14700 | training loss: 7.9663e-04 | validation loss: 1.4546e-04\n",
      "Epoch: 14710 | training loss: 7.9634e-04 | validation loss: 1.4532e-04\n",
      "Epoch: 14720 | training loss: 7.9605e-04 | validation loss: 1.4515e-04\n",
      "Epoch: 14730 | training loss: 7.9607e-04 | validation loss: 1.4484e-04\n",
      "Epoch: 14740 | training loss: 8.0428e-04 | validation loss: 1.4856e-04\n",
      "Epoch: 14750 | training loss: 7.9522e-04 | validation loss: 1.4525e-04\n",
      "Epoch: 14760 | training loss: 7.9575e-04 | validation loss: 1.4649e-04\n",
      "Epoch: 14770 | training loss: 7.9483e-04 | validation loss: 1.4533e-04\n",
      "Epoch: 14780 | training loss: 7.9438e-04 | validation loss: 1.4446e-04\n",
      "Epoch: 14790 | training loss: 7.9413e-04 | validation loss: 1.4424e-04\n",
      "Epoch: 14800 | training loss: 7.9381e-04 | validation loss: 1.4429e-04\n",
      "Epoch: 14810 | training loss: 7.9354e-04 | validation loss: 1.4420e-04\n",
      "Epoch: 14820 | training loss: 7.9325e-04 | validation loss: 1.4398e-04\n",
      "Epoch: 14830 | training loss: 7.9298e-04 | validation loss: 1.4390e-04\n",
      "Epoch: 14840 | training loss: 7.9270e-04 | validation loss: 1.4380e-04\n",
      "Epoch: 14850 | training loss: 7.9242e-04 | validation loss: 1.4366e-04\n",
      "Epoch: 14860 | training loss: 7.9214e-04 | validation loss: 1.4355e-04\n",
      "Epoch: 14870 | training loss: 7.9186e-04 | validation loss: 1.4343e-04\n",
      "Epoch: 14880 | training loss: 7.9157e-04 | validation loss: 1.4331e-04\n",
      "Epoch: 14890 | training loss: 7.9129e-04 | validation loss: 1.4319e-04\n",
      "Epoch: 14900 | training loss: 7.9101e-04 | validation loss: 1.4308e-04\n",
      "Epoch: 14910 | training loss: 7.9073e-04 | validation loss: 1.4296e-04\n",
      "Epoch: 14920 | training loss: 7.9044e-04 | validation loss: 1.4284e-04\n",
      "Epoch: 14930 | training loss: 7.9016e-04 | validation loss: 1.4275e-04\n",
      "Epoch: 14940 | training loss: 7.9004e-04 | validation loss: 1.4306e-04\n",
      "Epoch: 14950 | training loss: 8.0103e-04 | validation loss: 1.5385e-04\n",
      "Epoch: 14960 | training loss: 7.8981e-04 | validation loss: 1.4144e-04\n",
      "Epoch: 14970 | training loss: 7.8978e-04 | validation loss: 1.4186e-04\n",
      "Epoch: 14980 | training loss: 7.8911e-04 | validation loss: 1.4237e-04\n",
      "Epoch: 14990 | training loss: 7.8868e-04 | validation loss: 1.4251e-04\n",
      "Epoch: 15000 | training loss: 7.8830e-04 | validation loss: 1.4214e-04\n",
      "Epoch: 15010 | training loss: 7.8800e-04 | validation loss: 1.4175e-04\n",
      "Epoch: 15020 | training loss: 7.8774e-04 | validation loss: 1.4166e-04\n",
      "Epoch: 15030 | training loss: 7.8747e-04 | validation loss: 1.4163e-04\n",
      "Epoch: 15040 | training loss: 7.8721e-04 | validation loss: 1.4149e-04\n",
      "Epoch: 15050 | training loss: 7.8694e-04 | validation loss: 1.4140e-04\n",
      "Epoch: 15060 | training loss: 7.8667e-04 | validation loss: 1.4128e-04\n",
      "Epoch: 15070 | training loss: 7.8641e-04 | validation loss: 1.4117e-04\n",
      "Epoch: 15080 | training loss: 7.8614e-04 | validation loss: 1.4106e-04\n",
      "Epoch: 15090 | training loss: 7.8587e-04 | validation loss: 1.4095e-04\n",
      "Epoch: 15100 | training loss: 7.8560e-04 | validation loss: 1.4084e-04\n",
      "Epoch: 15110 | training loss: 7.8533e-04 | validation loss: 1.4073e-04\n",
      "Epoch: 15120 | training loss: 7.8506e-04 | validation loss: 1.4062e-04\n",
      "Epoch: 15130 | training loss: 7.8479e-04 | validation loss: 1.4051e-04\n",
      "Epoch: 15140 | training loss: 7.8451e-04 | validation loss: 1.4040e-04\n",
      "Epoch: 15150 | training loss: 7.8424e-04 | validation loss: 1.4032e-04\n",
      "Epoch: 15160 | training loss: 7.8400e-04 | validation loss: 1.4055e-04\n",
      "Epoch: 15170 | training loss: 7.8852e-04 | validation loss: 1.4750e-04\n",
      "Epoch: 15180 | training loss: 7.8447e-04 | validation loss: 1.3870e-04\n",
      "Epoch: 15190 | training loss: 7.8383e-04 | validation loss: 1.3999e-04\n",
      "Epoch: 15200 | training loss: 7.8299e-04 | validation loss: 1.3966e-04\n",
      "Epoch: 15210 | training loss: 7.8275e-04 | validation loss: 1.3995e-04\n",
      "Epoch: 15220 | training loss: 7.8250e-04 | validation loss: 1.4003e-04\n",
      "Epoch: 15230 | training loss: 7.8222e-04 | validation loss: 1.3960e-04\n",
      "Epoch: 15240 | training loss: 7.8196e-04 | validation loss: 1.3950e-04\n",
      "Epoch: 15250 | training loss: 7.8170e-04 | validation loss: 1.3928e-04\n",
      "Epoch: 15260 | training loss: 7.8145e-04 | validation loss: 1.3919e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15270 | training loss: 7.8120e-04 | validation loss: 1.3905e-04\n",
      "Epoch: 15280 | training loss: 7.8095e-04 | validation loss: 1.3894e-04\n",
      "Epoch: 15290 | training loss: 7.8070e-04 | validation loss: 1.3883e-04\n",
      "Epoch: 15300 | training loss: 7.8045e-04 | validation loss: 1.3872e-04\n",
      "Epoch: 15310 | training loss: 7.8020e-04 | validation loss: 1.3863e-04\n",
      "Epoch: 15320 | training loss: 7.7997e-04 | validation loss: 1.3864e-04\n",
      "Epoch: 15330 | training loss: 7.8126e-04 | validation loss: 1.4054e-04\n",
      "Epoch: 15340 | training loss: 7.7954e-04 | validation loss: 1.3884e-04\n",
      "Epoch: 15350 | training loss: 7.8095e-04 | validation loss: 1.4086e-04\n",
      "Epoch: 15360 | training loss: 7.7897e-04 | validation loss: 1.3827e-04\n",
      "Epoch: 15370 | training loss: 7.7893e-04 | validation loss: 1.3779e-04\n",
      "Epoch: 15380 | training loss: 7.7850e-04 | validation loss: 1.3785e-04\n",
      "Epoch: 15390 | training loss: 7.7828e-04 | validation loss: 1.3802e-04\n",
      "Epoch: 15400 | training loss: 7.7801e-04 | validation loss: 1.3773e-04\n",
      "Epoch: 15410 | training loss: 7.7777e-04 | validation loss: 1.3759e-04\n",
      "Epoch: 15420 | training loss: 7.7753e-04 | validation loss: 1.3758e-04\n",
      "Epoch: 15430 | training loss: 7.7728e-04 | validation loss: 1.3743e-04\n",
      "Epoch: 15440 | training loss: 7.7704e-04 | validation loss: 1.3737e-04\n",
      "Epoch: 15450 | training loss: 7.7679e-04 | validation loss: 1.3725e-04\n",
      "Epoch: 15460 | training loss: 7.7655e-04 | validation loss: 1.3717e-04\n",
      "Epoch: 15470 | training loss: 7.7631e-04 | validation loss: 1.3707e-04\n",
      "Epoch: 15480 | training loss: 7.7606e-04 | validation loss: 1.3697e-04\n",
      "Epoch: 15490 | training loss: 7.7581e-04 | validation loss: 1.3687e-04\n",
      "Epoch: 15500 | training loss: 7.7557e-04 | validation loss: 1.3677e-04\n",
      "Epoch: 15510 | training loss: 7.7532e-04 | validation loss: 1.3666e-04\n",
      "Epoch: 15520 | training loss: 7.7509e-04 | validation loss: 1.3649e-04\n",
      "Epoch: 15530 | training loss: 7.7651e-04 | validation loss: 1.3663e-04\n",
      "Epoch: 15540 | training loss: 7.7469e-04 | validation loss: 1.3622e-04\n",
      "Epoch: 15550 | training loss: 7.7594e-04 | validation loss: 1.3608e-04\n",
      "Epoch: 15560 | training loss: 7.7479e-04 | validation loss: 1.3617e-04\n",
      "Epoch: 15570 | training loss: 7.7403e-04 | validation loss: 1.3639e-04\n",
      "Epoch: 15580 | training loss: 7.7369e-04 | validation loss: 1.3636e-04\n",
      "Epoch: 15590 | training loss: 7.7345e-04 | validation loss: 1.3601e-04\n",
      "Epoch: 15600 | training loss: 7.7321e-04 | validation loss: 1.3576e-04\n",
      "Epoch: 15610 | training loss: 7.7297e-04 | validation loss: 1.3576e-04\n",
      "Epoch: 15620 | training loss: 7.7274e-04 | validation loss: 1.3573e-04\n",
      "Epoch: 15630 | training loss: 7.7250e-04 | validation loss: 1.3558e-04\n",
      "Epoch: 15640 | training loss: 7.7227e-04 | validation loss: 1.3551e-04\n",
      "Epoch: 15650 | training loss: 7.7203e-04 | validation loss: 1.3542e-04\n",
      "Epoch: 15660 | training loss: 7.7180e-04 | validation loss: 1.3533e-04\n",
      "Epoch: 15670 | training loss: 7.7156e-04 | validation loss: 1.3524e-04\n",
      "Epoch: 15680 | training loss: 7.7133e-04 | validation loss: 1.3515e-04\n",
      "Epoch: 15690 | training loss: 7.7109e-04 | validation loss: 1.3506e-04\n",
      "Epoch: 15700 | training loss: 7.7085e-04 | validation loss: 1.3497e-04\n",
      "Epoch: 15710 | training loss: 7.7061e-04 | validation loss: 1.3488e-04\n",
      "Epoch: 15720 | training loss: 7.7037e-04 | validation loss: 1.3479e-04\n",
      "Epoch: 15730 | training loss: 7.7013e-04 | validation loss: 1.3470e-04\n",
      "Epoch: 15740 | training loss: 7.6989e-04 | validation loss: 1.3463e-04\n",
      "Epoch: 15750 | training loss: 7.6967e-04 | validation loss: 1.3479e-04\n",
      "Epoch: 15760 | training loss: 7.7220e-04 | validation loss: 1.3941e-04\n",
      "Epoch: 15770 | training loss: 7.7375e-04 | validation loss: 1.3499e-04\n",
      "Epoch: 15780 | training loss: 7.6981e-04 | validation loss: 1.3335e-04\n",
      "Epoch: 15790 | training loss: 7.6895e-04 | validation loss: 1.3384e-04\n",
      "Epoch: 15800 | training loss: 7.6867e-04 | validation loss: 1.3484e-04\n",
      "Epoch: 15810 | training loss: 7.6837e-04 | validation loss: 1.3442e-04\n",
      "Epoch: 15820 | training loss: 7.6811e-04 | validation loss: 1.3401e-04\n",
      "Epoch: 15830 | training loss: 7.6789e-04 | validation loss: 1.3388e-04\n",
      "Epoch: 15840 | training loss: 7.6767e-04 | validation loss: 1.3368e-04\n",
      "Epoch: 15850 | training loss: 7.6745e-04 | validation loss: 1.3364e-04\n",
      "Epoch: 15860 | training loss: 7.6723e-04 | validation loss: 1.3356e-04\n",
      "Epoch: 15870 | training loss: 7.6701e-04 | validation loss: 1.3347e-04\n",
      "Epoch: 15880 | training loss: 7.6679e-04 | validation loss: 1.3340e-04\n",
      "Epoch: 15890 | training loss: 7.6657e-04 | validation loss: 1.3332e-04\n",
      "Epoch: 15900 | training loss: 7.6635e-04 | validation loss: 1.3325e-04\n",
      "Epoch: 15910 | training loss: 7.6613e-04 | validation loss: 1.3320e-04\n",
      "Epoch: 15920 | training loss: 7.6602e-04 | validation loss: 1.3344e-04\n",
      "Epoch: 15930 | training loss: 7.7470e-04 | validation loss: 1.4203e-04\n",
      "Epoch: 15940 | training loss: 7.6837e-04 | validation loss: 1.3342e-04\n",
      "Epoch: 15950 | training loss: 7.6638e-04 | validation loss: 1.3265e-04\n",
      "Epoch: 15960 | training loss: 7.6509e-04 | validation loss: 1.3259e-04\n",
      "Epoch: 15970 | training loss: 7.6492e-04 | validation loss: 1.3295e-04\n",
      "Epoch: 15980 | training loss: 7.6471e-04 | validation loss: 1.3287e-04\n",
      "Epoch: 15990 | training loss: 7.6444e-04 | validation loss: 1.3255e-04\n",
      "Epoch: 16000 | training loss: 7.6424e-04 | validation loss: 1.3238e-04\n",
      "Epoch: 16010 | training loss: 7.6402e-04 | validation loss: 1.3238e-04\n",
      "Epoch: 16020 | training loss: 7.6381e-04 | validation loss: 1.3233e-04\n",
      "Epoch: 16030 | training loss: 7.6360e-04 | validation loss: 1.3221e-04\n",
      "Epoch: 16040 | training loss: 7.6338e-04 | validation loss: 1.3215e-04\n",
      "Epoch: 16050 | training loss: 7.6317e-04 | validation loss: 1.3207e-04\n",
      "Epoch: 16060 | training loss: 7.6296e-04 | validation loss: 1.3199e-04\n",
      "Epoch: 16070 | training loss: 7.6275e-04 | validation loss: 1.3192e-04\n",
      "Epoch: 16080 | training loss: 7.6253e-04 | validation loss: 1.3184e-04\n",
      "Epoch: 16090 | training loss: 7.6232e-04 | validation loss: 1.3176e-04\n",
      "Epoch: 16100 | training loss: 7.6210e-04 | validation loss: 1.3168e-04\n",
      "Epoch: 16110 | training loss: 7.6189e-04 | validation loss: 1.3160e-04\n",
      "Epoch: 16120 | training loss: 7.6167e-04 | validation loss: 1.3153e-04\n",
      "Epoch: 16130 | training loss: 7.6145e-04 | validation loss: 1.3145e-04\n",
      "Epoch: 16140 | training loss: 7.6123e-04 | validation loss: 1.3139e-04\n",
      "Epoch: 16150 | training loss: 7.6111e-04 | validation loss: 1.3159e-04\n",
      "Epoch: 16160 | training loss: 7.7268e-04 | validation loss: 1.4258e-04\n",
      "Epoch: 16170 | training loss: 7.6189e-04 | validation loss: 1.3076e-04\n",
      "Epoch: 16180 | training loss: 7.6142e-04 | validation loss: 1.3072e-04\n",
      "Epoch: 16190 | training loss: 7.6062e-04 | validation loss: 1.3069e-04\n",
      "Epoch: 16200 | training loss: 7.6016e-04 | validation loss: 1.3080e-04\n",
      "Epoch: 16210 | training loss: 7.5986e-04 | validation loss: 1.3090e-04\n",
      "Epoch: 16220 | training loss: 7.5962e-04 | validation loss: 1.3090e-04\n",
      "Epoch: 16230 | training loss: 7.5940e-04 | validation loss: 1.3080e-04\n",
      "Epoch: 16240 | training loss: 7.5919e-04 | validation loss: 1.3066e-04\n",
      "Epoch: 16250 | training loss: 7.5899e-04 | validation loss: 1.3056e-04\n",
      "Epoch: 16260 | training loss: 7.5879e-04 | validation loss: 1.3051e-04\n",
      "Epoch: 16270 | training loss: 7.5858e-04 | validation loss: 1.3045e-04\n",
      "Epoch: 16280 | training loss: 7.5838e-04 | validation loss: 1.3037e-04\n",
      "Epoch: 16290 | training loss: 7.5817e-04 | validation loss: 1.3030e-04\n",
      "Epoch: 16300 | training loss: 7.5797e-04 | validation loss: 1.3023e-04\n",
      "Epoch: 16310 | training loss: 7.5776e-04 | validation loss: 1.3016e-04\n",
      "Epoch: 16320 | training loss: 7.5755e-04 | validation loss: 1.3009e-04\n",
      "Epoch: 16330 | training loss: 7.5735e-04 | validation loss: 1.3002e-04\n",
      "Epoch: 16340 | training loss: 7.5714e-04 | validation loss: 1.2995e-04\n",
      "Epoch: 16350 | training loss: 7.5693e-04 | validation loss: 1.2988e-04\n",
      "Epoch: 16360 | training loss: 7.5672e-04 | validation loss: 1.2980e-04\n",
      "Epoch: 16370 | training loss: 7.5651e-04 | validation loss: 1.2973e-04\n",
      "Epoch: 16380 | training loss: 7.5630e-04 | validation loss: 1.2966e-04\n",
      "Epoch: 16390 | training loss: 7.5609e-04 | validation loss: 1.2959e-04\n",
      "Epoch: 16400 | training loss: 7.5587e-04 | validation loss: 1.2951e-04\n",
      "Epoch: 16410 | training loss: 7.5566e-04 | validation loss: 1.2940e-04\n",
      "Epoch: 16420 | training loss: 7.5560e-04 | validation loss: 1.2880e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16430 | training loss: 7.5884e-04 | validation loss: 1.2853e-04\n",
      "Epoch: 16440 | training loss: 7.5763e-04 | validation loss: 1.2821e-04\n",
      "Epoch: 16450 | training loss: 7.5498e-04 | validation loss: 1.2879e-04\n",
      "Epoch: 16460 | training loss: 7.5481e-04 | validation loss: 1.2988e-04\n",
      "Epoch: 16470 | training loss: 7.5462e-04 | validation loss: 1.2941e-04\n",
      "Epoch: 16480 | training loss: 7.5432e-04 | validation loss: 1.2926e-04\n",
      "Epoch: 16490 | training loss: 7.5410e-04 | validation loss: 1.2876e-04\n",
      "Epoch: 16500 | training loss: 7.5390e-04 | validation loss: 1.2878e-04\n",
      "Epoch: 16510 | training loss: 7.5371e-04 | validation loss: 1.2871e-04\n",
      "Epoch: 16520 | training loss: 7.5351e-04 | validation loss: 1.2864e-04\n",
      "Epoch: 16530 | training loss: 7.5332e-04 | validation loss: 1.2861e-04\n",
      "Epoch: 16540 | training loss: 7.5312e-04 | validation loss: 1.2856e-04\n",
      "Epoch: 16550 | training loss: 7.5293e-04 | validation loss: 1.2851e-04\n",
      "Epoch: 16560 | training loss: 7.5275e-04 | validation loss: 1.2853e-04\n",
      "Epoch: 16570 | training loss: 7.5354e-04 | validation loss: 1.2984e-04\n",
      "Epoch: 16580 | training loss: 7.5455e-04 | validation loss: 1.3115e-04\n",
      "Epoch: 16590 | training loss: 7.5351e-04 | validation loss: 1.3021e-04\n",
      "Epoch: 16600 | training loss: 7.5206e-04 | validation loss: 1.2803e-04\n",
      "Epoch: 16610 | training loss: 7.5207e-04 | validation loss: 1.2790e-04\n",
      "Epoch: 16620 | training loss: 7.5161e-04 | validation loss: 1.2803e-04\n",
      "Epoch: 16630 | training loss: 7.5146e-04 | validation loss: 1.2818e-04\n",
      "Epoch: 16640 | training loss: 7.5124e-04 | validation loss: 1.2793e-04\n",
      "Epoch: 16650 | training loss: 7.5106e-04 | validation loss: 1.2784e-04\n",
      "Epoch: 16660 | training loss: 7.5087e-04 | validation loss: 1.2786e-04\n",
      "Epoch: 16670 | training loss: 7.5068e-04 | validation loss: 1.2775e-04\n",
      "Epoch: 16680 | training loss: 7.5049e-04 | validation loss: 1.2771e-04\n",
      "Epoch: 16690 | training loss: 7.5030e-04 | validation loss: 1.2764e-04\n",
      "Epoch: 16700 | training loss: 7.5011e-04 | validation loss: 1.2758e-04\n",
      "Epoch: 16710 | training loss: 7.4992e-04 | validation loss: 1.2751e-04\n",
      "Epoch: 16720 | training loss: 7.4973e-04 | validation loss: 1.2746e-04\n",
      "Epoch: 16730 | training loss: 7.4954e-04 | validation loss: 1.2739e-04\n",
      "Epoch: 16740 | training loss: 7.4935e-04 | validation loss: 1.2733e-04\n",
      "Epoch: 16750 | training loss: 7.4916e-04 | validation loss: 1.2727e-04\n",
      "Epoch: 16760 | training loss: 7.4897e-04 | validation loss: 1.2724e-04\n",
      "Epoch: 16770 | training loss: 7.4890e-04 | validation loss: 1.2750e-04\n",
      "Epoch: 16780 | training loss: 7.5839e-04 | validation loss: 1.3658e-04\n",
      "Epoch: 16790 | training loss: 7.5100e-04 | validation loss: 1.2747e-04\n",
      "Epoch: 16800 | training loss: 7.4951e-04 | validation loss: 1.2693e-04\n",
      "Epoch: 16810 | training loss: 7.4814e-04 | validation loss: 1.2673e-04\n",
      "Epoch: 16820 | training loss: 7.4789e-04 | validation loss: 1.2704e-04\n",
      "Epoch: 16830 | training loss: 7.4774e-04 | validation loss: 1.2709e-04\n",
      "Epoch: 16840 | training loss: 7.4750e-04 | validation loss: 1.2683e-04\n",
      "Epoch: 16850 | training loss: 7.4732e-04 | validation loss: 1.2665e-04\n",
      "Epoch: 16860 | training loss: 7.4713e-04 | validation loss: 1.2661e-04\n",
      "Epoch: 16870 | training loss: 7.4695e-04 | validation loss: 1.2660e-04\n",
      "Epoch: 16880 | training loss: 7.4677e-04 | validation loss: 1.2652e-04\n",
      "Epoch: 16890 | training loss: 7.4658e-04 | validation loss: 1.2646e-04\n",
      "Epoch: 16900 | training loss: 7.4640e-04 | validation loss: 1.2641e-04\n",
      "Epoch: 16910 | training loss: 7.4621e-04 | validation loss: 1.2635e-04\n",
      "Epoch: 16920 | training loss: 7.4603e-04 | validation loss: 1.2629e-04\n",
      "Epoch: 16930 | training loss: 7.4584e-04 | validation loss: 1.2623e-04\n",
      "Epoch: 16940 | training loss: 7.4565e-04 | validation loss: 1.2618e-04\n",
      "Epoch: 16950 | training loss: 7.4546e-04 | validation loss: 1.2612e-04\n",
      "Epoch: 16960 | training loss: 7.4528e-04 | validation loss: 1.2606e-04\n",
      "Epoch: 16970 | training loss: 7.4509e-04 | validation loss: 1.2600e-04\n",
      "Epoch: 16980 | training loss: 7.4490e-04 | validation loss: 1.2595e-04\n",
      "Epoch: 16990 | training loss: 7.4471e-04 | validation loss: 1.2590e-04\n",
      "Epoch: 17000 | training loss: 7.4457e-04 | validation loss: 1.2599e-04\n",
      "Epoch: 17010 | training loss: 7.5159e-04 | validation loss: 1.3258e-04\n",
      "Epoch: 17020 | training loss: 7.4927e-04 | validation loss: 1.2800e-04\n",
      "Epoch: 17030 | training loss: 7.4563e-04 | validation loss: 1.2710e-04\n",
      "Epoch: 17040 | training loss: 7.4443e-04 | validation loss: 1.2667e-04\n",
      "Epoch: 17050 | training loss: 7.4384e-04 | validation loss: 1.2608e-04\n",
      "Epoch: 17060 | training loss: 7.4352e-04 | validation loss: 1.2564e-04\n",
      "Epoch: 17070 | training loss: 7.4329e-04 | validation loss: 1.2548e-04\n",
      "Epoch: 17080 | training loss: 7.4310e-04 | validation loss: 1.2546e-04\n",
      "Epoch: 17090 | training loss: 7.4292e-04 | validation loss: 1.2536e-04\n",
      "Epoch: 17100 | training loss: 7.4275e-04 | validation loss: 1.2527e-04\n",
      "Epoch: 17110 | training loss: 7.4257e-04 | validation loss: 1.2525e-04\n",
      "Epoch: 17120 | training loss: 7.4239e-04 | validation loss: 1.2519e-04\n",
      "Epoch: 17130 | training loss: 7.4221e-04 | validation loss: 1.2515e-04\n",
      "Epoch: 17140 | training loss: 7.4203e-04 | validation loss: 1.2509e-04\n",
      "Epoch: 17150 | training loss: 7.4185e-04 | validation loss: 1.2504e-04\n",
      "Epoch: 17160 | training loss: 7.4167e-04 | validation loss: 1.2498e-04\n",
      "Epoch: 17170 | training loss: 7.4149e-04 | validation loss: 1.2493e-04\n",
      "Epoch: 17180 | training loss: 7.4131e-04 | validation loss: 1.2488e-04\n",
      "Epoch: 17190 | training loss: 7.4113e-04 | validation loss: 1.2482e-04\n",
      "Epoch: 17200 | training loss: 7.4095e-04 | validation loss: 1.2477e-04\n",
      "Epoch: 17210 | training loss: 7.4076e-04 | validation loss: 1.2472e-04\n",
      "Epoch: 17220 | training loss: 7.4058e-04 | validation loss: 1.2471e-04\n",
      "Epoch: 17230 | training loss: 7.4052e-04 | validation loss: 1.2527e-04\n",
      "Epoch: 17240 | training loss: 7.4935e-04 | validation loss: 1.3562e-04\n",
      "Epoch: 17250 | training loss: 7.4310e-04 | validation loss: 1.2781e-04\n",
      "Epoch: 17260 | training loss: 7.4045e-04 | validation loss: 1.2597e-04\n",
      "Epoch: 17270 | training loss: 7.3993e-04 | validation loss: 1.2523e-04\n",
      "Epoch: 17280 | training loss: 7.3955e-04 | validation loss: 1.2423e-04\n",
      "Epoch: 17290 | training loss: 7.3940e-04 | validation loss: 1.2407e-04\n",
      "Epoch: 17300 | training loss: 7.3923e-04 | validation loss: 1.2418e-04\n",
      "Epoch: 17310 | training loss: 7.3905e-04 | validation loss: 1.2408e-04\n",
      "Epoch: 17320 | training loss: 7.3887e-04 | validation loss: 1.2412e-04\n",
      "Epoch: 17330 | training loss: 7.3870e-04 | validation loss: 1.2406e-04\n",
      "Epoch: 17340 | training loss: 7.3853e-04 | validation loss: 1.2405e-04\n",
      "Epoch: 17350 | training loss: 7.3836e-04 | validation loss: 1.2399e-04\n",
      "Epoch: 17360 | training loss: 7.3819e-04 | validation loss: 1.2395e-04\n",
      "Epoch: 17370 | training loss: 7.3802e-04 | validation loss: 1.2391e-04\n",
      "Epoch: 17380 | training loss: 7.3785e-04 | validation loss: 1.2386e-04\n",
      "Epoch: 17390 | training loss: 7.3768e-04 | validation loss: 1.2382e-04\n",
      "Epoch: 17400 | training loss: 7.3751e-04 | validation loss: 1.2383e-04\n",
      "Epoch: 17410 | training loss: 7.3799e-04 | validation loss: 1.2471e-04\n",
      "Epoch: 17420 | training loss: 7.4280e-04 | validation loss: 1.2949e-04\n",
      "Epoch: 17430 | training loss: 7.3807e-04 | validation loss: 1.2513e-04\n",
      "Epoch: 17440 | training loss: 7.3695e-04 | validation loss: 1.2340e-04\n",
      "Epoch: 17450 | training loss: 7.3699e-04 | validation loss: 1.2335e-04\n",
      "Epoch: 17460 | training loss: 7.3655e-04 | validation loss: 1.2336e-04\n",
      "Epoch: 17470 | training loss: 7.3636e-04 | validation loss: 1.2354e-04\n",
      "Epoch: 17480 | training loss: 7.3619e-04 | validation loss: 1.2347e-04\n",
      "Epoch: 17490 | training loss: 7.3602e-04 | validation loss: 1.2331e-04\n",
      "Epoch: 17500 | training loss: 7.3585e-04 | validation loss: 1.2329e-04\n",
      "Epoch: 17510 | training loss: 7.3569e-04 | validation loss: 1.2328e-04\n",
      "Epoch: 17520 | training loss: 7.3552e-04 | validation loss: 1.2320e-04\n",
      "Epoch: 17530 | training loss: 7.3536e-04 | validation loss: 1.2317e-04\n",
      "Epoch: 17540 | training loss: 7.3519e-04 | validation loss: 1.2312e-04\n",
      "Epoch: 17550 | training loss: 7.3502e-04 | validation loss: 1.2308e-04\n",
      "Epoch: 17560 | training loss: 7.3485e-04 | validation loss: 1.2303e-04\n",
      "Epoch: 17570 | training loss: 7.3468e-04 | validation loss: 1.2298e-04\n",
      "Epoch: 17580 | training loss: 7.3451e-04 | validation loss: 1.2294e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17590 | training loss: 7.3434e-04 | validation loss: 1.2289e-04\n",
      "Epoch: 17600 | training loss: 7.3417e-04 | validation loss: 1.2284e-04\n",
      "Epoch: 17610 | training loss: 7.3400e-04 | validation loss: 1.2280e-04\n",
      "Epoch: 17620 | training loss: 7.3383e-04 | validation loss: 1.2278e-04\n",
      "Epoch: 17630 | training loss: 7.3388e-04 | validation loss: 1.2316e-04\n",
      "Epoch: 17640 | training loss: 7.4743e-04 | validation loss: 1.3526e-04\n",
      "Epoch: 17650 | training loss: 7.3367e-04 | validation loss: 1.2259e-04\n",
      "Epoch: 17660 | training loss: 7.3334e-04 | validation loss: 1.2203e-04\n",
      "Epoch: 17670 | training loss: 7.3314e-04 | validation loss: 1.2223e-04\n",
      "Epoch: 17680 | training loss: 7.3293e-04 | validation loss: 1.2249e-04\n",
      "Epoch: 17690 | training loss: 7.3275e-04 | validation loss: 1.2261e-04\n",
      "Epoch: 17700 | training loss: 7.3256e-04 | validation loss: 1.2251e-04\n",
      "Epoch: 17710 | training loss: 7.3238e-04 | validation loss: 1.2236e-04\n",
      "Epoch: 17720 | training loss: 7.3222e-04 | validation loss: 1.2230e-04\n",
      "Epoch: 17730 | training loss: 7.3206e-04 | validation loss: 1.2230e-04\n",
      "Epoch: 17740 | training loss: 7.3189e-04 | validation loss: 1.2225e-04\n",
      "Epoch: 17750 | training loss: 7.3173e-04 | validation loss: 1.2220e-04\n",
      "Epoch: 17760 | training loss: 7.3157e-04 | validation loss: 1.2217e-04\n",
      "Epoch: 17770 | training loss: 7.3141e-04 | validation loss: 1.2212e-04\n",
      "Epoch: 17780 | training loss: 7.3124e-04 | validation loss: 1.2208e-04\n",
      "Epoch: 17790 | training loss: 7.3108e-04 | validation loss: 1.2204e-04\n",
      "Epoch: 17800 | training loss: 7.3091e-04 | validation loss: 1.2200e-04\n",
      "Epoch: 17810 | training loss: 7.3075e-04 | validation loss: 1.2195e-04\n",
      "Epoch: 17820 | training loss: 7.3058e-04 | validation loss: 1.2191e-04\n",
      "Epoch: 17830 | training loss: 7.3042e-04 | validation loss: 1.2187e-04\n",
      "Epoch: 17840 | training loss: 7.3025e-04 | validation loss: 1.2182e-04\n",
      "Epoch: 17850 | training loss: 7.3008e-04 | validation loss: 1.2178e-04\n",
      "Epoch: 17860 | training loss: 7.2991e-04 | validation loss: 1.2173e-04\n",
      "Epoch: 17870 | training loss: 7.2975e-04 | validation loss: 1.2162e-04\n",
      "Epoch: 17880 | training loss: 7.3006e-04 | validation loss: 1.2082e-04\n",
      "Epoch: 17890 | training loss: 7.3334e-04 | validation loss: 1.2417e-04\n",
      "Epoch: 17900 | training loss: 7.3044e-04 | validation loss: 1.2387e-04\n",
      "Epoch: 17910 | training loss: 7.2996e-04 | validation loss: 1.2288e-04\n",
      "Epoch: 17920 | training loss: 7.2907e-04 | validation loss: 1.2213e-04\n",
      "Epoch: 17930 | training loss: 7.2882e-04 | validation loss: 1.2124e-04\n",
      "Epoch: 17940 | training loss: 7.2868e-04 | validation loss: 1.2120e-04\n",
      "Epoch: 17950 | training loss: 7.2850e-04 | validation loss: 1.2123e-04\n",
      "Epoch: 17960 | training loss: 7.2835e-04 | validation loss: 1.2134e-04\n",
      "Epoch: 17970 | training loss: 7.2819e-04 | validation loss: 1.2129e-04\n",
      "Epoch: 17980 | training loss: 7.2804e-04 | validation loss: 1.2126e-04\n",
      "Epoch: 17990 | training loss: 7.2788e-04 | validation loss: 1.2123e-04\n",
      "Epoch: 18000 | training loss: 7.2772e-04 | validation loss: 1.2119e-04\n",
      "Epoch: 18010 | training loss: 7.2757e-04 | validation loss: 1.2118e-04\n",
      "Epoch: 18020 | training loss: 7.2766e-04 | validation loss: 1.2157e-04\n",
      "Epoch: 18030 | training loss: 7.3604e-04 | validation loss: 1.2923e-04\n",
      "Epoch: 18040 | training loss: 7.2903e-04 | validation loss: 1.2145e-04\n",
      "Epoch: 18050 | training loss: 7.2737e-04 | validation loss: 1.2084e-04\n",
      "Epoch: 18060 | training loss: 7.2700e-04 | validation loss: 1.2137e-04\n",
      "Epoch: 18070 | training loss: 7.2673e-04 | validation loss: 1.2112e-04\n",
      "Epoch: 18080 | training loss: 7.2655e-04 | validation loss: 1.2077e-04\n",
      "Epoch: 18090 | training loss: 7.2637e-04 | validation loss: 1.2082e-04\n",
      "Epoch: 18100 | training loss: 7.2622e-04 | validation loss: 1.2084e-04\n",
      "Epoch: 18110 | training loss: 7.2607e-04 | validation loss: 1.2072e-04\n",
      "Epoch: 18120 | training loss: 7.2591e-04 | validation loss: 1.2074e-04\n",
      "Epoch: 18130 | training loss: 7.2576e-04 | validation loss: 1.2067e-04\n",
      "Epoch: 18140 | training loss: 7.2561e-04 | validation loss: 1.2065e-04\n",
      "Epoch: 18150 | training loss: 7.2546e-04 | validation loss: 1.2060e-04\n",
      "Epoch: 18160 | training loss: 7.2530e-04 | validation loss: 1.2057e-04\n",
      "Epoch: 18170 | training loss: 7.2515e-04 | validation loss: 1.2053e-04\n",
      "Epoch: 18180 | training loss: 7.2500e-04 | validation loss: 1.2050e-04\n",
      "Epoch: 18190 | training loss: 7.2484e-04 | validation loss: 1.2046e-04\n",
      "Epoch: 18200 | training loss: 7.2469e-04 | validation loss: 1.2045e-04\n",
      "Epoch: 18210 | training loss: 7.2463e-04 | validation loss: 1.2065e-04\n",
      "Epoch: 18220 | training loss: 7.3211e-04 | validation loss: 1.2767e-04\n",
      "Epoch: 18230 | training loss: 7.2850e-04 | validation loss: 1.2197e-04\n",
      "Epoch: 18240 | training loss: 7.2449e-04 | validation loss: 1.2014e-04\n",
      "Epoch: 18250 | training loss: 7.2403e-04 | validation loss: 1.2055e-04\n",
      "Epoch: 18260 | training loss: 7.2398e-04 | validation loss: 1.2066e-04\n",
      "Epoch: 18270 | training loss: 7.2365e-04 | validation loss: 1.2027e-04\n",
      "Epoch: 18280 | training loss: 7.2351e-04 | validation loss: 1.2009e-04\n",
      "Epoch: 18290 | training loss: 7.2335e-04 | validation loss: 1.2009e-04\n",
      "Epoch: 18300 | training loss: 7.2320e-04 | validation loss: 1.2012e-04\n",
      "Epoch: 18310 | training loss: 7.2305e-04 | validation loss: 1.2003e-04\n",
      "Epoch: 18320 | training loss: 7.2290e-04 | validation loss: 1.2000e-04\n",
      "Epoch: 18330 | training loss: 7.2275e-04 | validation loss: 1.1998e-04\n",
      "Epoch: 18340 | training loss: 7.2260e-04 | validation loss: 1.1994e-04\n",
      "Epoch: 18350 | training loss: 7.2245e-04 | validation loss: 1.1991e-04\n",
      "Epoch: 18360 | training loss: 7.2230e-04 | validation loss: 1.1987e-04\n",
      "Epoch: 18370 | training loss: 7.2215e-04 | validation loss: 1.1984e-04\n",
      "Epoch: 18380 | training loss: 7.2199e-04 | validation loss: 1.1980e-04\n",
      "Epoch: 18390 | training loss: 7.2184e-04 | validation loss: 1.1977e-04\n",
      "Epoch: 18400 | training loss: 7.2169e-04 | validation loss: 1.1973e-04\n",
      "Epoch: 18410 | training loss: 7.2153e-04 | validation loss: 1.1970e-04\n",
      "Epoch: 18420 | training loss: 7.2138e-04 | validation loss: 1.1967e-04\n",
      "Epoch: 18430 | training loss: 7.2125e-04 | validation loss: 1.1974e-04\n",
      "Epoch: 18440 | training loss: 7.2552e-04 | validation loss: 1.2394e-04\n",
      "Epoch: 18450 | training loss: 7.2626e-04 | validation loss: 1.2231e-04\n",
      "Epoch: 18460 | training loss: 7.2136e-04 | validation loss: 1.2027e-04\n",
      "Epoch: 18470 | training loss: 7.2074e-04 | validation loss: 1.1999e-04\n",
      "Epoch: 18480 | training loss: 7.2050e-04 | validation loss: 1.1960e-04\n",
      "Epoch: 18490 | training loss: 7.2038e-04 | validation loss: 1.1936e-04\n",
      "Epoch: 18500 | training loss: 7.2024e-04 | validation loss: 1.1934e-04\n",
      "Epoch: 18510 | training loss: 7.2008e-04 | validation loss: 1.1940e-04\n",
      "Epoch: 18520 | training loss: 7.1992e-04 | validation loss: 1.1936e-04\n",
      "Epoch: 18530 | training loss: 7.1978e-04 | validation loss: 1.1931e-04\n",
      "Epoch: 18540 | training loss: 7.1963e-04 | validation loss: 1.1930e-04\n",
      "Epoch: 18550 | training loss: 7.1949e-04 | validation loss: 1.1926e-04\n",
      "Epoch: 18560 | training loss: 7.1934e-04 | validation loss: 1.1923e-04\n",
      "Epoch: 18570 | training loss: 7.1919e-04 | validation loss: 1.1920e-04\n",
      "Epoch: 18580 | training loss: 7.1904e-04 | validation loss: 1.1917e-04\n",
      "Epoch: 18590 | training loss: 7.1890e-04 | validation loss: 1.1913e-04\n",
      "Epoch: 18600 | training loss: 7.1875e-04 | validation loss: 1.1910e-04\n",
      "Epoch: 18610 | training loss: 7.1860e-04 | validation loss: 1.1907e-04\n",
      "Epoch: 18620 | training loss: 7.1845e-04 | validation loss: 1.1904e-04\n",
      "Epoch: 18630 | training loss: 7.1830e-04 | validation loss: 1.1901e-04\n",
      "Epoch: 18640 | training loss: 7.1815e-04 | validation loss: 1.1898e-04\n",
      "Epoch: 18650 | training loss: 7.1800e-04 | validation loss: 1.1899e-04\n",
      "Epoch: 18660 | training loss: 7.1792e-04 | validation loss: 1.1940e-04\n",
      "Epoch: 18670 | training loss: 7.2303e-04 | validation loss: 1.2632e-04\n",
      "Epoch: 18680 | training loss: 7.1776e-04 | validation loss: 1.1971e-04\n",
      "Epoch: 18690 | training loss: 7.1745e-04 | validation loss: 1.1915e-04\n",
      "Epoch: 18700 | training loss: 7.1730e-04 | validation loss: 1.1907e-04\n",
      "Epoch: 18710 | training loss: 7.1715e-04 | validation loss: 1.1889e-04\n",
      "Epoch: 18720 | training loss: 7.1701e-04 | validation loss: 1.1890e-04\n",
      "Epoch: 18730 | training loss: 7.1685e-04 | validation loss: 1.1869e-04\n",
      "Epoch: 18740 | training loss: 7.1671e-04 | validation loss: 1.1862e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18750 | training loss: 7.1656e-04 | validation loss: 1.1859e-04\n",
      "Epoch: 18760 | training loss: 7.1642e-04 | validation loss: 1.1857e-04\n",
      "Epoch: 18770 | training loss: 7.1628e-04 | validation loss: 1.1858e-04\n",
      "Epoch: 18780 | training loss: 7.1625e-04 | validation loss: 1.1880e-04\n",
      "Epoch: 18790 | training loss: 7.2349e-04 | validation loss: 1.2542e-04\n",
      "Epoch: 18800 | training loss: 7.1994e-04 | validation loss: 1.2016e-04\n",
      "Epoch: 18810 | training loss: 7.1586e-04 | validation loss: 1.1829e-04\n",
      "Epoch: 18820 | training loss: 7.1587e-04 | validation loss: 1.1893e-04\n",
      "Epoch: 18830 | training loss: 7.1558e-04 | validation loss: 1.1869e-04\n",
      "Epoch: 18840 | training loss: 7.1532e-04 | validation loss: 1.1831e-04\n",
      "Epoch: 18850 | training loss: 7.1519e-04 | validation loss: 1.1827e-04\n",
      "Epoch: 18860 | training loss: 7.1504e-04 | validation loss: 1.1835e-04\n",
      "Epoch: 18870 | training loss: 7.1490e-04 | validation loss: 1.1830e-04\n",
      "Epoch: 18880 | training loss: 7.1476e-04 | validation loss: 1.1824e-04\n",
      "Epoch: 18890 | training loss: 7.1462e-04 | validation loss: 1.1825e-04\n",
      "Epoch: 18900 | training loss: 7.1448e-04 | validation loss: 1.1820e-04\n",
      "Epoch: 18910 | training loss: 7.1434e-04 | validation loss: 1.1818e-04\n",
      "Epoch: 18920 | training loss: 7.1420e-04 | validation loss: 1.1815e-04\n",
      "Epoch: 18930 | training loss: 7.1406e-04 | validation loss: 1.1812e-04\n",
      "Epoch: 18940 | training loss: 7.1392e-04 | validation loss: 1.1809e-04\n",
      "Epoch: 18950 | training loss: 7.1378e-04 | validation loss: 1.1807e-04\n",
      "Epoch: 18960 | training loss: 7.1364e-04 | validation loss: 1.1804e-04\n",
      "Epoch: 18970 | training loss: 7.1350e-04 | validation loss: 1.1801e-04\n",
      "Epoch: 18980 | training loss: 7.1335e-04 | validation loss: 1.1797e-04\n",
      "Epoch: 18990 | training loss: 7.1326e-04 | validation loss: 1.1787e-04\n",
      "Epoch: 19000 | training loss: 7.1938e-04 | validation loss: 1.2111e-04\n",
      "Epoch: 19010 | training loss: 7.1860e-04 | validation loss: 1.2337e-04\n",
      "Epoch: 19020 | training loss: 7.1348e-04 | validation loss: 1.1855e-04\n",
      "Epoch: 19030 | training loss: 7.1271e-04 | validation loss: 1.1759e-04\n",
      "Epoch: 19040 | training loss: 7.1262e-04 | validation loss: 1.1758e-04\n",
      "Epoch: 19050 | training loss: 7.1247e-04 | validation loss: 1.1774e-04\n",
      "Epoch: 19060 | training loss: 7.1229e-04 | validation loss: 1.1785e-04\n",
      "Epoch: 19070 | training loss: 7.1213e-04 | validation loss: 1.1783e-04\n",
      "Epoch: 19080 | training loss: 7.1200e-04 | validation loss: 1.1772e-04\n",
      "Epoch: 19090 | training loss: 7.1186e-04 | validation loss: 1.1769e-04\n",
      "Epoch: 19100 | training loss: 7.1173e-04 | validation loss: 1.1770e-04\n",
      "Epoch: 19110 | training loss: 7.1159e-04 | validation loss: 1.1766e-04\n",
      "Epoch: 19120 | training loss: 7.1145e-04 | validation loss: 1.1763e-04\n",
      "Epoch: 19130 | training loss: 7.1132e-04 | validation loss: 1.1761e-04\n",
      "Epoch: 19140 | training loss: 7.1118e-04 | validation loss: 1.1758e-04\n",
      "Epoch: 19150 | training loss: 7.1104e-04 | validation loss: 1.1756e-04\n",
      "Epoch: 19160 | training loss: 7.1090e-04 | validation loss: 1.1753e-04\n",
      "Epoch: 19170 | training loss: 7.1076e-04 | validation loss: 1.1751e-04\n",
      "Epoch: 19180 | training loss: 7.1062e-04 | validation loss: 1.1748e-04\n",
      "Epoch: 19190 | training loss: 7.1048e-04 | validation loss: 1.1746e-04\n",
      "Epoch: 19200 | training loss: 7.1034e-04 | validation loss: 1.1743e-04\n",
      "Epoch: 19210 | training loss: 7.1020e-04 | validation loss: 1.1741e-04\n",
      "Epoch: 19220 | training loss: 7.1006e-04 | validation loss: 1.1739e-04\n",
      "Epoch: 19230 | training loss: 7.0992e-04 | validation loss: 1.1750e-04\n",
      "Epoch: 19240 | training loss: 7.1107e-04 | validation loss: 1.1997e-04\n",
      "Epoch: 19250 | training loss: 7.1763e-04 | validation loss: 1.2048e-04\n",
      "Epoch: 19260 | training loss: 7.1164e-04 | validation loss: 1.1646e-04\n",
      "Epoch: 19270 | training loss: 7.0960e-04 | validation loss: 1.1669e-04\n",
      "Epoch: 19280 | training loss: 7.0949e-04 | validation loss: 1.1809e-04\n",
      "Epoch: 19290 | training loss: 7.0919e-04 | validation loss: 1.1753e-04\n",
      "Epoch: 19300 | training loss: 7.0900e-04 | validation loss: 1.1711e-04\n",
      "Epoch: 19310 | training loss: 7.0888e-04 | validation loss: 1.1705e-04\n",
      "Epoch: 19320 | training loss: 7.0875e-04 | validation loss: 1.1704e-04\n",
      "Epoch: 19330 | training loss: 7.0861e-04 | validation loss: 1.1711e-04\n",
      "Epoch: 19340 | training loss: 7.0848e-04 | validation loss: 1.1709e-04\n",
      "Epoch: 19350 | training loss: 7.0835e-04 | validation loss: 1.1706e-04\n",
      "Epoch: 19360 | training loss: 7.0822e-04 | validation loss: 1.1704e-04\n",
      "Epoch: 19370 | training loss: 7.0809e-04 | validation loss: 1.1701e-04\n",
      "Epoch: 19380 | training loss: 7.0796e-04 | validation loss: 1.1698e-04\n",
      "Epoch: 19390 | training loss: 7.0783e-04 | validation loss: 1.1695e-04\n",
      "Epoch: 19400 | training loss: 7.0770e-04 | validation loss: 1.1694e-04\n",
      "Epoch: 19410 | training loss: 7.0764e-04 | validation loss: 1.1710e-04\n",
      "Epoch: 19420 | training loss: 7.1560e-04 | validation loss: 1.2422e-04\n",
      "Epoch: 19430 | training loss: 7.1226e-04 | validation loss: 1.1914e-04\n",
      "Epoch: 19440 | training loss: 7.0831e-04 | validation loss: 1.1701e-04\n",
      "Epoch: 19450 | training loss: 7.0710e-04 | validation loss: 1.1672e-04\n",
      "Epoch: 19460 | training loss: 7.0699e-04 | validation loss: 1.1696e-04\n",
      "Epoch: 19470 | training loss: 7.0689e-04 | validation loss: 1.1699e-04\n",
      "Epoch: 19480 | training loss: 7.0670e-04 | validation loss: 1.1683e-04\n",
      "Epoch: 19490 | training loss: 7.0657e-04 | validation loss: 1.1671e-04\n",
      "Epoch: 19500 | training loss: 7.0644e-04 | validation loss: 1.1668e-04\n",
      "Epoch: 19510 | training loss: 7.0631e-04 | validation loss: 1.1670e-04\n",
      "Epoch: 19520 | training loss: 7.0619e-04 | validation loss: 1.1668e-04\n",
      "Epoch: 19530 | training loss: 7.0606e-04 | validation loss: 1.1664e-04\n",
      "Epoch: 19540 | training loss: 7.0594e-04 | validation loss: 1.1663e-04\n",
      "Epoch: 19550 | training loss: 7.0581e-04 | validation loss: 1.1660e-04\n",
      "Epoch: 19560 | training loss: 7.0568e-04 | validation loss: 1.1658e-04\n",
      "Epoch: 19570 | training loss: 7.0555e-04 | validation loss: 1.1656e-04\n",
      "Epoch: 19580 | training loss: 7.0542e-04 | validation loss: 1.1654e-04\n",
      "Epoch: 19590 | training loss: 7.0529e-04 | validation loss: 1.1651e-04\n",
      "Epoch: 19600 | training loss: 7.0516e-04 | validation loss: 1.1649e-04\n",
      "Epoch: 19610 | training loss: 7.0503e-04 | validation loss: 1.1647e-04\n",
      "Epoch: 19620 | training loss: 7.0490e-04 | validation loss: 1.1645e-04\n",
      "Epoch: 19630 | training loss: 7.0477e-04 | validation loss: 1.1643e-04\n",
      "Epoch: 19640 | training loss: 7.0464e-04 | validation loss: 1.1641e-04\n",
      "Epoch: 19650 | training loss: 7.0452e-04 | validation loss: 1.1647e-04\n",
      "Epoch: 19660 | training loss: 7.0755e-04 | validation loss: 1.1955e-04\n",
      "Epoch: 19670 | training loss: 7.0775e-04 | validation loss: 1.1798e-04\n",
      "Epoch: 19680 | training loss: 7.0416e-04 | validation loss: 1.1651e-04\n",
      "Epoch: 19690 | training loss: 7.0408e-04 | validation loss: 1.1669e-04\n",
      "Epoch: 19700 | training loss: 7.0399e-04 | validation loss: 1.1668e-04\n",
      "Epoch: 19710 | training loss: 7.0385e-04 | validation loss: 1.1657e-04\n",
      "Epoch: 19720 | training loss: 7.0368e-04 | validation loss: 1.1642e-04\n",
      "Epoch: 19730 | training loss: 7.0352e-04 | validation loss: 1.1627e-04\n",
      "Epoch: 19740 | training loss: 7.0339e-04 | validation loss: 1.1618e-04\n",
      "Epoch: 19750 | training loss: 7.0327e-04 | validation loss: 1.1616e-04\n",
      "Epoch: 19760 | training loss: 7.0314e-04 | validation loss: 1.1618e-04\n",
      "Epoch: 19770 | training loss: 7.0302e-04 | validation loss: 1.1617e-04\n",
      "Epoch: 19780 | training loss: 7.0289e-04 | validation loss: 1.1614e-04\n",
      "Epoch: 19790 | training loss: 7.0277e-04 | validation loss: 1.1612e-04\n",
      "Epoch: 19800 | training loss: 7.0264e-04 | validation loss: 1.1610e-04\n",
      "Epoch: 19810 | training loss: 7.0252e-04 | validation loss: 1.1608e-04\n",
      "Epoch: 19820 | training loss: 7.0239e-04 | validation loss: 1.1606e-04\n",
      "Epoch: 19830 | training loss: 7.0226e-04 | validation loss: 1.1604e-04\n",
      "Epoch: 19840 | training loss: 7.0213e-04 | validation loss: 1.1602e-04\n",
      "Epoch: 19850 | training loss: 7.0201e-04 | validation loss: 1.1600e-04\n",
      "Epoch: 19860 | training loss: 7.0188e-04 | validation loss: 1.1598e-04\n",
      "Epoch: 19870 | training loss: 7.0175e-04 | validation loss: 1.1596e-04\n",
      "Epoch: 19880 | training loss: 7.0162e-04 | validation loss: 1.1594e-04\n",
      "Epoch: 19890 | training loss: 7.0149e-04 | validation loss: 1.1592e-04\n",
      "Epoch: 19900 | training loss: 7.0136e-04 | validation loss: 1.1591e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19910 | training loss: 7.0122e-04 | validation loss: 1.1589e-04\n",
      "Epoch: 19920 | training loss: 7.0111e-04 | validation loss: 1.1591e-04\n",
      "Epoch: 19930 | training loss: 7.0447e-04 | validation loss: 1.1886e-04\n",
      "Epoch: 19940 | training loss: 7.0736e-04 | validation loss: 1.2065e-04\n",
      "Epoch: 19950 | training loss: 7.0319e-04 | validation loss: 1.1875e-04\n",
      "Epoch: 19960 | training loss: 7.0135e-04 | validation loss: 1.1724e-04\n",
      "Epoch: 19970 | training loss: 7.0050e-04 | validation loss: 1.1599e-04\n",
      "Epoch: 19980 | training loss: 7.0045e-04 | validation loss: 1.1562e-04\n",
      "Epoch: 19990 | training loss: 7.0029e-04 | validation loss: 1.1558e-04\n",
      "Epoch: 20000 | training loss: 7.0014e-04 | validation loss: 1.1563e-04\n",
      "Epoch: 20010 | training loss: 7.0001e-04 | validation loss: 1.1569e-04\n",
      "Epoch: 20020 | training loss: 6.9990e-04 | validation loss: 1.1571e-04\n",
      "Epoch: 20030 | training loss: 6.9978e-04 | validation loss: 1.1570e-04\n",
      "Epoch: 20040 | training loss: 6.9966e-04 | validation loss: 1.1566e-04\n",
      "Epoch: 20050 | training loss: 6.9954e-04 | validation loss: 1.1564e-04\n",
      "Epoch: 20060 | training loss: 6.9942e-04 | validation loss: 1.1562e-04\n",
      "Epoch: 20070 | training loss: 6.9930e-04 | validation loss: 1.1560e-04\n",
      "Epoch: 20080 | training loss: 6.9917e-04 | validation loss: 1.1558e-04\n",
      "Epoch: 20090 | training loss: 6.9905e-04 | validation loss: 1.1556e-04\n",
      "Epoch: 20100 | training loss: 6.9893e-04 | validation loss: 1.1554e-04\n",
      "Epoch: 20110 | training loss: 6.9881e-04 | validation loss: 1.1552e-04\n",
      "Epoch: 20120 | training loss: 6.9868e-04 | validation loss: 1.1550e-04\n",
      "Epoch: 20130 | training loss: 6.9856e-04 | validation loss: 1.1549e-04\n",
      "Epoch: 20140 | training loss: 6.9844e-04 | validation loss: 1.1547e-04\n",
      "Epoch: 20150 | training loss: 6.9831e-04 | validation loss: 1.1545e-04\n",
      "Epoch: 20160 | training loss: 6.9819e-04 | validation loss: 1.1543e-04\n",
      "Epoch: 20170 | training loss: 6.9806e-04 | validation loss: 1.1542e-04\n",
      "Epoch: 20180 | training loss: 6.9794e-04 | validation loss: 1.1547e-04\n",
      "Epoch: 20190 | training loss: 6.9907e-04 | validation loss: 1.1757e-04\n",
      "Epoch: 20200 | training loss: 6.9890e-04 | validation loss: 1.1463e-04\n",
      "Epoch: 20210 | training loss: 7.0001e-04 | validation loss: 1.1628e-04\n",
      "Epoch: 20220 | training loss: 6.9835e-04 | validation loss: 1.1585e-04\n",
      "Epoch: 20230 | training loss: 6.9754e-04 | validation loss: 1.1579e-04\n",
      "Epoch: 20240 | training loss: 6.9728e-04 | validation loss: 1.1564e-04\n",
      "Epoch: 20250 | training loss: 6.9714e-04 | validation loss: 1.1541e-04\n",
      "Epoch: 20260 | training loss: 6.9702e-04 | validation loss: 1.1527e-04\n",
      "Epoch: 20270 | training loss: 6.9689e-04 | validation loss: 1.1523e-04\n",
      "Epoch: 20280 | training loss: 6.9678e-04 | validation loss: 1.1523e-04\n",
      "Epoch: 20290 | training loss: 6.9666e-04 | validation loss: 1.1520e-04\n",
      "Epoch: 20300 | training loss: 6.9655e-04 | validation loss: 1.1517e-04\n",
      "Epoch: 20310 | training loss: 6.9643e-04 | validation loss: 1.1517e-04\n",
      "Epoch: 20320 | training loss: 6.9631e-04 | validation loss: 1.1515e-04\n",
      "Epoch: 20330 | training loss: 6.9620e-04 | validation loss: 1.1514e-04\n",
      "Epoch: 20340 | training loss: 6.9608e-04 | validation loss: 1.1512e-04\n",
      "Epoch: 20350 | training loss: 6.9596e-04 | validation loss: 1.1510e-04\n",
      "Epoch: 20360 | training loss: 6.9584e-04 | validation loss: 1.1509e-04\n",
      "Epoch: 20370 | training loss: 6.9572e-04 | validation loss: 1.1507e-04\n",
      "Epoch: 20380 | training loss: 6.9560e-04 | validation loss: 1.1505e-04\n",
      "Epoch: 20390 | training loss: 6.9548e-04 | validation loss: 1.1503e-04\n",
      "Epoch: 20400 | training loss: 6.9536e-04 | validation loss: 1.1502e-04\n",
      "Epoch: 20410 | training loss: 6.9524e-04 | validation loss: 1.1500e-04\n",
      "Epoch: 20420 | training loss: 6.9512e-04 | validation loss: 1.1498e-04\n",
      "Epoch: 20430 | training loss: 6.9500e-04 | validation loss: 1.1498e-04\n",
      "Epoch: 20440 | training loss: 6.9496e-04 | validation loss: 1.1515e-04\n",
      "Epoch: 20450 | training loss: 7.0835e-04 | validation loss: 1.2660e-04\n",
      "Epoch: 20460 | training loss: 6.9599e-04 | validation loss: 1.1519e-04\n",
      "Epoch: 20470 | training loss: 6.9535e-04 | validation loss: 1.1494e-04\n",
      "Epoch: 20480 | training loss: 6.9470e-04 | validation loss: 1.1475e-04\n",
      "Epoch: 20490 | training loss: 6.9441e-04 | validation loss: 1.1474e-04\n",
      "Epoch: 20500 | training loss: 6.9425e-04 | validation loss: 1.1476e-04\n",
      "Epoch: 20510 | training loss: 6.9411e-04 | validation loss: 1.1479e-04\n",
      "Epoch: 20520 | training loss: 6.9399e-04 | validation loss: 1.1481e-04\n",
      "Epoch: 20530 | training loss: 6.9386e-04 | validation loss: 1.1482e-04\n",
      "Epoch: 20540 | training loss: 6.9375e-04 | validation loss: 1.1482e-04\n",
      "Epoch: 20550 | training loss: 6.9363e-04 | validation loss: 1.1481e-04\n",
      "Epoch: 20560 | training loss: 6.9352e-04 | validation loss: 1.1479e-04\n",
      "Epoch: 20570 | training loss: 6.9341e-04 | validation loss: 1.1477e-04\n",
      "Epoch: 20580 | training loss: 6.9329e-04 | validation loss: 1.1475e-04\n",
      "Epoch: 20590 | training loss: 6.9318e-04 | validation loss: 1.1474e-04\n",
      "Epoch: 20600 | training loss: 6.9306e-04 | validation loss: 1.1473e-04\n",
      "Epoch: 20610 | training loss: 6.9294e-04 | validation loss: 1.1471e-04\n",
      "Epoch: 20620 | training loss: 6.9283e-04 | validation loss: 1.1470e-04\n",
      "Epoch: 20630 | training loss: 6.9271e-04 | validation loss: 1.1468e-04\n",
      "Epoch: 20640 | training loss: 6.9259e-04 | validation loss: 1.1467e-04\n",
      "Epoch: 20650 | training loss: 6.9247e-04 | validation loss: 1.1465e-04\n",
      "Epoch: 20660 | training loss: 6.9236e-04 | validation loss: 1.1464e-04\n",
      "Epoch: 20670 | training loss: 6.9224e-04 | validation loss: 1.1463e-04\n",
      "Epoch: 20680 | training loss: 6.9212e-04 | validation loss: 1.1461e-04\n",
      "Epoch: 20690 | training loss: 6.9200e-04 | validation loss: 1.1460e-04\n",
      "Epoch: 20700 | training loss: 6.9188e-04 | validation loss: 1.1458e-04\n",
      "Epoch: 20710 | training loss: 6.9176e-04 | validation loss: 1.1456e-04\n",
      "Epoch: 20720 | training loss: 6.9163e-04 | validation loss: 1.1453e-04\n",
      "Epoch: 20730 | training loss: 6.9155e-04 | validation loss: 1.1427e-04\n",
      "Epoch: 20740 | training loss: 6.9608e-04 | validation loss: 1.1444e-04\n",
      "Epoch: 20750 | training loss: 6.9491e-04 | validation loss: 1.1733e-04\n",
      "Epoch: 20760 | training loss: 6.9210e-04 | validation loss: 1.1396e-04\n",
      "Epoch: 20770 | training loss: 6.9220e-04 | validation loss: 1.1486e-04\n",
      "Epoch: 20780 | training loss: 6.9117e-04 | validation loss: 1.1428e-04\n",
      "Epoch: 20790 | training loss: 6.9086e-04 | validation loss: 1.1469e-04\n",
      "Epoch: 20800 | training loss: 6.9075e-04 | validation loss: 1.1464e-04\n",
      "Epoch: 20810 | training loss: 6.9063e-04 | validation loss: 1.1443e-04\n",
      "Epoch: 20820 | training loss: 6.9051e-04 | validation loss: 1.1441e-04\n",
      "Epoch: 20830 | training loss: 6.9040e-04 | validation loss: 1.1435e-04\n",
      "Epoch: 20840 | training loss: 6.9029e-04 | validation loss: 1.1434e-04\n",
      "Epoch: 20850 | training loss: 6.9018e-04 | validation loss: 1.1435e-04\n",
      "Epoch: 20860 | training loss: 6.9006e-04 | validation loss: 1.1433e-04\n",
      "Epoch: 20870 | training loss: 6.8995e-04 | validation loss: 1.1432e-04\n",
      "Epoch: 20880 | training loss: 6.8984e-04 | validation loss: 1.1430e-04\n",
      "Epoch: 20890 | training loss: 6.8972e-04 | validation loss: 1.1429e-04\n",
      "Epoch: 20900 | training loss: 6.8961e-04 | validation loss: 1.1427e-04\n",
      "Epoch: 20910 | training loss: 6.8950e-04 | validation loss: 1.1424e-04\n",
      "Epoch: 20920 | training loss: 6.9048e-04 | validation loss: 1.1457e-04\n",
      "Epoch: 20930 | training loss: 6.8943e-04 | validation loss: 1.1404e-04\n",
      "Epoch: 20940 | training loss: 6.8972e-04 | validation loss: 1.1417e-04\n",
      "Epoch: 20950 | training loss: 6.8908e-04 | validation loss: 1.1418e-04\n",
      "Epoch: 20960 | training loss: 6.8900e-04 | validation loss: 1.1436e-04\n",
      "Epoch: 20970 | training loss: 6.8891e-04 | validation loss: 1.1435e-04\n",
      "Epoch: 20980 | training loss: 6.8879e-04 | validation loss: 1.1427e-04\n",
      "Epoch: 20990 | training loss: 6.8866e-04 | validation loss: 1.1422e-04\n",
      "Epoch: 21000 | training loss: 6.8855e-04 | validation loss: 1.1419e-04\n",
      "Epoch: 21010 | training loss: 6.8845e-04 | validation loss: 1.1416e-04\n",
      "Epoch: 21020 | training loss: 6.8834e-04 | validation loss: 1.1414e-04\n",
      "Epoch: 21030 | training loss: 6.8824e-04 | validation loss: 1.1412e-04\n",
      "Epoch: 21040 | training loss: 6.8813e-04 | validation loss: 1.1411e-04\n",
      "Epoch: 21050 | training loss: 6.8802e-04 | validation loss: 1.1411e-04\n",
      "Epoch: 21060 | training loss: 6.8792e-04 | validation loss: 1.1410e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21070 | training loss: 6.8781e-04 | validation loss: 1.1408e-04\n",
      "Epoch: 21080 | training loss: 6.8770e-04 | validation loss: 1.1407e-04\n",
      "Epoch: 21090 | training loss: 6.8760e-04 | validation loss: 1.1406e-04\n",
      "Epoch: 21100 | training loss: 6.8749e-04 | validation loss: 1.1405e-04\n",
      "Epoch: 21110 | training loss: 6.8738e-04 | validation loss: 1.1403e-04\n",
      "Epoch: 21120 | training loss: 6.8727e-04 | validation loss: 1.1402e-04\n",
      "Epoch: 21130 | training loss: 6.8716e-04 | validation loss: 1.1401e-04\n",
      "Epoch: 21140 | training loss: 6.8705e-04 | validation loss: 1.1400e-04\n",
      "Epoch: 21150 | training loss: 6.8694e-04 | validation loss: 1.1399e-04\n",
      "Epoch: 21160 | training loss: 6.8683e-04 | validation loss: 1.1397e-04\n",
      "Epoch: 21170 | training loss: 6.8672e-04 | validation loss: 1.1396e-04\n",
      "Epoch: 21180 | training loss: 6.8661e-04 | validation loss: 1.1395e-04\n",
      "Epoch: 21190 | training loss: 6.8649e-04 | validation loss: 1.1394e-04\n",
      "Epoch: 21200 | training loss: 6.8638e-04 | validation loss: 1.1392e-04\n",
      "Epoch: 21210 | training loss: 6.8627e-04 | validation loss: 1.1391e-04\n",
      "Epoch: 21220 | training loss: 6.8615e-04 | validation loss: 1.1390e-04\n",
      "Epoch: 21230 | training loss: 6.8604e-04 | validation loss: 1.1387e-04\n",
      "Epoch: 21240 | training loss: 6.8717e-04 | validation loss: 1.1434e-04\n",
      "Epoch: 21250 | training loss: 6.8602e-04 | validation loss: 1.1368e-04\n",
      "Epoch: 21260 | training loss: 6.8591e-04 | validation loss: 1.1340e-04\n",
      "Epoch: 21270 | training loss: 6.8625e-04 | validation loss: 1.1388e-04\n",
      "Epoch: 21280 | training loss: 6.8601e-04 | validation loss: 1.1391e-04\n",
      "Epoch: 21290 | training loss: 6.8557e-04 | validation loss: 1.1376e-04\n",
      "Epoch: 21300 | training loss: 6.8534e-04 | validation loss: 1.1374e-04\n",
      "Epoch: 21310 | training loss: 6.8521e-04 | validation loss: 1.1376e-04\n",
      "Epoch: 21320 | training loss: 6.8511e-04 | validation loss: 1.1378e-04\n",
      "Epoch: 21330 | training loss: 6.8500e-04 | validation loss: 1.1379e-04\n",
      "Epoch: 21340 | training loss: 6.8490e-04 | validation loss: 1.1379e-04\n",
      "Epoch: 21350 | training loss: 6.8480e-04 | validation loss: 1.1378e-04\n",
      "Epoch: 21360 | training loss: 6.8469e-04 | validation loss: 1.1376e-04\n",
      "Epoch: 21370 | training loss: 6.8459e-04 | validation loss: 1.1375e-04\n",
      "Epoch: 21380 | training loss: 6.8448e-04 | validation loss: 1.1375e-04\n",
      "Epoch: 21390 | training loss: 6.8438e-04 | validation loss: 1.1374e-04\n",
      "Epoch: 21400 | training loss: 6.8427e-04 | validation loss: 1.1372e-04\n",
      "Epoch: 21410 | training loss: 6.8417e-04 | validation loss: 1.1371e-04\n",
      "Epoch: 21420 | training loss: 6.8406e-04 | validation loss: 1.1370e-04\n",
      "Epoch: 21430 | training loss: 6.8395e-04 | validation loss: 1.1369e-04\n",
      "Epoch: 21440 | training loss: 6.8385e-04 | validation loss: 1.1368e-04\n",
      "Epoch: 21450 | training loss: 6.8374e-04 | validation loss: 1.1367e-04\n",
      "Epoch: 21460 | training loss: 6.8363e-04 | validation loss: 1.1366e-04\n",
      "Epoch: 21470 | training loss: 6.8352e-04 | validation loss: 1.1365e-04\n",
      "Epoch: 21480 | training loss: 6.8341e-04 | validation loss: 1.1364e-04\n",
      "Epoch: 21490 | training loss: 6.8330e-04 | validation loss: 1.1363e-04\n",
      "Epoch: 21500 | training loss: 6.8319e-04 | validation loss: 1.1362e-04\n",
      "Epoch: 21510 | training loss: 6.8308e-04 | validation loss: 1.1361e-04\n",
      "Epoch: 21520 | training loss: 6.8297e-04 | validation loss: 1.1360e-04\n",
      "Epoch: 21530 | training loss: 6.8286e-04 | validation loss: 1.1361e-04\n",
      "Epoch: 21540 | training loss: 6.8285e-04 | validation loss: 1.1411e-04\n",
      "Epoch: 21550 | training loss: 6.8830e-04 | validation loss: 1.2078e-04\n",
      "Epoch: 21560 | training loss: 6.8404e-04 | validation loss: 1.1596e-04\n",
      "Epoch: 21570 | training loss: 6.8264e-04 | validation loss: 1.1395e-04\n",
      "Epoch: 21580 | training loss: 6.8262e-04 | validation loss: 1.1299e-04\n",
      "Epoch: 21590 | training loss: 6.8234e-04 | validation loss: 1.1332e-04\n",
      "Epoch: 21600 | training loss: 6.8214e-04 | validation loss: 1.1346e-04\n",
      "Epoch: 21610 | training loss: 6.8204e-04 | validation loss: 1.1362e-04\n",
      "Epoch: 21620 | training loss: 6.8193e-04 | validation loss: 1.1357e-04\n",
      "Epoch: 21630 | training loss: 6.8182e-04 | validation loss: 1.1348e-04\n",
      "Epoch: 21640 | training loss: 6.8172e-04 | validation loss: 1.1344e-04\n",
      "Epoch: 21650 | training loss: 6.8161e-04 | validation loss: 1.1342e-04\n",
      "Epoch: 21660 | training loss: 6.8152e-04 | validation loss: 1.1339e-04\n",
      "Epoch: 21670 | training loss: 6.8160e-04 | validation loss: 1.1337e-04\n",
      "Epoch: 21680 | training loss: 6.8871e-04 | validation loss: 1.1766e-04\n",
      "Epoch: 21690 | training loss: 6.8455e-04 | validation loss: 1.1660e-04\n",
      "Epoch: 21700 | training loss: 6.8116e-04 | validation loss: 1.1332e-04\n",
      "Epoch: 21710 | training loss: 6.8137e-04 | validation loss: 1.1337e-04\n",
      "Epoch: 21720 | training loss: 6.8095e-04 | validation loss: 1.1347e-04\n",
      "Epoch: 21730 | training loss: 6.8082e-04 | validation loss: 1.1340e-04\n",
      "Epoch: 21740 | training loss: 6.8073e-04 | validation loss: 1.1329e-04\n",
      "Epoch: 21750 | training loss: 6.8061e-04 | validation loss: 1.1336e-04\n",
      "Epoch: 21760 | training loss: 6.8050e-04 | validation loss: 1.1330e-04\n",
      "Epoch: 21770 | training loss: 6.8040e-04 | validation loss: 1.1331e-04\n",
      "Epoch: 21780 | training loss: 6.8030e-04 | validation loss: 1.1329e-04\n",
      "Epoch: 21790 | training loss: 6.8020e-04 | validation loss: 1.1329e-04\n",
      "Epoch: 21800 | training loss: 6.8010e-04 | validation loss: 1.1327e-04\n",
      "Epoch: 21810 | training loss: 6.7999e-04 | validation loss: 1.1326e-04\n",
      "Epoch: 21820 | training loss: 6.7989e-04 | validation loss: 1.1325e-04\n",
      "Epoch: 21830 | training loss: 6.7979e-04 | validation loss: 1.1324e-04\n",
      "Epoch: 21840 | training loss: 6.7968e-04 | validation loss: 1.1322e-04\n",
      "Epoch: 21850 | training loss: 6.7958e-04 | validation loss: 1.1319e-04\n",
      "Epoch: 21860 | training loss: 6.8006e-04 | validation loss: 1.1332e-04\n",
      "Epoch: 21870 | training loss: 6.8788e-04 | validation loss: 1.1805e-04\n",
      "Epoch: 21880 | training loss: 6.8124e-04 | validation loss: 1.1398e-04\n",
      "Epoch: 21890 | training loss: 6.7920e-04 | validation loss: 1.1312e-04\n",
      "Epoch: 21900 | training loss: 6.7918e-04 | validation loss: 1.1336e-04\n",
      "Epoch: 21910 | training loss: 6.7912e-04 | validation loss: 1.1342e-04\n",
      "Epoch: 21920 | training loss: 6.7892e-04 | validation loss: 1.1327e-04\n",
      "Epoch: 21930 | training loss: 6.7879e-04 | validation loss: 1.1314e-04\n",
      "Epoch: 21940 | training loss: 6.7870e-04 | validation loss: 1.1311e-04\n",
      "Epoch: 21950 | training loss: 6.7859e-04 | validation loss: 1.1313e-04\n",
      "Epoch: 21960 | training loss: 6.7849e-04 | validation loss: 1.1314e-04\n",
      "Epoch: 21970 | training loss: 6.7839e-04 | validation loss: 1.1311e-04\n",
      "Epoch: 21980 | training loss: 6.7829e-04 | validation loss: 1.1310e-04\n",
      "Epoch: 21990 | training loss: 6.7819e-04 | validation loss: 1.1310e-04\n",
      "Epoch: 22000 | training loss: 6.7809e-04 | validation loss: 1.1308e-04\n",
      "Epoch: 22010 | training loss: 6.7799e-04 | validation loss: 1.1308e-04\n",
      "Epoch: 22020 | training loss: 6.7789e-04 | validation loss: 1.1307e-04\n",
      "Epoch: 22030 | training loss: 6.7779e-04 | validation loss: 1.1306e-04\n",
      "Epoch: 22040 | training loss: 6.7768e-04 | validation loss: 1.1305e-04\n",
      "Epoch: 22050 | training loss: 6.7758e-04 | validation loss: 1.1304e-04\n",
      "Epoch: 22060 | training loss: 6.7748e-04 | validation loss: 1.1303e-04\n",
      "Epoch: 22070 | training loss: 6.7738e-04 | validation loss: 1.1302e-04\n",
      "Epoch: 22080 | training loss: 6.7727e-04 | validation loss: 1.1301e-04\n",
      "Epoch: 22090 | training loss: 6.7717e-04 | validation loss: 1.1300e-04\n",
      "Epoch: 22100 | training loss: 6.7706e-04 | validation loss: 1.1299e-04\n",
      "Epoch: 22110 | training loss: 6.7697e-04 | validation loss: 1.1303e-04\n",
      "Epoch: 22120 | training loss: 6.8148e-04 | validation loss: 1.1708e-04\n",
      "Epoch: 22130 | training loss: 6.8651e-04 | validation loss: 1.1888e-04\n",
      "Epoch: 22140 | training loss: 6.7996e-04 | validation loss: 1.1497e-04\n",
      "Epoch: 22150 | training loss: 6.7749e-04 | validation loss: 1.1354e-04\n",
      "Epoch: 22160 | training loss: 6.7658e-04 | validation loss: 1.1305e-04\n",
      "Epoch: 22170 | training loss: 6.7638e-04 | validation loss: 1.1298e-04\n",
      "Epoch: 22180 | training loss: 6.7629e-04 | validation loss: 1.1298e-04\n",
      "Epoch: 22190 | training loss: 6.7620e-04 | validation loss: 1.1295e-04\n",
      "Epoch: 22200 | training loss: 6.7610e-04 | validation loss: 1.1292e-04\n",
      "Epoch: 22210 | training loss: 6.7600e-04 | validation loss: 1.1290e-04\n",
      "Epoch: 22220 | training loss: 6.7591e-04 | validation loss: 1.1290e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22230 | training loss: 6.7581e-04 | validation loss: 1.1290e-04\n",
      "Epoch: 22240 | training loss: 6.7572e-04 | validation loss: 1.1289e-04\n",
      "Epoch: 22250 | training loss: 6.7562e-04 | validation loss: 1.1288e-04\n",
      "Epoch: 22260 | training loss: 6.7552e-04 | validation loss: 1.1287e-04\n",
      "Epoch: 22270 | training loss: 6.7542e-04 | validation loss: 1.1286e-04\n",
      "Epoch: 22280 | training loss: 6.7533e-04 | validation loss: 1.1285e-04\n",
      "Epoch: 22290 | training loss: 6.7523e-04 | validation loss: 1.1285e-04\n",
      "Epoch: 22300 | training loss: 6.7513e-04 | validation loss: 1.1284e-04\n",
      "Epoch: 22310 | training loss: 6.7503e-04 | validation loss: 1.1283e-04\n",
      "Epoch: 22320 | training loss: 6.7493e-04 | validation loss: 1.1282e-04\n",
      "Epoch: 22330 | training loss: 6.7483e-04 | validation loss: 1.1281e-04\n",
      "Epoch: 22340 | training loss: 6.7473e-04 | validation loss: 1.1280e-04\n",
      "Epoch: 22350 | training loss: 6.7463e-04 | validation loss: 1.1280e-04\n",
      "Epoch: 22360 | training loss: 6.7453e-04 | validation loss: 1.1279e-04\n",
      "Epoch: 22370 | training loss: 6.7443e-04 | validation loss: 1.1278e-04\n",
      "Epoch: 22380 | training loss: 6.7433e-04 | validation loss: 1.1276e-04\n",
      "Epoch: 22390 | training loss: 6.7423e-04 | validation loss: 1.1262e-04\n",
      "Epoch: 22400 | training loss: 6.7646e-04 | validation loss: 1.1208e-04\n",
      "Epoch: 22410 | training loss: 6.7632e-04 | validation loss: 1.1565e-04\n",
      "Epoch: 22420 | training loss: 6.7480e-04 | validation loss: 1.1462e-04\n",
      "Epoch: 22430 | training loss: 6.7407e-04 | validation loss: 1.1328e-04\n",
      "Epoch: 22440 | training loss: 6.7377e-04 | validation loss: 1.1298e-04\n",
      "Epoch: 22450 | training loss: 6.7366e-04 | validation loss: 1.1284e-04\n",
      "Epoch: 22460 | training loss: 6.7355e-04 | validation loss: 1.1271e-04\n",
      "Epoch: 22470 | training loss: 6.7346e-04 | validation loss: 1.1268e-04\n",
      "Epoch: 22480 | training loss: 6.7341e-04 | validation loss: 1.1265e-04\n",
      "Epoch: 22490 | training loss: 6.7419e-04 | validation loss: 1.1300e-04\n",
      "Epoch: 22500 | training loss: 6.7675e-04 | validation loss: 1.1450e-04\n",
      "Epoch: 22510 | training loss: 6.7411e-04 | validation loss: 1.1380e-04\n",
      "Epoch: 22520 | training loss: 6.7319e-04 | validation loss: 1.1260e-04\n",
      "Epoch: 22530 | training loss: 6.7292e-04 | validation loss: 1.1273e-04\n",
      "Epoch: 22540 | training loss: 6.7280e-04 | validation loss: 1.1257e-04\n",
      "Epoch: 22550 | training loss: 6.7270e-04 | validation loss: 1.1267e-04\n",
      "Epoch: 22560 | training loss: 6.7260e-04 | validation loss: 1.1256e-04\n",
      "Epoch: 22570 | training loss: 6.7249e-04 | validation loss: 1.1259e-04\n",
      "Epoch: 22580 | training loss: 6.7240e-04 | validation loss: 1.1259e-04\n",
      "Epoch: 22590 | training loss: 6.7230e-04 | validation loss: 1.1258e-04\n",
      "Epoch: 22600 | training loss: 6.7221e-04 | validation loss: 1.1259e-04\n",
      "Epoch: 22610 | training loss: 6.7227e-04 | validation loss: 1.1281e-04\n",
      "Epoch: 22620 | training loss: 6.7706e-04 | validation loss: 1.1705e-04\n",
      "Epoch: 22630 | training loss: 6.7369e-04 | validation loss: 1.1326e-04\n",
      "Epoch: 22640 | training loss: 6.7289e-04 | validation loss: 1.1373e-04\n",
      "Epoch: 22650 | training loss: 6.7177e-04 | validation loss: 1.1247e-04\n",
      "Epoch: 22660 | training loss: 6.7168e-04 | validation loss: 1.1246e-04\n",
      "Epoch: 22670 | training loss: 6.7159e-04 | validation loss: 1.1262e-04\n",
      "Epoch: 22680 | training loss: 6.7147e-04 | validation loss: 1.1244e-04\n",
      "Epoch: 22690 | training loss: 6.7136e-04 | validation loss: 1.1252e-04\n",
      "Epoch: 22700 | training loss: 6.7126e-04 | validation loss: 1.1245e-04\n",
      "Epoch: 22710 | training loss: 6.7116e-04 | validation loss: 1.1248e-04\n",
      "Epoch: 22720 | training loss: 6.7107e-04 | validation loss: 1.1246e-04\n",
      "Epoch: 22730 | training loss: 6.7097e-04 | validation loss: 1.1244e-04\n",
      "Epoch: 22740 | training loss: 6.7087e-04 | validation loss: 1.1243e-04\n",
      "Epoch: 22750 | training loss: 6.7078e-04 | validation loss: 1.1242e-04\n",
      "Epoch: 22760 | training loss: 6.7068e-04 | validation loss: 1.1240e-04\n",
      "Epoch: 22770 | training loss: 6.7069e-04 | validation loss: 1.1236e-04\n",
      "Epoch: 22780 | training loss: 6.7695e-04 | validation loss: 1.1608e-04\n",
      "Epoch: 22790 | training loss: 6.7441e-04 | validation loss: 1.1610e-04\n",
      "Epoch: 22800 | training loss: 6.7040e-04 | validation loss: 1.1223e-04\n",
      "Epoch: 22810 | training loss: 6.7076e-04 | validation loss: 1.1245e-04\n",
      "Epoch: 22820 | training loss: 6.7012e-04 | validation loss: 1.1241e-04\n",
      "Epoch: 22830 | training loss: 6.7010e-04 | validation loss: 1.1256e-04\n",
      "Epoch: 22840 | training loss: 6.6993e-04 | validation loss: 1.1234e-04\n",
      "Epoch: 22850 | training loss: 6.6985e-04 | validation loss: 1.1233e-04\n",
      "Epoch: 22860 | training loss: 6.6975e-04 | validation loss: 1.1239e-04\n",
      "Epoch: 22870 | training loss: 6.6965e-04 | validation loss: 1.1233e-04\n",
      "Epoch: 22880 | training loss: 6.6956e-04 | validation loss: 1.1234e-04\n",
      "Epoch: 22890 | training loss: 6.6946e-04 | validation loss: 1.1233e-04\n",
      "Epoch: 22900 | training loss: 6.6937e-04 | validation loss: 1.1233e-04\n",
      "Epoch: 22910 | training loss: 6.6927e-04 | validation loss: 1.1231e-04\n",
      "Epoch: 22920 | training loss: 6.6918e-04 | validation loss: 1.1231e-04\n",
      "Epoch: 22930 | training loss: 6.6908e-04 | validation loss: 1.1230e-04\n",
      "Epoch: 22940 | training loss: 6.6899e-04 | validation loss: 1.1229e-04\n",
      "Epoch: 22950 | training loss: 6.6889e-04 | validation loss: 1.1229e-04\n",
      "Epoch: 22960 | training loss: 6.6879e-04 | validation loss: 1.1228e-04\n",
      "Epoch: 22970 | training loss: 6.6871e-04 | validation loss: 1.1230e-04\n",
      "Epoch: 22980 | training loss: 6.6986e-04 | validation loss: 1.1341e-04\n",
      "Epoch: 22990 | training loss: 6.7009e-04 | validation loss: 1.1465e-04\n",
      "Epoch: 23000 | training loss: 6.7103e-04 | validation loss: 1.1379e-04\n",
      "Epoch: 23010 | training loss: 6.6934e-04 | validation loss: 1.1210e-04\n",
      "Epoch: 23020 | training loss: 6.6858e-04 | validation loss: 1.1190e-04\n",
      "Epoch: 23030 | training loss: 6.6824e-04 | validation loss: 1.1208e-04\n",
      "Epoch: 23040 | training loss: 6.6807e-04 | validation loss: 1.1217e-04\n",
      "Epoch: 23050 | training loss: 6.6797e-04 | validation loss: 1.1219e-04\n",
      "Epoch: 23060 | training loss: 6.6788e-04 | validation loss: 1.1224e-04\n",
      "Epoch: 23070 | training loss: 6.6779e-04 | validation loss: 1.1225e-04\n",
      "Epoch: 23080 | training loss: 6.6769e-04 | validation loss: 1.1220e-04\n",
      "Epoch: 23090 | training loss: 6.6760e-04 | validation loss: 1.1218e-04\n",
      "Epoch: 23100 | training loss: 6.6751e-04 | validation loss: 1.1217e-04\n",
      "Epoch: 23110 | training loss: 6.6742e-04 | validation loss: 1.1218e-04\n",
      "Epoch: 23120 | training loss: 6.6733e-04 | validation loss: 1.1217e-04\n",
      "Epoch: 23130 | training loss: 6.6723e-04 | validation loss: 1.1215e-04\n",
      "Epoch: 23140 | training loss: 6.6714e-04 | validation loss: 1.1215e-04\n",
      "Epoch: 23150 | training loss: 6.6705e-04 | validation loss: 1.1214e-04\n",
      "Epoch: 23160 | training loss: 6.6695e-04 | validation loss: 1.1213e-04\n",
      "Epoch: 23170 | training loss: 6.6686e-04 | validation loss: 1.1212e-04\n",
      "Epoch: 23180 | training loss: 6.6676e-04 | validation loss: 1.1208e-04\n",
      "Epoch: 23190 | training loss: 6.6681e-04 | validation loss: 1.1175e-04\n",
      "Epoch: 23200 | training loss: 6.7608e-04 | validation loss: 1.1630e-04\n",
      "Epoch: 23210 | training loss: 6.6964e-04 | validation loss: 1.1305e-04\n",
      "Epoch: 23220 | training loss: 6.6682e-04 | validation loss: 1.1156e-04\n",
      "Epoch: 23230 | training loss: 6.6661e-04 | validation loss: 1.1179e-04\n",
      "Epoch: 23240 | training loss: 6.6623e-04 | validation loss: 1.1209e-04\n",
      "Epoch: 23250 | training loss: 6.6616e-04 | validation loss: 1.1223e-04\n",
      "Epoch: 23260 | training loss: 6.6606e-04 | validation loss: 1.1211e-04\n",
      "Epoch: 23270 | training loss: 6.6596e-04 | validation loss: 1.1212e-04\n",
      "Epoch: 23280 | training loss: 6.6587e-04 | validation loss: 1.1207e-04\n",
      "Epoch: 23290 | training loss: 6.6578e-04 | validation loss: 1.1205e-04\n",
      "Epoch: 23300 | training loss: 6.6569e-04 | validation loss: 1.1202e-04\n",
      "Epoch: 23310 | training loss: 6.6561e-04 | validation loss: 1.1202e-04\n",
      "Epoch: 23320 | training loss: 6.6552e-04 | validation loss: 1.1200e-04\n",
      "Epoch: 23330 | training loss: 6.6542e-04 | validation loss: 1.1199e-04\n",
      "Epoch: 23340 | training loss: 6.6533e-04 | validation loss: 1.1198e-04\n",
      "Epoch: 23350 | training loss: 6.6524e-04 | validation loss: 1.1198e-04\n",
      "Epoch: 23360 | training loss: 6.6515e-04 | validation loss: 1.1196e-04\n",
      "Epoch: 23370 | training loss: 6.6508e-04 | validation loss: 1.1192e-04\n",
      "Epoch: 23380 | training loss: 6.6685e-04 | validation loss: 1.1279e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23390 | training loss: 6.6488e-04 | validation loss: 1.1186e-04\n",
      "Epoch: 23400 | training loss: 6.6710e-04 | validation loss: 1.1294e-04\n",
      "Epoch: 23410 | training loss: 6.6555e-04 | validation loss: 1.1214e-04\n",
      "Epoch: 23420 | training loss: 6.6469e-04 | validation loss: 1.1186e-04\n",
      "Epoch: 23430 | training loss: 6.6456e-04 | validation loss: 1.1199e-04\n",
      "Epoch: 23440 | training loss: 6.6450e-04 | validation loss: 1.1203e-04\n",
      "Epoch: 23450 | training loss: 6.6437e-04 | validation loss: 1.1193e-04\n",
      "Epoch: 23460 | training loss: 6.6429e-04 | validation loss: 1.1189e-04\n",
      "Epoch: 23470 | training loss: 6.6420e-04 | validation loss: 1.1190e-04\n",
      "Epoch: 23480 | training loss: 6.6411e-04 | validation loss: 1.1191e-04\n",
      "Epoch: 23490 | training loss: 6.6402e-04 | validation loss: 1.1189e-04\n",
      "Epoch: 23500 | training loss: 6.6393e-04 | validation loss: 1.1188e-04\n",
      "Epoch: 23510 | training loss: 6.6385e-04 | validation loss: 1.1188e-04\n",
      "Epoch: 23520 | training loss: 6.6376e-04 | validation loss: 1.1187e-04\n",
      "Epoch: 23530 | training loss: 6.6367e-04 | validation loss: 1.1186e-04\n",
      "Epoch: 23540 | training loss: 6.6358e-04 | validation loss: 1.1185e-04\n",
      "Epoch: 23550 | training loss: 6.6349e-04 | validation loss: 1.1185e-04\n",
      "Epoch: 23560 | training loss: 6.6340e-04 | validation loss: 1.1184e-04\n",
      "Epoch: 23570 | training loss: 6.6331e-04 | validation loss: 1.1183e-04\n",
      "Epoch: 23580 | training loss: 6.6322e-04 | validation loss: 1.1183e-04\n",
      "Epoch: 23590 | training loss: 6.6313e-04 | validation loss: 1.1182e-04\n",
      "Epoch: 23600 | training loss: 6.6304e-04 | validation loss: 1.1181e-04\n",
      "Epoch: 23610 | training loss: 6.6295e-04 | validation loss: 1.1183e-04\n",
      "Epoch: 23620 | training loss: 6.6365e-04 | validation loss: 1.1267e-04\n",
      "Epoch: 23630 | training loss: 6.6747e-04 | validation loss: 1.1622e-04\n",
      "Epoch: 23640 | training loss: 6.6656e-04 | validation loss: 1.1513e-04\n",
      "Epoch: 23650 | training loss: 6.6394e-04 | validation loss: 1.1277e-04\n",
      "Epoch: 23660 | training loss: 6.6298e-04 | validation loss: 1.1196e-04\n",
      "Epoch: 23670 | training loss: 6.6258e-04 | validation loss: 1.1178e-04\n",
      "Epoch: 23680 | training loss: 6.6238e-04 | validation loss: 1.1179e-04\n",
      "Epoch: 23690 | training loss: 6.6226e-04 | validation loss: 1.1180e-04\n",
      "Epoch: 23700 | training loss: 6.6218e-04 | validation loss: 1.1176e-04\n",
      "Epoch: 23710 | training loss: 6.6209e-04 | validation loss: 1.1175e-04\n",
      "Epoch: 23720 | training loss: 6.6201e-04 | validation loss: 1.1176e-04\n",
      "Epoch: 23730 | training loss: 6.6192e-04 | validation loss: 1.1174e-04\n",
      "Epoch: 23740 | training loss: 6.6183e-04 | validation loss: 1.1174e-04\n",
      "Epoch: 23750 | training loss: 6.6175e-04 | validation loss: 1.1173e-04\n",
      "Epoch: 23760 | training loss: 6.6166e-04 | validation loss: 1.1172e-04\n",
      "Epoch: 23770 | training loss: 6.6157e-04 | validation loss: 1.1172e-04\n",
      "Epoch: 23780 | training loss: 6.6149e-04 | validation loss: 1.1171e-04\n",
      "Epoch: 23790 | training loss: 6.6140e-04 | validation loss: 1.1171e-04\n",
      "Epoch: 23800 | training loss: 6.6131e-04 | validation loss: 1.1170e-04\n",
      "Epoch: 23810 | training loss: 6.6122e-04 | validation loss: 1.1169e-04\n",
      "Epoch: 23820 | training loss: 6.6113e-04 | validation loss: 1.1169e-04\n",
      "Epoch: 23830 | training loss: 6.6104e-04 | validation loss: 1.1168e-04\n",
      "Epoch: 23840 | training loss: 6.6095e-04 | validation loss: 1.1164e-04\n",
      "Epoch: 23850 | training loss: 6.6094e-04 | validation loss: 1.1132e-04\n",
      "Epoch: 23860 | training loss: 6.6446e-04 | validation loss: 1.1143e-04\n",
      "Epoch: 23870 | training loss: 6.6117e-04 | validation loss: 1.1113e-04\n",
      "Epoch: 23880 | training loss: 6.6075e-04 | validation loss: 1.1182e-04\n",
      "Epoch: 23890 | training loss: 6.6053e-04 | validation loss: 1.1181e-04\n",
      "Epoch: 23900 | training loss: 6.6048e-04 | validation loss: 1.1180e-04\n",
      "Epoch: 23910 | training loss: 6.6043e-04 | validation loss: 1.1176e-04\n",
      "Epoch: 23920 | training loss: 6.6070e-04 | validation loss: 1.1181e-04\n",
      "Epoch: 23930 | training loss: 6.6344e-04 | validation loss: 1.1337e-04\n",
      "Epoch: 23940 | training loss: 6.6036e-04 | validation loss: 1.1197e-04\n",
      "Epoch: 23950 | training loss: 6.6001e-04 | validation loss: 1.1156e-04\n",
      "Epoch: 23960 | training loss: 6.5996e-04 | validation loss: 1.1152e-04\n",
      "Epoch: 23970 | training loss: 6.5991e-04 | validation loss: 1.1171e-04\n",
      "Epoch: 23980 | training loss: 6.5976e-04 | validation loss: 1.1153e-04\n",
      "Epoch: 23990 | training loss: 6.5969e-04 | validation loss: 1.1152e-04\n",
      "Epoch: 24000 | training loss: 6.5959e-04 | validation loss: 1.1152e-04\n",
      "Epoch: 24010 | training loss: 6.5954e-04 | validation loss: 1.1150e-04\n",
      "Epoch: 24020 | training loss: 6.6023e-04 | validation loss: 1.1182e-04\n",
      "Epoch: 24030 | training loss: 6.6395e-04 | validation loss: 1.1409e-04\n",
      "Epoch: 24040 | training loss: 6.6049e-04 | validation loss: 1.1286e-04\n",
      "Epoch: 24050 | training loss: 6.5932e-04 | validation loss: 1.1149e-04\n",
      "Epoch: 24060 | training loss: 6.5907e-04 | validation loss: 1.1154e-04\n",
      "Epoch: 24070 | training loss: 6.5899e-04 | validation loss: 1.1150e-04\n",
      "Epoch: 24080 | training loss: 6.5890e-04 | validation loss: 1.1151e-04\n",
      "Epoch: 24090 | training loss: 6.5882e-04 | validation loss: 1.1148e-04\n",
      "Epoch: 24100 | training loss: 6.5874e-04 | validation loss: 1.1152e-04\n",
      "Epoch: 24110 | training loss: 6.5865e-04 | validation loss: 1.1148e-04\n",
      "Epoch: 24120 | training loss: 6.5856e-04 | validation loss: 1.1146e-04\n",
      "Epoch: 24130 | training loss: 6.5848e-04 | validation loss: 1.1145e-04\n",
      "Epoch: 24140 | training loss: 6.5841e-04 | validation loss: 1.1143e-04\n",
      "Epoch: 24150 | training loss: 6.5878e-04 | validation loss: 1.1156e-04\n",
      "Epoch: 24160 | training loss: 6.6565e-04 | validation loss: 1.1582e-04\n",
      "Epoch: 24170 | training loss: 6.6007e-04 | validation loss: 1.1342e-04\n",
      "Epoch: 24180 | training loss: 6.5806e-04 | validation loss: 1.1136e-04\n",
      "Epoch: 24190 | training loss: 6.5815e-04 | validation loss: 1.1139e-04\n",
      "Epoch: 24200 | training loss: 6.5800e-04 | validation loss: 1.1166e-04\n",
      "Epoch: 24210 | training loss: 6.5783e-04 | validation loss: 1.1138e-04\n",
      "Epoch: 24220 | training loss: 6.5772e-04 | validation loss: 1.1144e-04\n",
      "Epoch: 24230 | training loss: 6.5764e-04 | validation loss: 1.1140e-04\n",
      "Epoch: 24240 | training loss: 6.5755e-04 | validation loss: 1.1142e-04\n",
      "Epoch: 24250 | training loss: 6.5747e-04 | validation loss: 1.1139e-04\n",
      "Epoch: 24260 | training loss: 6.5738e-04 | validation loss: 1.1140e-04\n",
      "Epoch: 24270 | training loss: 6.5730e-04 | validation loss: 1.1140e-04\n",
      "Epoch: 24280 | training loss: 6.5721e-04 | validation loss: 1.1139e-04\n",
      "Epoch: 24290 | training loss: 6.5712e-04 | validation loss: 1.1139e-04\n",
      "Epoch: 24300 | training loss: 6.5705e-04 | validation loss: 1.1142e-04\n",
      "Epoch: 24310 | training loss: 6.5758e-04 | validation loss: 1.1207e-04\n",
      "Epoch: 24320 | training loss: 6.6509e-04 | validation loss: 1.1837e-04\n",
      "Epoch: 24330 | training loss: 6.5684e-04 | validation loss: 1.1106e-04\n",
      "Epoch: 24340 | training loss: 6.5768e-04 | validation loss: 1.1196e-04\n",
      "Epoch: 24350 | training loss: 6.5664e-04 | validation loss: 1.1142e-04\n",
      "Epoch: 24360 | training loss: 6.5666e-04 | validation loss: 1.1138e-04\n",
      "Epoch: 24370 | training loss: 6.5646e-04 | validation loss: 1.1137e-04\n",
      "Epoch: 24380 | training loss: 6.5639e-04 | validation loss: 1.1132e-04\n",
      "Epoch: 24390 | training loss: 6.5630e-04 | validation loss: 1.1134e-04\n",
      "Epoch: 24400 | training loss: 6.5621e-04 | validation loss: 1.1132e-04\n",
      "Epoch: 24410 | training loss: 6.5613e-04 | validation loss: 1.1131e-04\n",
      "Epoch: 24420 | training loss: 6.5604e-04 | validation loss: 1.1131e-04\n",
      "Epoch: 24430 | training loss: 6.5596e-04 | validation loss: 1.1131e-04\n",
      "Epoch: 24440 | training loss: 6.5588e-04 | validation loss: 1.1131e-04\n",
      "Epoch: 24450 | training loss: 6.5579e-04 | validation loss: 1.1133e-04\n",
      "Epoch: 24460 | training loss: 6.5574e-04 | validation loss: 1.1156e-04\n",
      "Epoch: 24470 | training loss: 6.5760e-04 | validation loss: 1.1464e-04\n",
      "Epoch: 24480 | training loss: 6.5675e-04 | validation loss: 1.1080e-04\n",
      "Epoch: 24490 | training loss: 6.5550e-04 | validation loss: 1.1101e-04\n",
      "Epoch: 24500 | training loss: 6.5550e-04 | validation loss: 1.1165e-04\n",
      "Epoch: 24510 | training loss: 6.5545e-04 | validation loss: 1.1147e-04\n",
      "Epoch: 24520 | training loss: 6.5603e-04 | validation loss: 1.1146e-04\n",
      "Epoch: 24530 | training loss: 6.5768e-04 | validation loss: 1.1243e-04\n",
      "Epoch: 24540 | training loss: 6.5559e-04 | validation loss: 1.1187e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24550 | training loss: 6.5498e-04 | validation loss: 1.1124e-04\n",
      "Epoch: 24560 | training loss: 6.5496e-04 | validation loss: 1.1120e-04\n",
      "Epoch: 24570 | training loss: 6.5485e-04 | validation loss: 1.1130e-04\n",
      "Epoch: 24580 | training loss: 6.5475e-04 | validation loss: 1.1129e-04\n",
      "Epoch: 24590 | training loss: 6.5466e-04 | validation loss: 1.1127e-04\n",
      "Epoch: 24600 | training loss: 6.5465e-04 | validation loss: 1.1137e-04\n",
      "Epoch: 24610 | training loss: 6.5622e-04 | validation loss: 1.1289e-04\n",
      "Epoch: 24620 | training loss: 6.5552e-04 | validation loss: 1.1241e-04\n",
      "Epoch: 24630 | training loss: 6.5447e-04 | validation loss: 1.1112e-04\n",
      "Epoch: 24640 | training loss: 6.5423e-04 | validation loss: 1.1117e-04\n",
      "Epoch: 24650 | training loss: 6.5415e-04 | validation loss: 1.1119e-04\n",
      "Epoch: 24660 | training loss: 6.5407e-04 | validation loss: 1.1116e-04\n",
      "Epoch: 24670 | training loss: 6.5399e-04 | validation loss: 1.1113e-04\n",
      "Epoch: 24680 | training loss: 6.5392e-04 | validation loss: 1.1119e-04\n",
      "Epoch: 24690 | training loss: 6.5383e-04 | validation loss: 1.1113e-04\n",
      "Epoch: 24700 | training loss: 6.5375e-04 | validation loss: 1.1112e-04\n",
      "Epoch: 24710 | training loss: 6.5366e-04 | validation loss: 1.1112e-04\n",
      "Epoch: 24720 | training loss: 6.5359e-04 | validation loss: 1.1110e-04\n",
      "Epoch: 24730 | training loss: 6.5369e-04 | validation loss: 1.1111e-04\n",
      "Epoch: 24740 | training loss: 6.5964e-04 | validation loss: 1.1475e-04\n",
      "Epoch: 24750 | training loss: 6.5599e-04 | validation loss: 1.1357e-04\n",
      "Epoch: 24760 | training loss: 6.5403e-04 | validation loss: 1.1129e-04\n",
      "Epoch: 24770 | training loss: 6.5319e-04 | validation loss: 1.1117e-04\n",
      "Epoch: 24780 | training loss: 6.5323e-04 | validation loss: 1.1126e-04\n",
      "Epoch: 24790 | training loss: 6.5307e-04 | validation loss: 1.1106e-04\n",
      "Epoch: 24800 | training loss: 6.5295e-04 | validation loss: 1.1114e-04\n",
      "Epoch: 24810 | training loss: 6.5286e-04 | validation loss: 1.1106e-04\n",
      "Epoch: 24820 | training loss: 6.5278e-04 | validation loss: 1.1109e-04\n",
      "Epoch: 24830 | training loss: 6.5270e-04 | validation loss: 1.1107e-04\n",
      "Epoch: 24840 | training loss: 6.5262e-04 | validation loss: 1.1107e-04\n",
      "Epoch: 24850 | training loss: 6.5253e-04 | validation loss: 1.1106e-04\n",
      "Epoch: 24860 | training loss: 6.5245e-04 | validation loss: 1.1106e-04\n",
      "Epoch: 24870 | training loss: 6.5237e-04 | validation loss: 1.1106e-04\n",
      "Epoch: 24880 | training loss: 6.5229e-04 | validation loss: 1.1107e-04\n",
      "Epoch: 24890 | training loss: 6.5226e-04 | validation loss: 1.1127e-04\n",
      "Epoch: 24900 | training loss: 6.5496e-04 | validation loss: 1.1422e-04\n",
      "Epoch: 24910 | training loss: 6.5678e-04 | validation loss: 1.1191e-04\n",
      "Epoch: 24920 | training loss: 6.5358e-04 | validation loss: 1.1116e-04\n",
      "Epoch: 24930 | training loss: 6.5241e-04 | validation loss: 1.1049e-04\n",
      "Epoch: 24940 | training loss: 6.5199e-04 | validation loss: 1.1083e-04\n",
      "Epoch: 24950 | training loss: 6.5180e-04 | validation loss: 1.1075e-04\n",
      "Epoch: 24960 | training loss: 6.5168e-04 | validation loss: 1.1092e-04\n",
      "Epoch: 24970 | training loss: 6.5158e-04 | validation loss: 1.1090e-04\n",
      "Epoch: 24980 | training loss: 6.5151e-04 | validation loss: 1.1090e-04\n",
      "Epoch: 24990 | training loss: 6.5142e-04 | validation loss: 1.1093e-04\n",
      "Epoch: 25000 | training loss: 6.5134e-04 | validation loss: 1.1095e-04\n",
      "Epoch: 25010 | training loss: 6.5127e-04 | validation loss: 1.1096e-04\n",
      "Epoch: 25020 | training loss: 6.5119e-04 | validation loss: 1.1094e-04\n",
      "Epoch: 25030 | training loss: 6.5143e-04 | validation loss: 1.1098e-04\n",
      "Epoch: 25040 | training loss: 6.6465e-04 | validation loss: 1.1945e-04\n",
      "Epoch: 25050 | training loss: 6.5097e-04 | validation loss: 1.1100e-04\n",
      "Epoch: 25060 | training loss: 6.5181e-04 | validation loss: 1.1197e-04\n",
      "Epoch: 25070 | training loss: 6.5131e-04 | validation loss: 1.1155e-04\n",
      "Epoch: 25080 | training loss: 6.5078e-04 | validation loss: 1.1105e-04\n",
      "Epoch: 25090 | training loss: 6.5067e-04 | validation loss: 1.1089e-04\n",
      "Epoch: 25100 | training loss: 6.5061e-04 | validation loss: 1.1088e-04\n",
      "Epoch: 25110 | training loss: 6.5051e-04 | validation loss: 1.1091e-04\n",
      "Epoch: 25120 | training loss: 6.5044e-04 | validation loss: 1.1093e-04\n",
      "Epoch: 25130 | training loss: 6.5036e-04 | validation loss: 1.1090e-04\n",
      "Epoch: 25140 | training loss: 6.5028e-04 | validation loss: 1.1089e-04\n",
      "Epoch: 25150 | training loss: 6.5021e-04 | validation loss: 1.1090e-04\n",
      "Epoch: 25160 | training loss: 6.5013e-04 | validation loss: 1.1089e-04\n",
      "Epoch: 25170 | training loss: 6.5006e-04 | validation loss: 1.1088e-04\n",
      "Epoch: 25180 | training loss: 6.4998e-04 | validation loss: 1.1088e-04\n",
      "Epoch: 25190 | training loss: 6.4990e-04 | validation loss: 1.1087e-04\n",
      "Epoch: 25200 | training loss: 6.4982e-04 | validation loss: 1.1087e-04\n",
      "Epoch: 25210 | training loss: 6.4975e-04 | validation loss: 1.1086e-04\n",
      "Epoch: 25220 | training loss: 6.4967e-04 | validation loss: 1.1085e-04\n",
      "Epoch: 25230 | training loss: 6.4959e-04 | validation loss: 1.1085e-04\n",
      "Epoch: 25240 | training loss: 6.4951e-04 | validation loss: 1.1084e-04\n",
      "Epoch: 25250 | training loss: 6.4943e-04 | validation loss: 1.1084e-04\n",
      "Epoch: 25260 | training loss: 6.4936e-04 | validation loss: 1.1086e-04\n",
      "Epoch: 25270 | training loss: 6.5008e-04 | validation loss: 1.1170e-04\n",
      "Epoch: 25280 | training loss: 6.5481e-04 | validation loss: 1.1579e-04\n",
      "Epoch: 25290 | training loss: 6.5288e-04 | validation loss: 1.1415e-04\n",
      "Epoch: 25300 | training loss: 6.4995e-04 | validation loss: 1.1164e-04\n",
      "Epoch: 25310 | training loss: 6.4912e-04 | validation loss: 1.1087e-04\n",
      "Epoch: 25320 | training loss: 6.4891e-04 | validation loss: 1.1072e-04\n",
      "Epoch: 25330 | training loss: 6.4885e-04 | validation loss: 1.1077e-04\n",
      "Epoch: 25340 | training loss: 6.4878e-04 | validation loss: 1.1082e-04\n",
      "Epoch: 25350 | training loss: 6.4869e-04 | validation loss: 1.1081e-04\n",
      "Epoch: 25360 | training loss: 6.4861e-04 | validation loss: 1.1079e-04\n",
      "Epoch: 25370 | training loss: 6.4854e-04 | validation loss: 1.1079e-04\n",
      "Epoch: 25380 | training loss: 6.4846e-04 | validation loss: 1.1079e-04\n",
      "Epoch: 25390 | training loss: 6.4838e-04 | validation loss: 1.1078e-04\n",
      "Epoch: 25400 | training loss: 6.4831e-04 | validation loss: 1.1078e-04\n",
      "Epoch: 25410 | training loss: 6.4823e-04 | validation loss: 1.1077e-04\n",
      "Epoch: 25420 | training loss: 6.4816e-04 | validation loss: 1.1076e-04\n",
      "Epoch: 25430 | training loss: 6.4808e-04 | validation loss: 1.1076e-04\n",
      "Epoch: 25440 | training loss: 6.4800e-04 | validation loss: 1.1075e-04\n",
      "Epoch: 25450 | training loss: 6.4793e-04 | validation loss: 1.1075e-04\n",
      "Epoch: 25460 | training loss: 6.4785e-04 | validation loss: 1.1074e-04\n",
      "Epoch: 25470 | training loss: 6.4777e-04 | validation loss: 1.1074e-04\n",
      "Epoch: 25480 | training loss: 6.4770e-04 | validation loss: 1.1073e-04\n",
      "Epoch: 25490 | training loss: 6.4762e-04 | validation loss: 1.1073e-04\n",
      "Epoch: 25500 | training loss: 6.4754e-04 | validation loss: 1.1071e-04\n",
      "Epoch: 25510 | training loss: 6.4747e-04 | validation loss: 1.1060e-04\n",
      "Epoch: 25520 | training loss: 6.4894e-04 | validation loss: 1.0994e-04\n",
      "Epoch: 25530 | training loss: 6.4929e-04 | validation loss: 1.1361e-04\n",
      "Epoch: 25540 | training loss: 6.5092e-04 | validation loss: 1.1367e-04\n",
      "Epoch: 25550 | training loss: 6.4761e-04 | validation loss: 1.1187e-04\n",
      "Epoch: 25560 | training loss: 6.4719e-04 | validation loss: 1.1118e-04\n",
      "Epoch: 25570 | training loss: 6.4706e-04 | validation loss: 1.1092e-04\n",
      "Epoch: 25580 | training loss: 6.4700e-04 | validation loss: 1.1092e-04\n",
      "Epoch: 25590 | training loss: 6.4689e-04 | validation loss: 1.1071e-04\n",
      "Epoch: 25600 | training loss: 6.4679e-04 | validation loss: 1.1068e-04\n",
      "Epoch: 25610 | training loss: 6.4671e-04 | validation loss: 1.1069e-04\n",
      "Epoch: 25620 | training loss: 6.4665e-04 | validation loss: 1.1070e-04\n",
      "Epoch: 25630 | training loss: 6.4671e-04 | validation loss: 1.1087e-04\n",
      "Epoch: 25640 | training loss: 6.5043e-04 | validation loss: 1.1407e-04\n",
      "Epoch: 25650 | training loss: 6.4692e-04 | validation loss: 1.1077e-04\n",
      "Epoch: 25660 | training loss: 6.4723e-04 | validation loss: 1.1158e-04\n",
      "Epoch: 25670 | training loss: 6.4665e-04 | validation loss: 1.1069e-04\n",
      "Epoch: 25680 | training loss: 6.4626e-04 | validation loss: 1.1074e-04\n",
      "Epoch: 25690 | training loss: 6.4613e-04 | validation loss: 1.1059e-04\n",
      "Epoch: 25700 | training loss: 6.4605e-04 | validation loss: 1.1062e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25710 | training loss: 6.4598e-04 | validation loss: 1.1059e-04\n",
      "Epoch: 25720 | training loss: 6.4591e-04 | validation loss: 1.1061e-04\n",
      "Epoch: 25730 | training loss: 6.4583e-04 | validation loss: 1.1058e-04\n",
      "Epoch: 25740 | training loss: 6.4576e-04 | validation loss: 1.1058e-04\n",
      "Epoch: 25750 | training loss: 6.4568e-04 | validation loss: 1.1058e-04\n",
      "Epoch: 25760 | training loss: 6.4561e-04 | validation loss: 1.1058e-04\n",
      "Epoch: 25770 | training loss: 6.4554e-04 | validation loss: 1.1060e-04\n",
      "Epoch: 25780 | training loss: 6.4571e-04 | validation loss: 1.1090e-04\n",
      "Epoch: 25790 | training loss: 6.5499e-04 | validation loss: 1.1849e-04\n",
      "Epoch: 25800 | training loss: 6.4846e-04 | validation loss: 1.1218e-04\n",
      "Epoch: 25810 | training loss: 6.4538e-04 | validation loss: 1.1051e-04\n",
      "Epoch: 25820 | training loss: 6.4556e-04 | validation loss: 1.1105e-04\n",
      "Epoch: 25830 | training loss: 6.4511e-04 | validation loss: 1.1060e-04\n",
      "Epoch: 25840 | training loss: 6.4509e-04 | validation loss: 1.1050e-04\n",
      "Epoch: 25850 | training loss: 6.4496e-04 | validation loss: 1.1056e-04\n",
      "Epoch: 25860 | training loss: 6.4489e-04 | validation loss: 1.1054e-04\n",
      "Epoch: 25870 | training loss: 6.4481e-04 | validation loss: 1.1051e-04\n",
      "Epoch: 25880 | training loss: 6.4474e-04 | validation loss: 1.1053e-04\n",
      "Epoch: 25890 | training loss: 6.4467e-04 | validation loss: 1.1051e-04\n",
      "Epoch: 25900 | training loss: 6.4459e-04 | validation loss: 1.1051e-04\n",
      "Epoch: 25910 | training loss: 6.4452e-04 | validation loss: 1.1050e-04\n",
      "Epoch: 25920 | training loss: 6.4445e-04 | validation loss: 1.1050e-04\n",
      "Epoch: 25930 | training loss: 6.4437e-04 | validation loss: 1.1049e-04\n",
      "Epoch: 25940 | training loss: 6.4430e-04 | validation loss: 1.1049e-04\n",
      "Epoch: 25950 | training loss: 6.4422e-04 | validation loss: 1.1049e-04\n",
      "Epoch: 25960 | training loss: 6.4415e-04 | validation loss: 1.1049e-04\n",
      "Epoch: 25970 | training loss: 6.4416e-04 | validation loss: 1.1063e-04\n",
      "Epoch: 25980 | training loss: 6.5165e-04 | validation loss: 1.1685e-04\n",
      "Epoch: 25990 | training loss: 6.4933e-04 | validation loss: 1.1362e-04\n",
      "Epoch: 26000 | training loss: 6.4405e-04 | validation loss: 1.1066e-04\n",
      "Epoch: 26010 | training loss: 6.4403e-04 | validation loss: 1.1085e-04\n",
      "Epoch: 26020 | training loss: 6.4395e-04 | validation loss: 1.1064e-04\n",
      "Epoch: 26030 | training loss: 6.4366e-04 | validation loss: 1.1041e-04\n",
      "Epoch: 26040 | training loss: 6.4360e-04 | validation loss: 1.1048e-04\n",
      "Epoch: 26050 | training loss: 6.4351e-04 | validation loss: 1.1045e-04\n",
      "Epoch: 26060 | training loss: 6.4344e-04 | validation loss: 1.1044e-04\n",
      "Epoch: 26070 | training loss: 6.4336e-04 | validation loss: 1.1045e-04\n",
      "Epoch: 26080 | training loss: 6.4329e-04 | validation loss: 1.1043e-04\n",
      "Epoch: 26090 | training loss: 6.4322e-04 | validation loss: 1.1043e-04\n",
      "Epoch: 26100 | training loss: 6.4315e-04 | validation loss: 1.1042e-04\n",
      "Epoch: 26110 | training loss: 6.4307e-04 | validation loss: 1.1042e-04\n",
      "Epoch: 26120 | training loss: 6.4300e-04 | validation loss: 1.1042e-04\n",
      "Epoch: 26130 | training loss: 6.4293e-04 | validation loss: 1.1041e-04\n",
      "Epoch: 26140 | training loss: 6.4285e-04 | validation loss: 1.1041e-04\n",
      "Epoch: 26150 | training loss: 6.4278e-04 | validation loss: 1.1040e-04\n",
      "Epoch: 26160 | training loss: 6.4270e-04 | validation loss: 1.1041e-04\n",
      "Epoch: 26170 | training loss: 6.4263e-04 | validation loss: 1.1049e-04\n",
      "Epoch: 26180 | training loss: 6.4316e-04 | validation loss: 1.1190e-04\n",
      "Epoch: 26190 | training loss: 6.4307e-04 | validation loss: 1.1009e-04\n",
      "Epoch: 26200 | training loss: 6.4432e-04 | validation loss: 1.1269e-04\n",
      "Epoch: 26210 | training loss: 6.4261e-04 | validation loss: 1.1120e-04\n",
      "Epoch: 26220 | training loss: 6.4272e-04 | validation loss: 1.1087e-04\n",
      "Epoch: 26230 | training loss: 6.4226e-04 | validation loss: 1.1070e-04\n",
      "Epoch: 26240 | training loss: 6.4223e-04 | validation loss: 1.1067e-04\n",
      "Epoch: 26250 | training loss: 6.4209e-04 | validation loss: 1.1049e-04\n",
      "Epoch: 26260 | training loss: 6.4203e-04 | validation loss: 1.1045e-04\n",
      "Epoch: 26270 | training loss: 6.4245e-04 | validation loss: 1.1090e-04\n",
      "Epoch: 26280 | training loss: 6.4703e-04 | validation loss: 1.1471e-04\n",
      "Epoch: 26290 | training loss: 6.4342e-04 | validation loss: 1.1108e-04\n",
      "Epoch: 26300 | training loss: 6.4235e-04 | validation loss: 1.1101e-04\n",
      "Epoch: 26310 | training loss: 6.4187e-04 | validation loss: 1.1032e-04\n",
      "Epoch: 26320 | training loss: 6.4166e-04 | validation loss: 1.1047e-04\n",
      "Epoch: 26330 | training loss: 6.4153e-04 | validation loss: 1.1027e-04\n",
      "Epoch: 26340 | training loss: 6.4143e-04 | validation loss: 1.1032e-04\n",
      "Epoch: 26350 | training loss: 6.4136e-04 | validation loss: 1.1031e-04\n",
      "Epoch: 26360 | training loss: 6.4128e-04 | validation loss: 1.1028e-04\n",
      "Epoch: 26370 | training loss: 6.4121e-04 | validation loss: 1.1027e-04\n",
      "Epoch: 26380 | training loss: 6.4116e-04 | validation loss: 1.1025e-04\n",
      "Epoch: 26390 | training loss: 6.4148e-04 | validation loss: 1.1038e-04\n",
      "Epoch: 26400 | training loss: 6.4767e-04 | validation loss: 1.1428e-04\n",
      "Epoch: 26410 | training loss: 6.4327e-04 | validation loss: 1.1248e-04\n",
      "Epoch: 26420 | training loss: 6.4139e-04 | validation loss: 1.1040e-04\n",
      "Epoch: 26430 | training loss: 6.4081e-04 | validation loss: 1.1030e-04\n",
      "Epoch: 26440 | training loss: 6.4073e-04 | validation loss: 1.1029e-04\n",
      "Epoch: 26450 | training loss: 6.4066e-04 | validation loss: 1.1023e-04\n",
      "Epoch: 26460 | training loss: 6.4058e-04 | validation loss: 1.1027e-04\n",
      "Epoch: 26470 | training loss: 6.4051e-04 | validation loss: 1.1024e-04\n",
      "Epoch: 26480 | training loss: 6.4044e-04 | validation loss: 1.1023e-04\n",
      "Epoch: 26490 | training loss: 6.4037e-04 | validation loss: 1.1025e-04\n",
      "Epoch: 26500 | training loss: 6.4030e-04 | validation loss: 1.1023e-04\n",
      "Epoch: 26510 | training loss: 6.4023e-04 | validation loss: 1.1023e-04\n",
      "Epoch: 26520 | training loss: 6.4016e-04 | validation loss: 1.1022e-04\n",
      "Epoch: 26530 | training loss: 6.4009e-04 | validation loss: 1.1023e-04\n",
      "Epoch: 26540 | training loss: 6.4007e-04 | validation loss: 1.1033e-04\n",
      "Epoch: 26550 | training loss: 6.4581e-04 | validation loss: 1.1519e-04\n",
      "Epoch: 26560 | training loss: 6.4503e-04 | validation loss: 1.1323e-04\n",
      "Epoch: 26570 | training loss: 6.3983e-04 | validation loss: 1.1034e-04\n",
      "Epoch: 26580 | training loss: 6.4011e-04 | validation loss: 1.1071e-04\n",
      "Epoch: 26590 | training loss: 6.3994e-04 | validation loss: 1.1047e-04\n",
      "Epoch: 26600 | training loss: 6.3963e-04 | validation loss: 1.1017e-04\n",
      "Epoch: 26610 | training loss: 6.3955e-04 | validation loss: 1.1018e-04\n",
      "Epoch: 26620 | training loss: 6.3948e-04 | validation loss: 1.1020e-04\n",
      "Epoch: 26630 | training loss: 6.3940e-04 | validation loss: 1.1018e-04\n",
      "Epoch: 26640 | training loss: 6.3934e-04 | validation loss: 1.1018e-04\n",
      "Epoch: 26650 | training loss: 6.3927e-04 | validation loss: 1.1017e-04\n",
      "Epoch: 26660 | training loss: 6.3920e-04 | validation loss: 1.1017e-04\n",
      "Epoch: 26670 | training loss: 6.3913e-04 | validation loss: 1.1017e-04\n",
      "Epoch: 26680 | training loss: 6.3906e-04 | validation loss: 1.1016e-04\n",
      "Epoch: 26690 | training loss: 6.3899e-04 | validation loss: 1.1016e-04\n",
      "Epoch: 26700 | training loss: 6.3892e-04 | validation loss: 1.1015e-04\n",
      "Epoch: 26710 | training loss: 6.3885e-04 | validation loss: 1.1015e-04\n",
      "Epoch: 26720 | training loss: 6.3878e-04 | validation loss: 1.1014e-04\n",
      "Epoch: 26730 | training loss: 6.3871e-04 | validation loss: 1.1014e-04\n",
      "Epoch: 26740 | training loss: 6.3864e-04 | validation loss: 1.1013e-04\n",
      "Epoch: 26750 | training loss: 6.3857e-04 | validation loss: 1.1012e-04\n",
      "Epoch: 26760 | training loss: 6.3851e-04 | validation loss: 1.0997e-04\n",
      "Epoch: 26770 | training loss: 6.4051e-04 | validation loss: 1.0943e-04\n",
      "Epoch: 26780 | training loss: 6.3995e-04 | validation loss: 1.1253e-04\n",
      "Epoch: 26790 | training loss: 6.4264e-04 | validation loss: 1.1356e-04\n",
      "Epoch: 26800 | training loss: 6.3894e-04 | validation loss: 1.1153e-04\n",
      "Epoch: 26810 | training loss: 6.3839e-04 | validation loss: 1.1055e-04\n",
      "Epoch: 26820 | training loss: 6.3814e-04 | validation loss: 1.1040e-04\n",
      "Epoch: 26830 | training loss: 6.3803e-04 | validation loss: 1.1021e-04\n",
      "Epoch: 26840 | training loss: 6.3797e-04 | validation loss: 1.1012e-04\n",
      "Epoch: 26850 | training loss: 6.3790e-04 | validation loss: 1.1016e-04\n",
      "Epoch: 26860 | training loss: 6.3782e-04 | validation loss: 1.1012e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26870 | training loss: 6.3775e-04 | validation loss: 1.1008e-04\n",
      "Epoch: 26880 | training loss: 6.3768e-04 | validation loss: 1.1006e-04\n",
      "Epoch: 26890 | training loss: 6.3763e-04 | validation loss: 1.1003e-04\n",
      "Epoch: 26900 | training loss: 6.3840e-04 | validation loss: 1.1041e-04\n",
      "Epoch: 26910 | training loss: 6.4378e-04 | validation loss: 1.1381e-04\n",
      "Epoch: 26920 | training loss: 6.3744e-04 | validation loss: 1.1000e-04\n",
      "Epoch: 26930 | training loss: 6.3827e-04 | validation loss: 1.1099e-04\n",
      "Epoch: 26940 | training loss: 6.3729e-04 | validation loss: 1.1004e-04\n",
      "Epoch: 26950 | training loss: 6.3734e-04 | validation loss: 1.1000e-04\n",
      "Epoch: 26960 | training loss: 6.3716e-04 | validation loss: 1.1005e-04\n",
      "Epoch: 26970 | training loss: 6.3709e-04 | validation loss: 1.1004e-04\n",
      "Epoch: 26980 | training loss: 6.3703e-04 | validation loss: 1.1000e-04\n",
      "Epoch: 26990 | training loss: 6.3696e-04 | validation loss: 1.1003e-04\n",
      "Epoch: 27000 | training loss: 6.3689e-04 | validation loss: 1.1000e-04\n",
      "Epoch: 27010 | training loss: 6.3682e-04 | validation loss: 1.1001e-04\n",
      "Epoch: 27020 | training loss: 6.3676e-04 | validation loss: 1.0999e-04\n",
      "Epoch: 27030 | training loss: 6.3669e-04 | validation loss: 1.0999e-04\n",
      "Epoch: 27040 | training loss: 6.3662e-04 | validation loss: 1.0999e-04\n",
      "Epoch: 27050 | training loss: 6.3656e-04 | validation loss: 1.0998e-04\n",
      "Epoch: 27060 | training loss: 6.3649e-04 | validation loss: 1.0998e-04\n",
      "Epoch: 27070 | training loss: 6.3642e-04 | validation loss: 1.0997e-04\n",
      "Epoch: 27080 | training loss: 6.3635e-04 | validation loss: 1.0996e-04\n",
      "Epoch: 27090 | training loss: 6.3635e-04 | validation loss: 1.0994e-04\n",
      "Epoch: 27100 | training loss: 6.4460e-04 | validation loss: 1.1515e-04\n",
      "Epoch: 27110 | training loss: 6.4261e-04 | validation loss: 1.1546e-04\n",
      "Epoch: 27120 | training loss: 6.3723e-04 | validation loss: 1.1105e-04\n",
      "Epoch: 27130 | training loss: 6.3606e-04 | validation loss: 1.0994e-04\n",
      "Epoch: 27140 | training loss: 6.3601e-04 | validation loss: 1.0983e-04\n",
      "Epoch: 27150 | training loss: 6.3598e-04 | validation loss: 1.0988e-04\n",
      "Epoch: 27160 | training loss: 6.3586e-04 | validation loss: 1.0992e-04\n",
      "Epoch: 27170 | training loss: 6.3577e-04 | validation loss: 1.0996e-04\n",
      "Epoch: 27180 | training loss: 6.3571e-04 | validation loss: 1.0996e-04\n",
      "Epoch: 27190 | training loss: 6.3564e-04 | validation loss: 1.0992e-04\n",
      "Epoch: 27200 | training loss: 6.3558e-04 | validation loss: 1.0991e-04\n",
      "Epoch: 27210 | training loss: 6.3551e-04 | validation loss: 1.0992e-04\n",
      "Epoch: 27220 | training loss: 6.3544e-04 | validation loss: 1.0991e-04\n",
      "Epoch: 27230 | training loss: 6.3538e-04 | validation loss: 1.0991e-04\n",
      "Epoch: 27240 | training loss: 6.3531e-04 | validation loss: 1.0991e-04\n",
      "Epoch: 27250 | training loss: 6.3525e-04 | validation loss: 1.0990e-04\n",
      "Epoch: 27260 | training loss: 6.3518e-04 | validation loss: 1.0990e-04\n",
      "Epoch: 27270 | training loss: 6.3511e-04 | validation loss: 1.0989e-04\n",
      "Epoch: 27280 | training loss: 6.3505e-04 | validation loss: 1.0989e-04\n",
      "Epoch: 27290 | training loss: 6.3498e-04 | validation loss: 1.0988e-04\n",
      "Epoch: 27300 | training loss: 6.3491e-04 | validation loss: 1.0988e-04\n",
      "Epoch: 27310 | training loss: 6.3484e-04 | validation loss: 1.0987e-04\n",
      "Epoch: 27320 | training loss: 6.3478e-04 | validation loss: 1.0987e-04\n",
      "Epoch: 27330 | training loss: 6.3471e-04 | validation loss: 1.0987e-04\n",
      "Epoch: 27340 | training loss: 6.3467e-04 | validation loss: 1.0991e-04\n",
      "Epoch: 27350 | training loss: 6.3963e-04 | validation loss: 1.1388e-04\n",
      "Epoch: 27360 | training loss: 6.4150e-04 | validation loss: 1.1485e-04\n",
      "Epoch: 27370 | training loss: 6.3582e-04 | validation loss: 1.1144e-04\n",
      "Epoch: 27380 | training loss: 6.3487e-04 | validation loss: 1.1063e-04\n",
      "Epoch: 27390 | training loss: 6.3451e-04 | validation loss: 1.1022e-04\n",
      "Epoch: 27400 | training loss: 6.3433e-04 | validation loss: 1.1000e-04\n",
      "Epoch: 27410 | training loss: 6.3422e-04 | validation loss: 1.0992e-04\n",
      "Epoch: 27420 | training loss: 6.3414e-04 | validation loss: 1.0987e-04\n",
      "Epoch: 27430 | training loss: 6.3407e-04 | validation loss: 1.0982e-04\n",
      "Epoch: 27440 | training loss: 6.3401e-04 | validation loss: 1.0980e-04\n",
      "Epoch: 27450 | training loss: 6.3394e-04 | validation loss: 1.0980e-04\n",
      "Epoch: 27460 | training loss: 6.3388e-04 | validation loss: 1.0980e-04\n",
      "Epoch: 27470 | training loss: 6.3382e-04 | validation loss: 1.0980e-04\n",
      "Epoch: 27480 | training loss: 6.3375e-04 | validation loss: 1.0980e-04\n",
      "Epoch: 27490 | training loss: 6.3369e-04 | validation loss: 1.0979e-04\n",
      "Epoch: 27500 | training loss: 6.3362e-04 | validation loss: 1.0979e-04\n",
      "Epoch: 27510 | training loss: 6.3356e-04 | validation loss: 1.0978e-04\n",
      "Epoch: 27520 | training loss: 6.3349e-04 | validation loss: 1.0978e-04\n",
      "Epoch: 27530 | training loss: 6.3343e-04 | validation loss: 1.0977e-04\n",
      "Epoch: 27540 | training loss: 6.3336e-04 | validation loss: 1.0977e-04\n",
      "Epoch: 27550 | training loss: 6.3329e-04 | validation loss: 1.0976e-04\n",
      "Epoch: 27560 | training loss: 6.3323e-04 | validation loss: 1.0977e-04\n",
      "Epoch: 27570 | training loss: 6.3317e-04 | validation loss: 1.0986e-04\n",
      "Epoch: 27580 | training loss: 6.3490e-04 | validation loss: 1.1272e-04\n",
      "Epoch: 27590 | training loss: 6.3532e-04 | validation loss: 1.0957e-04\n",
      "Epoch: 27600 | training loss: 6.3360e-04 | validation loss: 1.0923e-04\n",
      "Epoch: 27610 | training loss: 6.3328e-04 | validation loss: 1.0949e-04\n",
      "Epoch: 27620 | training loss: 6.3296e-04 | validation loss: 1.0996e-04\n",
      "Epoch: 27630 | training loss: 6.3281e-04 | validation loss: 1.0984e-04\n",
      "Epoch: 27640 | training loss: 6.3273e-04 | validation loss: 1.0986e-04\n",
      "Epoch: 27650 | training loss: 6.3266e-04 | validation loss: 1.0978e-04\n",
      "Epoch: 27660 | training loss: 6.3260e-04 | validation loss: 1.0976e-04\n",
      "Epoch: 27670 | training loss: 6.3253e-04 | validation loss: 1.0971e-04\n",
      "Epoch: 27680 | training loss: 6.3247e-04 | validation loss: 1.0971e-04\n",
      "Epoch: 27690 | training loss: 6.3241e-04 | validation loss: 1.0970e-04\n",
      "Epoch: 27700 | training loss: 6.3234e-04 | validation loss: 1.0968e-04\n",
      "Epoch: 27710 | training loss: 6.3228e-04 | validation loss: 1.0968e-04\n",
      "Epoch: 27720 | training loss: 6.3224e-04 | validation loss: 1.0973e-04\n",
      "Epoch: 27730 | training loss: 6.3343e-04 | validation loss: 1.1095e-04\n",
      "Epoch: 27740 | training loss: 6.3519e-04 | validation loss: 1.1246e-04\n",
      "Epoch: 27750 | training loss: 6.3267e-04 | validation loss: 1.1037e-04\n",
      "Epoch: 27760 | training loss: 6.3259e-04 | validation loss: 1.0984e-04\n",
      "Epoch: 27770 | training loss: 6.3198e-04 | validation loss: 1.0961e-04\n",
      "Epoch: 27780 | training loss: 6.3194e-04 | validation loss: 1.0981e-04\n",
      "Epoch: 27790 | training loss: 6.3178e-04 | validation loss: 1.0963e-04\n",
      "Epoch: 27800 | training loss: 6.3173e-04 | validation loss: 1.0961e-04\n",
      "Epoch: 27810 | training loss: 6.3166e-04 | validation loss: 1.0965e-04\n",
      "Epoch: 27820 | training loss: 6.3160e-04 | validation loss: 1.0961e-04\n",
      "Epoch: 27830 | training loss: 6.3153e-04 | validation loss: 1.0962e-04\n",
      "Epoch: 27840 | training loss: 6.3147e-04 | validation loss: 1.0961e-04\n",
      "Epoch: 27850 | training loss: 6.3141e-04 | validation loss: 1.0961e-04\n",
      "Epoch: 27860 | training loss: 6.3134e-04 | validation loss: 1.0960e-04\n",
      "Epoch: 27870 | training loss: 6.3128e-04 | validation loss: 1.0960e-04\n",
      "Epoch: 27880 | training loss: 6.3122e-04 | validation loss: 1.0959e-04\n",
      "Epoch: 27890 | training loss: 6.3115e-04 | validation loss: 1.0959e-04\n",
      "Epoch: 27900 | training loss: 6.3109e-04 | validation loss: 1.0958e-04\n",
      "Epoch: 27910 | training loss: 6.3103e-04 | validation loss: 1.0959e-04\n",
      "Epoch: 27920 | training loss: 6.3116e-04 | validation loss: 1.0985e-04\n",
      "Epoch: 27930 | training loss: 6.4499e-04 | validation loss: 1.2089e-04\n",
      "Epoch: 27940 | training loss: 6.3226e-04 | validation loss: 1.1016e-04\n",
      "Epoch: 27950 | training loss: 6.3245e-04 | validation loss: 1.1034e-04\n",
      "Epoch: 27960 | training loss: 6.3115e-04 | validation loss: 1.0968e-04\n",
      "Epoch: 27970 | training loss: 6.3067e-04 | validation loss: 1.0956e-04\n",
      "Epoch: 27980 | training loss: 6.3063e-04 | validation loss: 1.0966e-04\n",
      "Epoch: 27990 | training loss: 6.3056e-04 | validation loss: 1.0962e-04\n",
      "Epoch: 28000 | training loss: 6.3048e-04 | validation loss: 1.0953e-04\n",
      "Epoch: 28010 | training loss: 6.3042e-04 | validation loss: 1.0952e-04\n",
      "Epoch: 28020 | training loss: 6.3035e-04 | validation loss: 1.0954e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28030 | training loss: 6.3029e-04 | validation loss: 1.0954e-04\n",
      "Epoch: 28040 | training loss: 6.3023e-04 | validation loss: 1.0952e-04\n",
      "Epoch: 28050 | training loss: 6.3017e-04 | validation loss: 1.0952e-04\n",
      "Epoch: 28060 | training loss: 6.3011e-04 | validation loss: 1.0952e-04\n",
      "Epoch: 28070 | training loss: 6.3005e-04 | validation loss: 1.0951e-04\n",
      "Epoch: 28080 | training loss: 6.2998e-04 | validation loss: 1.0951e-04\n",
      "Epoch: 28090 | training loss: 6.2992e-04 | validation loss: 1.0950e-04\n",
      "Epoch: 28100 | training loss: 6.2986e-04 | validation loss: 1.0950e-04\n",
      "Epoch: 28110 | training loss: 6.2979e-04 | validation loss: 1.0949e-04\n",
      "Epoch: 28120 | training loss: 6.2973e-04 | validation loss: 1.0949e-04\n",
      "Epoch: 28130 | training loss: 6.2967e-04 | validation loss: 1.0948e-04\n",
      "Epoch: 28140 | training loss: 6.2960e-04 | validation loss: 1.0948e-04\n",
      "Epoch: 28150 | training loss: 6.2954e-04 | validation loss: 1.0948e-04\n",
      "Epoch: 28160 | training loss: 6.2949e-04 | validation loss: 1.0950e-04\n",
      "Epoch: 28170 | training loss: 6.3188e-04 | validation loss: 1.1149e-04\n",
      "Epoch: 28180 | training loss: 6.3120e-04 | validation loss: 1.1136e-04\n",
      "Epoch: 28190 | training loss: 6.2946e-04 | validation loss: 1.1012e-04\n",
      "Epoch: 28200 | training loss: 6.2926e-04 | validation loss: 1.0970e-04\n",
      "Epoch: 28210 | training loss: 6.2920e-04 | validation loss: 1.0960e-04\n",
      "Epoch: 28220 | training loss: 6.2914e-04 | validation loss: 1.0954e-04\n",
      "Epoch: 28230 | training loss: 6.2907e-04 | validation loss: 1.0951e-04\n",
      "Epoch: 28240 | training loss: 6.2900e-04 | validation loss: 1.0949e-04\n",
      "Epoch: 28250 | training loss: 6.2894e-04 | validation loss: 1.0945e-04\n",
      "Epoch: 28260 | training loss: 6.2888e-04 | validation loss: 1.0942e-04\n",
      "Epoch: 28270 | training loss: 6.2882e-04 | validation loss: 1.0941e-04\n",
      "Epoch: 28280 | training loss: 6.2876e-04 | validation loss: 1.0941e-04\n",
      "Epoch: 28290 | training loss: 6.2870e-04 | validation loss: 1.0941e-04\n",
      "Epoch: 28300 | training loss: 6.2864e-04 | validation loss: 1.0941e-04\n",
      "Epoch: 28310 | training loss: 6.2858e-04 | validation loss: 1.0941e-04\n",
      "Epoch: 28320 | training loss: 6.2852e-04 | validation loss: 1.0940e-04\n",
      "Epoch: 28330 | training loss: 6.2845e-04 | validation loss: 1.0939e-04\n",
      "Epoch: 28340 | training loss: 6.2839e-04 | validation loss: 1.0939e-04\n",
      "Epoch: 28350 | training loss: 6.2833e-04 | validation loss: 1.0938e-04\n",
      "Epoch: 28360 | training loss: 6.2827e-04 | validation loss: 1.0938e-04\n",
      "Epoch: 28370 | training loss: 6.2821e-04 | validation loss: 1.0937e-04\n",
      "Epoch: 28380 | training loss: 6.2814e-04 | validation loss: 1.0937e-04\n",
      "Epoch: 28390 | training loss: 6.2808e-04 | validation loss: 1.0934e-04\n",
      "Epoch: 28400 | training loss: 6.2807e-04 | validation loss: 1.0912e-04\n",
      "Epoch: 28410 | training loss: 6.3493e-04 | validation loss: 1.1163e-04\n",
      "Epoch: 28420 | training loss: 6.3022e-04 | validation loss: 1.1034e-04\n",
      "Epoch: 28430 | training loss: 6.2887e-04 | validation loss: 1.0904e-04\n",
      "Epoch: 28440 | training loss: 6.2794e-04 | validation loss: 1.0891e-04\n",
      "Epoch: 28450 | training loss: 6.2782e-04 | validation loss: 1.0919e-04\n",
      "Epoch: 28460 | training loss: 6.2771e-04 | validation loss: 1.0917e-04\n",
      "Epoch: 28470 | training loss: 6.2762e-04 | validation loss: 1.0932e-04\n",
      "Epoch: 28480 | training loss: 6.2755e-04 | validation loss: 1.0927e-04\n",
      "Epoch: 28490 | training loss: 6.2749e-04 | validation loss: 1.0931e-04\n",
      "Epoch: 28500 | training loss: 6.2743e-04 | validation loss: 1.0928e-04\n",
      "Epoch: 28510 | training loss: 6.2737e-04 | validation loss: 1.0929e-04\n",
      "Epoch: 28520 | training loss: 6.2731e-04 | validation loss: 1.0929e-04\n",
      "Epoch: 28530 | training loss: 6.2725e-04 | validation loss: 1.0929e-04\n",
      "Epoch: 28540 | training loss: 6.2718e-04 | validation loss: 1.0928e-04\n",
      "Epoch: 28550 | training loss: 6.2712e-04 | validation loss: 1.0928e-04\n",
      "Epoch: 28560 | training loss: 6.2706e-04 | validation loss: 1.0927e-04\n",
      "Epoch: 28570 | training loss: 6.2701e-04 | validation loss: 1.0925e-04\n",
      "Epoch: 28580 | training loss: 6.2792e-04 | validation loss: 1.0966e-04\n",
      "Epoch: 28590 | training loss: 6.3015e-04 | validation loss: 1.1106e-04\n",
      "Epoch: 28600 | training loss: 6.3070e-04 | validation loss: 1.1146e-04\n",
      "Epoch: 28610 | training loss: 6.2823e-04 | validation loss: 1.0995e-04\n",
      "Epoch: 28620 | training loss: 6.2724e-04 | validation loss: 1.0941e-04\n",
      "Epoch: 28630 | training loss: 6.2684e-04 | validation loss: 1.0925e-04\n",
      "Epoch: 28640 | training loss: 6.2665e-04 | validation loss: 1.0921e-04\n",
      "Epoch: 28650 | training loss: 6.2655e-04 | validation loss: 1.0922e-04\n",
      "Epoch: 28660 | training loss: 6.2649e-04 | validation loss: 1.0924e-04\n",
      "Epoch: 28670 | training loss: 6.2643e-04 | validation loss: 1.0925e-04\n",
      "Epoch: 28680 | training loss: 6.2638e-04 | validation loss: 1.0924e-04\n",
      "Epoch: 28690 | training loss: 6.2632e-04 | validation loss: 1.0922e-04\n",
      "Epoch: 28700 | training loss: 6.2626e-04 | validation loss: 1.0922e-04\n",
      "Epoch: 28710 | training loss: 6.2620e-04 | validation loss: 1.0922e-04\n",
      "Epoch: 28720 | training loss: 6.2614e-04 | validation loss: 1.0921e-04\n",
      "Epoch: 28730 | training loss: 6.2609e-04 | validation loss: 1.0921e-04\n",
      "Epoch: 28740 | training loss: 6.2603e-04 | validation loss: 1.0920e-04\n",
      "Epoch: 28750 | training loss: 6.2597e-04 | validation loss: 1.0920e-04\n",
      "Epoch: 28760 | training loss: 6.2591e-04 | validation loss: 1.0920e-04\n",
      "Epoch: 28770 | training loss: 6.2585e-04 | validation loss: 1.0919e-04\n",
      "Epoch: 28780 | training loss: 6.2579e-04 | validation loss: 1.0919e-04\n",
      "Epoch: 28790 | training loss: 6.2573e-04 | validation loss: 1.0918e-04\n",
      "Epoch: 28800 | training loss: 6.2567e-04 | validation loss: 1.0918e-04\n",
      "Epoch: 28810 | training loss: 6.2561e-04 | validation loss: 1.0917e-04\n",
      "Epoch: 28820 | training loss: 6.2555e-04 | validation loss: 1.0917e-04\n",
      "Epoch: 28830 | training loss: 6.2549e-04 | validation loss: 1.0916e-04\n",
      "Epoch: 28840 | training loss: 6.2543e-04 | validation loss: 1.0916e-04\n",
      "Epoch: 28850 | training loss: 6.2537e-04 | validation loss: 1.0916e-04\n",
      "Epoch: 28860 | training loss: 6.2532e-04 | validation loss: 1.0920e-04\n",
      "Epoch: 28870 | training loss: 6.3009e-04 | validation loss: 1.1319e-04\n",
      "Epoch: 28880 | training loss: 6.3441e-04 | validation loss: 1.1511e-04\n",
      "Epoch: 28890 | training loss: 6.2789e-04 | validation loss: 1.1102e-04\n",
      "Epoch: 28900 | training loss: 6.2626e-04 | validation loss: 1.1003e-04\n",
      "Epoch: 28910 | training loss: 6.2546e-04 | validation loss: 1.0950e-04\n",
      "Epoch: 28920 | training loss: 6.2511e-04 | validation loss: 1.0925e-04\n",
      "Epoch: 28930 | training loss: 6.2496e-04 | validation loss: 1.0914e-04\n",
      "Epoch: 28940 | training loss: 6.2487e-04 | validation loss: 1.0913e-04\n",
      "Epoch: 28950 | training loss: 6.2481e-04 | validation loss: 1.0913e-04\n",
      "Epoch: 28960 | training loss: 6.2474e-04 | validation loss: 1.0912e-04\n",
      "Epoch: 28970 | training loss: 6.2469e-04 | validation loss: 1.0911e-04\n",
      "Epoch: 28980 | training loss: 6.2463e-04 | validation loss: 1.0911e-04\n",
      "Epoch: 28990 | training loss: 6.2457e-04 | validation loss: 1.0911e-04\n",
      "Epoch: 29000 | training loss: 6.2452e-04 | validation loss: 1.0910e-04\n",
      "Epoch: 29010 | training loss: 6.2446e-04 | validation loss: 1.0910e-04\n",
      "Epoch: 29020 | training loss: 6.2440e-04 | validation loss: 1.0909e-04\n",
      "Epoch: 29030 | training loss: 6.2434e-04 | validation loss: 1.0909e-04\n",
      "Epoch: 29040 | training loss: 6.2428e-04 | validation loss: 1.0909e-04\n",
      "Epoch: 29050 | training loss: 6.2423e-04 | validation loss: 1.0908e-04\n",
      "Epoch: 29060 | training loss: 6.2417e-04 | validation loss: 1.0908e-04\n",
      "Epoch: 29070 | training loss: 6.2411e-04 | validation loss: 1.0907e-04\n",
      "Epoch: 29080 | training loss: 6.2405e-04 | validation loss: 1.0907e-04\n",
      "Epoch: 29090 | training loss: 6.2399e-04 | validation loss: 1.0906e-04\n",
      "Epoch: 29100 | training loss: 6.2393e-04 | validation loss: 1.0903e-04\n",
      "Epoch: 29110 | training loss: 6.2395e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29120 | training loss: 6.2654e-04 | validation loss: 1.0862e-04\n",
      "Epoch: 29130 | training loss: 6.2444e-04 | validation loss: 1.0836e-04\n",
      "Epoch: 29140 | training loss: 6.2386e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29150 | training loss: 6.2366e-04 | validation loss: 1.0884e-04\n",
      "Epoch: 29160 | training loss: 6.2359e-04 | validation loss: 1.0900e-04\n",
      "Epoch: 29170 | training loss: 6.2354e-04 | validation loss: 1.0908e-04\n",
      "Epoch: 29180 | training loss: 6.2357e-04 | validation loss: 1.0910e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29190 | training loss: 6.2534e-04 | validation loss: 1.1011e-04\n",
      "Epoch: 29200 | training loss: 6.2441e-04 | validation loss: 1.0951e-04\n",
      "Epoch: 29210 | training loss: 6.2337e-04 | validation loss: 1.0914e-04\n",
      "Epoch: 29220 | training loss: 6.2325e-04 | validation loss: 1.0904e-04\n",
      "Epoch: 29230 | training loss: 6.2321e-04 | validation loss: 1.0897e-04\n",
      "Epoch: 29240 | training loss: 6.2314e-04 | validation loss: 1.0903e-04\n",
      "Epoch: 29250 | training loss: 6.2307e-04 | validation loss: 1.0898e-04\n",
      "Epoch: 29260 | training loss: 6.2301e-04 | validation loss: 1.0897e-04\n",
      "Epoch: 29270 | training loss: 6.2296e-04 | validation loss: 1.0900e-04\n",
      "Epoch: 29280 | training loss: 6.2289e-04 | validation loss: 1.0898e-04\n",
      "Epoch: 29290 | training loss: 6.2284e-04 | validation loss: 1.0896e-04\n",
      "Epoch: 29300 | training loss: 6.2278e-04 | validation loss: 1.0895e-04\n",
      "Epoch: 29310 | training loss: 6.2279e-04 | validation loss: 1.0894e-04\n",
      "Epoch: 29320 | training loss: 6.2516e-04 | validation loss: 1.1035e-04\n",
      "Epoch: 29330 | training loss: 6.2273e-04 | validation loss: 1.0891e-04\n",
      "Epoch: 29340 | training loss: 6.2330e-04 | validation loss: 1.0923e-04\n",
      "Epoch: 29350 | training loss: 6.2306e-04 | validation loss: 1.0957e-04\n",
      "Epoch: 29360 | training loss: 6.2246e-04 | validation loss: 1.0892e-04\n",
      "Epoch: 29370 | training loss: 6.2239e-04 | validation loss: 1.0892e-04\n",
      "Epoch: 29380 | training loss: 6.2235e-04 | validation loss: 1.0899e-04\n",
      "Epoch: 29390 | training loss: 6.2228e-04 | validation loss: 1.0891e-04\n",
      "Epoch: 29400 | training loss: 6.2221e-04 | validation loss: 1.0895e-04\n",
      "Epoch: 29410 | training loss: 6.2215e-04 | validation loss: 1.0892e-04\n",
      "Epoch: 29420 | training loss: 6.2210e-04 | validation loss: 1.0892e-04\n",
      "Epoch: 29430 | training loss: 6.2204e-04 | validation loss: 1.0892e-04\n",
      "Epoch: 29440 | training loss: 6.2198e-04 | validation loss: 1.0891e-04\n",
      "Epoch: 29450 | training loss: 6.2192e-04 | validation loss: 1.0890e-04\n",
      "Epoch: 29460 | training loss: 6.2186e-04 | validation loss: 1.0890e-04\n",
      "Epoch: 29470 | training loss: 6.2182e-04 | validation loss: 1.0888e-04\n",
      "Epoch: 29480 | training loss: 6.2250e-04 | validation loss: 1.0921e-04\n",
      "Epoch: 29490 | training loss: 6.2989e-04 | validation loss: 1.1400e-04\n",
      "Epoch: 29500 | training loss: 6.2168e-04 | validation loss: 1.0896e-04\n",
      "Epoch: 29510 | training loss: 6.2257e-04 | validation loss: 1.0989e-04\n",
      "Epoch: 29520 | training loss: 6.2160e-04 | validation loss: 1.0891e-04\n",
      "Epoch: 29530 | training loss: 6.2158e-04 | validation loss: 1.0886e-04\n",
      "Epoch: 29540 | training loss: 6.2142e-04 | validation loss: 1.0891e-04\n",
      "Epoch: 29550 | training loss: 6.2138e-04 | validation loss: 1.0889e-04\n",
      "Epoch: 29560 | training loss: 6.2130e-04 | validation loss: 1.0886e-04\n",
      "Epoch: 29570 | training loss: 6.2125e-04 | validation loss: 1.0887e-04\n",
      "Epoch: 29580 | training loss: 6.2119e-04 | validation loss: 1.0886e-04\n",
      "Epoch: 29590 | training loss: 6.2113e-04 | validation loss: 1.0886e-04\n",
      "Epoch: 29600 | training loss: 6.2108e-04 | validation loss: 1.0885e-04\n",
      "Epoch: 29610 | training loss: 6.2102e-04 | validation loss: 1.0885e-04\n",
      "Epoch: 29620 | training loss: 6.2096e-04 | validation loss: 1.0884e-04\n",
      "Epoch: 29630 | training loss: 6.2090e-04 | validation loss: 1.0884e-04\n",
      "Epoch: 29640 | training loss: 6.2085e-04 | validation loss: 1.0884e-04\n",
      "Epoch: 29650 | training loss: 6.2079e-04 | validation loss: 1.0884e-04\n",
      "Epoch: 29660 | training loss: 6.2073e-04 | validation loss: 1.0887e-04\n",
      "Epoch: 29670 | training loss: 6.2074e-04 | validation loss: 1.0922e-04\n",
      "Epoch: 29680 | training loss: 6.2347e-04 | validation loss: 1.1309e-04\n",
      "Epoch: 29690 | training loss: 6.2556e-04 | validation loss: 1.1261e-04\n",
      "Epoch: 29700 | training loss: 6.2174e-04 | validation loss: 1.0920e-04\n",
      "Epoch: 29710 | training loss: 6.2117e-04 | validation loss: 1.0943e-04\n",
      "Epoch: 29720 | training loss: 6.2068e-04 | validation loss: 1.0897e-04\n",
      "Epoch: 29730 | training loss: 6.2043e-04 | validation loss: 1.0901e-04\n",
      "Epoch: 29740 | training loss: 6.2032e-04 | validation loss: 1.0884e-04\n",
      "Epoch: 29750 | training loss: 6.2025e-04 | validation loss: 1.0886e-04\n",
      "Epoch: 29760 | training loss: 6.2018e-04 | validation loss: 1.0878e-04\n",
      "Epoch: 29770 | training loss: 6.2012e-04 | validation loss: 1.0877e-04\n",
      "Epoch: 29780 | training loss: 6.2006e-04 | validation loss: 1.0877e-04\n",
      "Epoch: 29790 | training loss: 6.2001e-04 | validation loss: 1.0877e-04\n",
      "Epoch: 29800 | training loss: 6.1996e-04 | validation loss: 1.0877e-04\n",
      "Epoch: 29810 | training loss: 6.1997e-04 | validation loss: 1.0886e-04\n",
      "Epoch: 29820 | training loss: 6.2257e-04 | validation loss: 1.1104e-04\n",
      "Epoch: 29830 | training loss: 6.1980e-04 | validation loss: 1.0885e-04\n",
      "Epoch: 29840 | training loss: 6.2074e-04 | validation loss: 1.0976e-04\n",
      "Epoch: 29850 | training loss: 6.2016e-04 | validation loss: 1.0894e-04\n",
      "Epoch: 29860 | training loss: 6.1962e-04 | validation loss: 1.0876e-04\n",
      "Epoch: 29870 | training loss: 6.1961e-04 | validation loss: 1.0882e-04\n",
      "Epoch: 29880 | training loss: 6.1954e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29890 | training loss: 6.1947e-04 | validation loss: 1.0876e-04\n",
      "Epoch: 29900 | training loss: 6.1941e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29910 | training loss: 6.1935e-04 | validation loss: 1.0873e-04\n",
      "Epoch: 29920 | training loss: 6.1930e-04 | validation loss: 1.0872e-04\n",
      "Epoch: 29930 | training loss: 6.1924e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29940 | training loss: 6.1918e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29950 | training loss: 6.1913e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29960 | training loss: 6.1907e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 29970 | training loss: 6.1903e-04 | validation loss: 1.0873e-04\n",
      "Epoch: 29980 | training loss: 6.1950e-04 | validation loss: 1.0926e-04\n",
      "Epoch: 29990 | training loss: 6.2905e-04 | validation loss: 1.1684e-04\n",
      "Epoch: 30000 | training loss: 6.1938e-04 | validation loss: 1.0878e-04\n",
      "Epoch: 30010 | training loss: 6.1973e-04 | validation loss: 1.0908e-04\n",
      "Epoch: 30020 | training loss: 6.1880e-04 | validation loss: 1.0883e-04\n",
      "Epoch: 30030 | training loss: 6.1881e-04 | validation loss: 1.0887e-04\n",
      "Epoch: 30040 | training loss: 6.1866e-04 | validation loss: 1.0863e-04\n",
      "Epoch: 30050 | training loss: 6.1858e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 30060 | training loss: 6.1853e-04 | validation loss: 1.0870e-04\n",
      "Epoch: 30070 | training loss: 6.1848e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 30080 | training loss: 6.1842e-04 | validation loss: 1.0867e-04\n",
      "Epoch: 30090 | training loss: 6.1836e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 30100 | training loss: 6.1831e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 30110 | training loss: 6.1825e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 30120 | training loss: 6.1820e-04 | validation loss: 1.0864e-04\n",
      "Epoch: 30130 | training loss: 6.1814e-04 | validation loss: 1.0864e-04\n",
      "Epoch: 30140 | training loss: 6.1809e-04 | validation loss: 1.0864e-04\n",
      "Epoch: 30150 | training loss: 6.1803e-04 | validation loss: 1.0863e-04\n",
      "Epoch: 30160 | training loss: 6.1798e-04 | validation loss: 1.0864e-04\n",
      "Epoch: 30170 | training loss: 6.1810e-04 | validation loss: 1.0884e-04\n",
      "Epoch: 30180 | training loss: 6.2925e-04 | validation loss: 1.1758e-04\n",
      "Epoch: 30190 | training loss: 6.2177e-04 | validation loss: 1.1100e-04\n",
      "Epoch: 30200 | training loss: 6.1876e-04 | validation loss: 1.0944e-04\n",
      "Epoch: 30210 | training loss: 6.1771e-04 | validation loss: 1.0863e-04\n",
      "Epoch: 30220 | training loss: 6.1784e-04 | validation loss: 1.0868e-04\n",
      "Epoch: 30230 | training loss: 6.1763e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 30240 | training loss: 6.1756e-04 | validation loss: 1.0860e-04\n",
      "Epoch: 30250 | training loss: 6.1749e-04 | validation loss: 1.0862e-04\n",
      "Epoch: 30260 | training loss: 6.1744e-04 | validation loss: 1.0859e-04\n",
      "Epoch: 30270 | training loss: 6.1738e-04 | validation loss: 1.0859e-04\n",
      "Epoch: 30280 | training loss: 6.1733e-04 | validation loss: 1.0859e-04\n",
      "Epoch: 30290 | training loss: 6.1727e-04 | validation loss: 1.0858e-04\n",
      "Epoch: 30300 | training loss: 6.1722e-04 | validation loss: 1.0858e-04\n",
      "Epoch: 30310 | training loss: 6.1716e-04 | validation loss: 1.0857e-04\n",
      "Epoch: 30320 | training loss: 6.1711e-04 | validation loss: 1.0855e-04\n",
      "Epoch: 30330 | training loss: 6.1707e-04 | validation loss: 1.0843e-04\n",
      "Epoch: 30340 | training loss: 6.1792e-04 | validation loss: 1.0784e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30350 | training loss: 6.1772e-04 | validation loss: 1.0995e-04\n",
      "Epoch: 30360 | training loss: 6.1704e-04 | validation loss: 1.0821e-04\n",
      "Epoch: 30370 | training loss: 6.1699e-04 | validation loss: 1.0823e-04\n",
      "Epoch: 30380 | training loss: 6.1679e-04 | validation loss: 1.0858e-04\n",
      "Epoch: 30390 | training loss: 6.1674e-04 | validation loss: 1.0873e-04\n",
      "Epoch: 30400 | training loss: 6.1668e-04 | validation loss: 1.0855e-04\n",
      "Epoch: 30410 | training loss: 6.1693e-04 | validation loss: 1.0882e-04\n",
      "Epoch: 30420 | training loss: 6.2674e-04 | validation loss: 1.1671e-04\n",
      "Epoch: 30430 | training loss: 6.1957e-04 | validation loss: 1.1027e-04\n",
      "Epoch: 30440 | training loss: 6.1658e-04 | validation loss: 1.0853e-04\n",
      "Epoch: 30450 | training loss: 6.1683e-04 | validation loss: 1.0902e-04\n",
      "Epoch: 30460 | training loss: 6.1636e-04 | validation loss: 1.0853e-04\n",
      "Epoch: 30470 | training loss: 6.1636e-04 | validation loss: 1.0848e-04\n",
      "Epoch: 30480 | training loss: 6.1626e-04 | validation loss: 1.0854e-04\n",
      "Epoch: 30490 | training loss: 6.1620e-04 | validation loss: 1.0850e-04\n",
      "Epoch: 30500 | training loss: 6.1615e-04 | validation loss: 1.0849e-04\n",
      "Epoch: 30510 | training loss: 6.1609e-04 | validation loss: 1.0850e-04\n",
      "Epoch: 30520 | training loss: 6.1604e-04 | validation loss: 1.0849e-04\n",
      "Epoch: 30530 | training loss: 6.1599e-04 | validation loss: 1.0848e-04\n",
      "Epoch: 30540 | training loss: 6.1593e-04 | validation loss: 1.0848e-04\n",
      "Epoch: 30550 | training loss: 6.1588e-04 | validation loss: 1.0848e-04\n",
      "Epoch: 30560 | training loss: 6.1582e-04 | validation loss: 1.0847e-04\n",
      "Epoch: 30570 | training loss: 6.1577e-04 | validation loss: 1.0847e-04\n",
      "Epoch: 30580 | training loss: 6.1572e-04 | validation loss: 1.0846e-04\n",
      "Epoch: 30590 | training loss: 6.1567e-04 | validation loss: 1.0844e-04\n",
      "Epoch: 30600 | training loss: 6.1636e-04 | validation loss: 1.0879e-04\n",
      "Epoch: 30610 | training loss: 6.2419e-04 | validation loss: 1.1391e-04\n",
      "Epoch: 30620 | training loss: 6.1612e-04 | validation loss: 1.0880e-04\n",
      "Epoch: 30630 | training loss: 6.1594e-04 | validation loss: 1.0903e-04\n",
      "Epoch: 30640 | training loss: 6.1581e-04 | validation loss: 1.0880e-04\n",
      "Epoch: 30650 | training loss: 6.1535e-04 | validation loss: 1.0841e-04\n",
      "Epoch: 30660 | training loss: 6.1535e-04 | validation loss: 1.0847e-04\n",
      "Epoch: 30670 | training loss: 6.1525e-04 | validation loss: 1.0843e-04\n",
      "Epoch: 30680 | training loss: 6.1520e-04 | validation loss: 1.0844e-04\n",
      "Epoch: 30690 | training loss: 6.1514e-04 | validation loss: 1.0843e-04\n",
      "Epoch: 30700 | training loss: 6.1509e-04 | validation loss: 1.0842e-04\n",
      "Epoch: 30710 | training loss: 6.1504e-04 | validation loss: 1.0843e-04\n",
      "Epoch: 30720 | training loss: 6.1498e-04 | validation loss: 1.0842e-04\n",
      "Epoch: 30730 | training loss: 6.1493e-04 | validation loss: 1.0841e-04\n",
      "Epoch: 30740 | training loss: 6.1488e-04 | validation loss: 1.0841e-04\n",
      "Epoch: 30750 | training loss: 6.1482e-04 | validation loss: 1.0841e-04\n",
      "Epoch: 30760 | training loss: 6.1477e-04 | validation loss: 1.0840e-04\n",
      "Epoch: 30770 | training loss: 6.1471e-04 | validation loss: 1.0840e-04\n",
      "Epoch: 30780 | training loss: 6.1466e-04 | validation loss: 1.0842e-04\n",
      "Epoch: 30790 | training loss: 6.1463e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 30800 | training loss: 6.1696e-04 | validation loss: 1.1207e-04\n",
      "Epoch: 30810 | training loss: 6.1511e-04 | validation loss: 1.0779e-04\n",
      "Epoch: 30820 | training loss: 6.1557e-04 | validation loss: 1.0852e-04\n",
      "Epoch: 30830 | training loss: 6.1824e-04 | validation loss: 1.1117e-04\n",
      "Epoch: 30840 | training loss: 6.1552e-04 | validation loss: 1.0886e-04\n",
      "Epoch: 30850 | training loss: 6.1466e-04 | validation loss: 1.0873e-04\n",
      "Epoch: 30860 | training loss: 6.1432e-04 | validation loss: 1.0837e-04\n",
      "Epoch: 30870 | training loss: 6.1419e-04 | validation loss: 1.0840e-04\n",
      "Epoch: 30880 | training loss: 6.1416e-04 | validation loss: 1.0845e-04\n",
      "Epoch: 30890 | training loss: 6.1408e-04 | validation loss: 1.0836e-04\n",
      "Epoch: 30900 | training loss: 6.1404e-04 | validation loss: 1.0833e-04\n",
      "Epoch: 30910 | training loss: 6.1402e-04 | validation loss: 1.0831e-04\n",
      "Epoch: 30920 | training loss: 6.1445e-04 | validation loss: 1.0855e-04\n",
      "Epoch: 30930 | training loss: 6.1933e-04 | validation loss: 1.1174e-04\n",
      "Epoch: 30940 | training loss: 6.1546e-04 | validation loss: 1.0983e-04\n",
      "Epoch: 30950 | training loss: 6.1445e-04 | validation loss: 1.0862e-04\n",
      "Epoch: 30960 | training loss: 6.1398e-04 | validation loss: 1.0863e-04\n",
      "Epoch: 30970 | training loss: 6.1377e-04 | validation loss: 1.0831e-04\n",
      "Epoch: 30980 | training loss: 6.1365e-04 | validation loss: 1.0838e-04\n",
      "Epoch: 30990 | training loss: 6.1356e-04 | validation loss: 1.0830e-04\n",
      "Epoch: 31000 | training loss: 6.1351e-04 | validation loss: 1.0829e-04\n",
      "Epoch: 31010 | training loss: 6.1346e-04 | validation loss: 1.0831e-04\n",
      "Epoch: 31020 | training loss: 6.1341e-04 | validation loss: 1.0831e-04\n",
      "Epoch: 31030 | training loss: 6.1337e-04 | validation loss: 1.0834e-04\n",
      "Epoch: 31040 | training loss: 6.1372e-04 | validation loss: 1.0874e-04\n",
      "Epoch: 31050 | training loss: 6.2048e-04 | validation loss: 1.1415e-04\n",
      "Epoch: 31060 | training loss: 6.1577e-04 | validation loss: 1.0973e-04\n",
      "Epoch: 31070 | training loss: 6.1372e-04 | validation loss: 1.0891e-04\n",
      "Epoch: 31080 | training loss: 6.1310e-04 | validation loss: 1.0826e-04\n",
      "Epoch: 31090 | training loss: 6.1306e-04 | validation loss: 1.0824e-04\n",
      "Epoch: 31100 | training loss: 6.1301e-04 | validation loss: 1.0832e-04\n",
      "Epoch: 31110 | training loss: 6.1295e-04 | validation loss: 1.0825e-04\n",
      "Epoch: 31120 | training loss: 6.1289e-04 | validation loss: 1.0827e-04\n",
      "Epoch: 31130 | training loss: 6.1284e-04 | validation loss: 1.0826e-04\n",
      "Epoch: 31140 | training loss: 6.1279e-04 | validation loss: 1.0825e-04\n",
      "Epoch: 31150 | training loss: 6.1273e-04 | validation loss: 1.0825e-04\n",
      "Epoch: 31160 | training loss: 6.1268e-04 | validation loss: 1.0825e-04\n",
      "Epoch: 31170 | training loss: 6.1263e-04 | validation loss: 1.0825e-04\n",
      "Epoch: 31180 | training loss: 6.1260e-04 | validation loss: 1.0830e-04\n",
      "Epoch: 31190 | training loss: 6.1373e-04 | validation loss: 1.0936e-04\n",
      "Epoch: 31200 | training loss: 6.1674e-04 | validation loss: 1.1188e-04\n",
      "Epoch: 31210 | training loss: 6.1255e-04 | validation loss: 1.0827e-04\n",
      "Epoch: 31220 | training loss: 6.1323e-04 | validation loss: 1.0868e-04\n",
      "Epoch: 31230 | training loss: 6.1232e-04 | validation loss: 1.0830e-04\n",
      "Epoch: 31240 | training loss: 6.1236e-04 | validation loss: 1.0827e-04\n",
      "Epoch: 31250 | training loss: 6.1225e-04 | validation loss: 1.0825e-04\n",
      "Epoch: 31260 | training loss: 6.1217e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31270 | training loss: 6.1212e-04 | validation loss: 1.0822e-04\n",
      "Epoch: 31280 | training loss: 6.1206e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31290 | training loss: 6.1201e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31300 | training loss: 6.1196e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31310 | training loss: 6.1191e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31320 | training loss: 6.1186e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31330 | training loss: 6.1180e-04 | validation loss: 1.0823e-04\n",
      "Epoch: 31340 | training loss: 6.1178e-04 | validation loss: 1.0846e-04\n",
      "Epoch: 31350 | training loss: 6.1352e-04 | validation loss: 1.1122e-04\n",
      "Epoch: 31360 | training loss: 6.1251e-04 | validation loss: 1.0760e-04\n",
      "Epoch: 31370 | training loss: 6.1274e-04 | validation loss: 1.0892e-04\n",
      "Epoch: 31380 | training loss: 6.1379e-04 | validation loss: 1.1047e-04\n",
      "Epoch: 31390 | training loss: 6.1226e-04 | validation loss: 1.0883e-04\n",
      "Epoch: 31400 | training loss: 6.1150e-04 | validation loss: 1.0837e-04\n",
      "Epoch: 31410 | training loss: 6.1145e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31420 | training loss: 6.1139e-04 | validation loss: 1.0807e-04\n",
      "Epoch: 31430 | training loss: 6.1133e-04 | validation loss: 1.0812e-04\n",
      "Epoch: 31440 | training loss: 6.1127e-04 | validation loss: 1.0815e-04\n",
      "Epoch: 31450 | training loss: 6.1141e-04 | validation loss: 1.0821e-04\n",
      "Epoch: 31460 | training loss: 6.1455e-04 | validation loss: 1.1021e-04\n",
      "Epoch: 31470 | training loss: 6.1111e-04 | validation loss: 1.0815e-04\n",
      "Epoch: 31480 | training loss: 6.1107e-04 | validation loss: 1.0810e-04\n",
      "Epoch: 31490 | training loss: 6.1102e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 31500 | training loss: 6.1094e-04 | validation loss: 1.0811e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31510 | training loss: 6.1089e-04 | validation loss: 1.0811e-04\n",
      "Epoch: 31520 | training loss: 6.1085e-04 | validation loss: 1.0815e-04\n",
      "Epoch: 31530 | training loss: 6.1079e-04 | validation loss: 1.0810e-04\n",
      "Epoch: 31540 | training loss: 6.1074e-04 | validation loss: 1.0810e-04\n",
      "Epoch: 31550 | training loss: 6.1068e-04 | validation loss: 1.0810e-04\n",
      "Epoch: 31560 | training loss: 6.1063e-04 | validation loss: 1.0810e-04\n",
      "Epoch: 31570 | training loss: 6.1060e-04 | validation loss: 1.0808e-04\n",
      "Epoch: 31580 | training loss: 6.1140e-04 | validation loss: 1.0852e-04\n",
      "Epoch: 31590 | training loss: 6.1774e-04 | validation loss: 1.1268e-04\n",
      "Epoch: 31600 | training loss: 6.1047e-04 | validation loss: 1.0815e-04\n",
      "Epoch: 31610 | training loss: 6.1138e-04 | validation loss: 1.0907e-04\n",
      "Epoch: 31620 | training loss: 6.1035e-04 | validation loss: 1.0805e-04\n",
      "Epoch: 31630 | training loss: 6.1041e-04 | validation loss: 1.0807e-04\n",
      "Epoch: 31640 | training loss: 6.1024e-04 | validation loss: 1.0812e-04\n",
      "Epoch: 31650 | training loss: 6.1019e-04 | validation loss: 1.0809e-04\n",
      "Epoch: 31660 | training loss: 6.1014e-04 | validation loss: 1.0805e-04\n",
      "Epoch: 31670 | training loss: 6.1009e-04 | validation loss: 1.0809e-04\n",
      "Epoch: 31680 | training loss: 6.1003e-04 | validation loss: 1.0805e-04\n",
      "Epoch: 31690 | training loss: 6.0998e-04 | validation loss: 1.0807e-04\n",
      "Epoch: 31700 | training loss: 6.0993e-04 | validation loss: 1.0805e-04\n",
      "Epoch: 31710 | training loss: 6.0988e-04 | validation loss: 1.0805e-04\n",
      "Epoch: 31720 | training loss: 6.0983e-04 | validation loss: 1.0805e-04\n",
      "Epoch: 31730 | training loss: 6.0978e-04 | validation loss: 1.0804e-04\n",
      "Epoch: 31740 | training loss: 6.0973e-04 | validation loss: 1.0804e-04\n",
      "Epoch: 31750 | training loss: 6.0968e-04 | validation loss: 1.0803e-04\n",
      "Epoch: 31760 | training loss: 6.0963e-04 | validation loss: 1.0801e-04\n",
      "Epoch: 31770 | training loss: 6.0970e-04 | validation loss: 1.0795e-04\n",
      "Epoch: 31780 | training loss: 6.1895e-04 | validation loss: 1.1372e-04\n",
      "Epoch: 31790 | training loss: 6.1441e-04 | validation loss: 1.1271e-04\n",
      "Epoch: 31800 | training loss: 6.1048e-04 | validation loss: 1.1009e-04\n",
      "Epoch: 31810 | training loss: 6.0987e-04 | validation loss: 1.0919e-04\n",
      "Epoch: 31820 | training loss: 6.0944e-04 | validation loss: 1.0851e-04\n",
      "Epoch: 31830 | training loss: 6.0933e-04 | validation loss: 1.0823e-04\n",
      "Epoch: 31840 | training loss: 6.0924e-04 | validation loss: 1.0810e-04\n",
      "Epoch: 31850 | training loss: 6.0919e-04 | validation loss: 1.0803e-04\n",
      "Epoch: 31860 | training loss: 6.0914e-04 | validation loss: 1.0796e-04\n",
      "Epoch: 31870 | training loss: 6.0909e-04 | validation loss: 1.0796e-04\n",
      "Epoch: 31880 | training loss: 6.0904e-04 | validation loss: 1.0797e-04\n",
      "Epoch: 31890 | training loss: 6.0900e-04 | validation loss: 1.0799e-04\n",
      "Epoch: 31900 | training loss: 6.0895e-04 | validation loss: 1.0800e-04\n",
      "Epoch: 31910 | training loss: 6.0890e-04 | validation loss: 1.0799e-04\n",
      "Epoch: 31920 | training loss: 6.0885e-04 | validation loss: 1.0798e-04\n",
      "Epoch: 31930 | training loss: 6.0880e-04 | validation loss: 1.0798e-04\n",
      "Epoch: 31940 | training loss: 6.0875e-04 | validation loss: 1.0798e-04\n",
      "Epoch: 31950 | training loss: 6.0870e-04 | validation loss: 1.0797e-04\n",
      "Epoch: 31960 | training loss: 6.0865e-04 | validation loss: 1.0797e-04\n",
      "Epoch: 31970 | training loss: 6.0860e-04 | validation loss: 1.0797e-04\n",
      "Epoch: 31980 | training loss: 6.0858e-04 | validation loss: 1.0802e-04\n",
      "Epoch: 31990 | training loss: 6.1480e-04 | validation loss: 1.1272e-04\n",
      "Epoch: 32000 | training loss: 6.1471e-04 | validation loss: 1.1236e-04\n",
      "Epoch: 32010 | training loss: 6.0876e-04 | validation loss: 1.0781e-04\n",
      "Epoch: 32020 | training loss: 6.0841e-04 | validation loss: 1.0801e-04\n",
      "Epoch: 32030 | training loss: 6.0851e-04 | validation loss: 1.0830e-04\n",
      "Epoch: 32040 | training loss: 6.0838e-04 | validation loss: 1.0820e-04\n",
      "Epoch: 32050 | training loss: 6.0823e-04 | validation loss: 1.0806e-04\n",
      "Epoch: 32060 | training loss: 6.0818e-04 | validation loss: 1.0800e-04\n",
      "Epoch: 32070 | training loss: 6.0813e-04 | validation loss: 1.0796e-04\n",
      "Epoch: 32080 | training loss: 6.0808e-04 | validation loss: 1.0793e-04\n",
      "Epoch: 32090 | training loss: 6.0803e-04 | validation loss: 1.0792e-04\n",
      "Epoch: 32100 | training loss: 6.0798e-04 | validation loss: 1.0793e-04\n",
      "Epoch: 32110 | training loss: 6.0794e-04 | validation loss: 1.0792e-04\n",
      "Epoch: 32120 | training loss: 6.0789e-04 | validation loss: 1.0792e-04\n",
      "Epoch: 32130 | training loss: 6.0784e-04 | validation loss: 1.0791e-04\n",
      "Epoch: 32140 | training loss: 6.0779e-04 | validation loss: 1.0791e-04\n",
      "Epoch: 32150 | training loss: 6.0774e-04 | validation loss: 1.0790e-04\n",
      "Epoch: 32160 | training loss: 6.0770e-04 | validation loss: 1.0790e-04\n",
      "Epoch: 32170 | training loss: 6.0765e-04 | validation loss: 1.0790e-04\n",
      "Epoch: 32180 | training loss: 6.0760e-04 | validation loss: 1.0789e-04\n",
      "Epoch: 32190 | training loss: 6.0755e-04 | validation loss: 1.0789e-04\n",
      "Epoch: 32200 | training loss: 6.0750e-04 | validation loss: 1.0789e-04\n",
      "Epoch: 32210 | training loss: 6.0745e-04 | validation loss: 1.0788e-04\n",
      "Epoch: 32220 | training loss: 6.0740e-04 | validation loss: 1.0788e-04\n",
      "Epoch: 32230 | training loss: 6.0736e-04 | validation loss: 1.0791e-04\n",
      "Epoch: 32240 | training loss: 6.0939e-04 | validation loss: 1.0968e-04\n",
      "Epoch: 32250 | training loss: 6.0750e-04 | validation loss: 1.0803e-04\n",
      "Epoch: 32260 | training loss: 6.0810e-04 | validation loss: 1.0887e-04\n",
      "Epoch: 32270 | training loss: 6.0773e-04 | validation loss: 1.0855e-04\n",
      "Epoch: 32280 | training loss: 6.0740e-04 | validation loss: 1.0824e-04\n",
      "Epoch: 32290 | training loss: 6.0721e-04 | validation loss: 1.0805e-04\n",
      "Epoch: 32300 | training loss: 6.0708e-04 | validation loss: 1.0792e-04\n",
      "Epoch: 32310 | training loss: 6.0699e-04 | validation loss: 1.0785e-04\n",
      "Epoch: 32320 | training loss: 6.0693e-04 | validation loss: 1.0783e-04\n",
      "Epoch: 32330 | training loss: 6.0689e-04 | validation loss: 1.0784e-04\n",
      "Epoch: 32340 | training loss: 6.0684e-04 | validation loss: 1.0785e-04\n",
      "Epoch: 32350 | training loss: 6.0679e-04 | validation loss: 1.0785e-04\n",
      "Epoch: 32360 | training loss: 6.0675e-04 | validation loss: 1.0784e-04\n",
      "Epoch: 32370 | training loss: 6.0670e-04 | validation loss: 1.0784e-04\n",
      "Epoch: 32380 | training loss: 6.0665e-04 | validation loss: 1.0784e-04\n",
      "Epoch: 32390 | training loss: 6.0660e-04 | validation loss: 1.0783e-04\n",
      "Epoch: 32400 | training loss: 6.0656e-04 | validation loss: 1.0783e-04\n",
      "Epoch: 32410 | training loss: 6.0651e-04 | validation loss: 1.0782e-04\n",
      "Epoch: 32420 | training loss: 6.0646e-04 | validation loss: 1.0782e-04\n",
      "Epoch: 32430 | training loss: 6.0641e-04 | validation loss: 1.0782e-04\n",
      "Epoch: 32440 | training loss: 6.0636e-04 | validation loss: 1.0781e-04\n",
      "Epoch: 32450 | training loss: 6.0631e-04 | validation loss: 1.0781e-04\n",
      "Epoch: 32460 | training loss: 6.0626e-04 | validation loss: 1.0781e-04\n",
      "Epoch: 32470 | training loss: 6.0621e-04 | validation loss: 1.0780e-04\n",
      "Epoch: 32480 | training loss: 6.0617e-04 | validation loss: 1.0780e-04\n",
      "Epoch: 32490 | training loss: 6.0612e-04 | validation loss: 1.0780e-04\n",
      "Epoch: 32500 | training loss: 6.0607e-04 | validation loss: 1.0780e-04\n",
      "Epoch: 32510 | training loss: 6.0602e-04 | validation loss: 1.0782e-04\n",
      "Epoch: 32520 | training loss: 6.0629e-04 | validation loss: 1.0853e-04\n",
      "Epoch: 32530 | training loss: 6.1400e-04 | validation loss: 1.1277e-04\n",
      "Epoch: 32540 | training loss: 6.1033e-04 | validation loss: 1.0957e-04\n",
      "Epoch: 32550 | training loss: 6.0588e-04 | validation loss: 1.0749e-04\n",
      "Epoch: 32560 | training loss: 6.0637e-04 | validation loss: 1.0865e-04\n",
      "Epoch: 32570 | training loss: 6.0584e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 32580 | training loss: 6.0575e-04 | validation loss: 1.0796e-04\n",
      "Epoch: 32590 | training loss: 6.0565e-04 | validation loss: 1.0782e-04\n",
      "Epoch: 32600 | training loss: 6.0561e-04 | validation loss: 1.0766e-04\n",
      "Epoch: 32610 | training loss: 6.0556e-04 | validation loss: 1.0778e-04\n",
      "Epoch: 32620 | training loss: 6.0551e-04 | validation loss: 1.0776e-04\n",
      "Epoch: 32630 | training loss: 6.0547e-04 | validation loss: 1.0773e-04\n",
      "Epoch: 32640 | training loss: 6.0542e-04 | validation loss: 1.0773e-04\n",
      "Epoch: 32650 | training loss: 6.0538e-04 | validation loss: 1.0774e-04\n",
      "Epoch: 32660 | training loss: 6.0533e-04 | validation loss: 1.0773e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32670 | training loss: 6.0528e-04 | validation loss: 1.0772e-04\n",
      "Epoch: 32680 | training loss: 6.0524e-04 | validation loss: 1.0772e-04\n",
      "Epoch: 32690 | training loss: 6.0519e-04 | validation loss: 1.0772e-04\n",
      "Epoch: 32700 | training loss: 6.0514e-04 | validation loss: 1.0772e-04\n",
      "Epoch: 32710 | training loss: 6.0510e-04 | validation loss: 1.0772e-04\n",
      "Epoch: 32720 | training loss: 6.0516e-04 | validation loss: 1.0785e-04\n",
      "Epoch: 32730 | training loss: 6.1503e-04 | validation loss: 1.1557e-04\n",
      "Epoch: 32740 | training loss: 6.1086e-04 | validation loss: 1.1143e-04\n",
      "Epoch: 32750 | training loss: 6.0591e-04 | validation loss: 1.0821e-04\n",
      "Epoch: 32760 | training loss: 6.0487e-04 | validation loss: 1.0771e-04\n",
      "Epoch: 32770 | training loss: 6.0499e-04 | validation loss: 1.0789e-04\n",
      "Epoch: 32780 | training loss: 6.0487e-04 | validation loss: 1.0781e-04\n",
      "Epoch: 32790 | training loss: 6.0474e-04 | validation loss: 1.0769e-04\n",
      "Epoch: 32800 | training loss: 6.0470e-04 | validation loss: 1.0767e-04\n",
      "Epoch: 32810 | training loss: 6.0465e-04 | validation loss: 1.0768e-04\n",
      "Epoch: 32820 | training loss: 6.0460e-04 | validation loss: 1.0769e-04\n",
      "Epoch: 32830 | training loss: 6.0456e-04 | validation loss: 1.0768e-04\n",
      "Epoch: 32840 | training loss: 6.0451e-04 | validation loss: 1.0767e-04\n",
      "Epoch: 32850 | training loss: 6.0447e-04 | validation loss: 1.0767e-04\n",
      "Epoch: 32860 | training loss: 6.0442e-04 | validation loss: 1.0767e-04\n",
      "Epoch: 32870 | training loss: 6.0438e-04 | validation loss: 1.0766e-04\n",
      "Epoch: 32880 | training loss: 6.0433e-04 | validation loss: 1.0766e-04\n",
      "Epoch: 32890 | training loss: 6.0428e-04 | validation loss: 1.0766e-04\n",
      "Epoch: 32900 | training loss: 6.0424e-04 | validation loss: 1.0765e-04\n",
      "Epoch: 32910 | training loss: 6.0419e-04 | validation loss: 1.0765e-04\n",
      "Epoch: 32920 | training loss: 6.0414e-04 | validation loss: 1.0765e-04\n",
      "Epoch: 32930 | training loss: 6.0410e-04 | validation loss: 1.0764e-04\n",
      "Epoch: 32940 | training loss: 6.0405e-04 | validation loss: 1.0764e-04\n",
      "Epoch: 32950 | training loss: 6.0400e-04 | validation loss: 1.0763e-04\n",
      "Epoch: 32960 | training loss: 6.0412e-04 | validation loss: 1.0767e-04\n",
      "Epoch: 32970 | training loss: 6.2012e-04 | validation loss: 1.1853e-04\n",
      "Epoch: 32980 | training loss: 6.0512e-04 | validation loss: 1.0883e-04\n",
      "Epoch: 32990 | training loss: 6.0537e-04 | validation loss: 1.0904e-04\n",
      "Epoch: 33000 | training loss: 6.0451e-04 | validation loss: 1.0834e-04\n",
      "Epoch: 33010 | training loss: 6.0397e-04 | validation loss: 1.0789e-04\n",
      "Epoch: 33020 | training loss: 6.0372e-04 | validation loss: 1.0767e-04\n",
      "Epoch: 33030 | training loss: 6.0365e-04 | validation loss: 1.0761e-04\n",
      "Epoch: 33040 | training loss: 6.0361e-04 | validation loss: 1.0760e-04\n",
      "Epoch: 33050 | training loss: 6.0356e-04 | validation loss: 1.0760e-04\n",
      "Epoch: 33060 | training loss: 6.0351e-04 | validation loss: 1.0761e-04\n",
      "Epoch: 33070 | training loss: 6.0347e-04 | validation loss: 1.0761e-04\n",
      "Epoch: 33080 | training loss: 6.0342e-04 | validation loss: 1.0760e-04\n",
      "Epoch: 33090 | training loss: 6.0338e-04 | validation loss: 1.0760e-04\n",
      "Epoch: 33100 | training loss: 6.0333e-04 | validation loss: 1.0760e-04\n",
      "Epoch: 33110 | training loss: 6.0329e-04 | validation loss: 1.0759e-04\n",
      "Epoch: 33120 | training loss: 6.0324e-04 | validation loss: 1.0759e-04\n",
      "Epoch: 33130 | training loss: 6.0319e-04 | validation loss: 1.0758e-04\n",
      "Epoch: 33140 | training loss: 6.0315e-04 | validation loss: 1.0758e-04\n",
      "Epoch: 33150 | training loss: 6.0310e-04 | validation loss: 1.0758e-04\n",
      "Epoch: 33160 | training loss: 6.0305e-04 | validation loss: 1.0757e-04\n",
      "Epoch: 33170 | training loss: 6.0301e-04 | validation loss: 1.0757e-04\n",
      "Epoch: 33180 | training loss: 6.0296e-04 | validation loss: 1.0757e-04\n",
      "Epoch: 33190 | training loss: 6.0291e-04 | validation loss: 1.0756e-04\n",
      "Epoch: 33200 | training loss: 6.0287e-04 | validation loss: 1.0756e-04\n",
      "Epoch: 33210 | training loss: 6.0282e-04 | validation loss: 1.0756e-04\n",
      "Epoch: 33220 | training loss: 6.0277e-04 | validation loss: 1.0755e-04\n",
      "Epoch: 33230 | training loss: 6.0278e-04 | validation loss: 1.0755e-04\n",
      "Epoch: 33240 | training loss: 6.1691e-04 | validation loss: 1.1711e-04\n",
      "Epoch: 33250 | training loss: 6.0636e-04 | validation loss: 1.1079e-04\n",
      "Epoch: 33260 | training loss: 6.0356e-04 | validation loss: 1.0855e-04\n",
      "Epoch: 33270 | training loss: 6.0261e-04 | validation loss: 1.0774e-04\n",
      "Epoch: 33280 | training loss: 6.0251e-04 | validation loss: 1.0761e-04\n",
      "Epoch: 33290 | training loss: 6.0248e-04 | validation loss: 1.0757e-04\n",
      "Epoch: 33300 | training loss: 6.0243e-04 | validation loss: 1.0754e-04\n",
      "Epoch: 33310 | training loss: 6.0238e-04 | validation loss: 1.0752e-04\n",
      "Epoch: 33320 | training loss: 6.0233e-04 | validation loss: 1.0752e-04\n",
      "Epoch: 33330 | training loss: 6.0229e-04 | validation loss: 1.0753e-04\n",
      "Epoch: 33340 | training loss: 6.0224e-04 | validation loss: 1.0753e-04\n",
      "Epoch: 33350 | training loss: 6.0220e-04 | validation loss: 1.0752e-04\n",
      "Epoch: 33360 | training loss: 6.0216e-04 | validation loss: 1.0752e-04\n",
      "Epoch: 33370 | training loss: 6.0211e-04 | validation loss: 1.0752e-04\n",
      "Epoch: 33380 | training loss: 6.0207e-04 | validation loss: 1.0751e-04\n",
      "Epoch: 33390 | training loss: 6.0202e-04 | validation loss: 1.0751e-04\n",
      "Epoch: 33400 | training loss: 6.0198e-04 | validation loss: 1.0751e-04\n",
      "Epoch: 33410 | training loss: 6.0193e-04 | validation loss: 1.0750e-04\n",
      "Epoch: 33420 | training loss: 6.0189e-04 | validation loss: 1.0750e-04\n",
      "Epoch: 33430 | training loss: 6.0184e-04 | validation loss: 1.0750e-04\n",
      "Epoch: 33440 | training loss: 6.0179e-04 | validation loss: 1.0749e-04\n",
      "Epoch: 33450 | training loss: 6.0175e-04 | validation loss: 1.0749e-04\n",
      "Epoch: 33460 | training loss: 6.0170e-04 | validation loss: 1.0749e-04\n",
      "Epoch: 33470 | training loss: 6.0166e-04 | validation loss: 1.0748e-04\n",
      "Epoch: 33480 | training loss: 6.0161e-04 | validation loss: 1.0748e-04\n",
      "Epoch: 33490 | training loss: 6.0156e-04 | validation loss: 1.0748e-04\n",
      "Epoch: 33500 | training loss: 6.0152e-04 | validation loss: 1.0746e-04\n",
      "Epoch: 33510 | training loss: 6.0148e-04 | validation loss: 1.0731e-04\n",
      "Epoch: 33520 | training loss: 6.0485e-04 | validation loss: 1.0719e-04\n",
      "Epoch: 33530 | training loss: 6.0183e-04 | validation loss: 1.0789e-04\n",
      "Epoch: 33540 | training loss: 6.0190e-04 | validation loss: 1.0790e-04\n",
      "Epoch: 33550 | training loss: 6.0143e-04 | validation loss: 1.0747e-04\n",
      "Epoch: 33560 | training loss: 6.0125e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 33570 | training loss: 6.0120e-04 | validation loss: 1.0736e-04\n",
      "Epoch: 33580 | training loss: 6.0119e-04 | validation loss: 1.0739e-04\n",
      "Epoch: 33590 | training loss: 6.0270e-04 | validation loss: 1.0837e-04\n",
      "Epoch: 33600 | training loss: 6.0341e-04 | validation loss: 1.0880e-04\n",
      "Epoch: 33610 | training loss: 6.0131e-04 | validation loss: 1.0749e-04\n",
      "Epoch: 33620 | training loss: 6.0175e-04 | validation loss: 1.0813e-04\n",
      "Epoch: 33630 | training loss: 6.0095e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 33640 | training loss: 6.0094e-04 | validation loss: 1.0742e-04\n",
      "Epoch: 33650 | training loss: 6.0088e-04 | validation loss: 1.0749e-04\n",
      "Epoch: 33660 | training loss: 6.0081e-04 | validation loss: 1.0741e-04\n",
      "Epoch: 33670 | training loss: 6.0076e-04 | validation loss: 1.0743e-04\n",
      "Epoch: 33680 | training loss: 6.0071e-04 | validation loss: 1.0741e-04\n",
      "Epoch: 33690 | training loss: 6.0067e-04 | validation loss: 1.0742e-04\n",
      "Epoch: 33700 | training loss: 6.0062e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 33710 | training loss: 6.0058e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 33720 | training loss: 6.0053e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 33730 | training loss: 6.0049e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 33740 | training loss: 6.0044e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 33750 | training loss: 6.0040e-04 | validation loss: 1.0741e-04\n",
      "Epoch: 33760 | training loss: 6.0057e-04 | validation loss: 1.0763e-04\n",
      "Epoch: 33770 | training loss: 6.1173e-04 | validation loss: 1.1626e-04\n",
      "Epoch: 33780 | training loss: 6.0415e-04 | validation loss: 1.0976e-04\n",
      "Epoch: 33790 | training loss: 6.0077e-04 | validation loss: 1.0761e-04\n",
      "Epoch: 33800 | training loss: 6.0037e-04 | validation loss: 1.0759e-04\n",
      "Epoch: 33810 | training loss: 6.0031e-04 | validation loss: 1.0758e-04\n",
      "Epoch: 33820 | training loss: 6.0010e-04 | validation loss: 1.0736e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33830 | training loss: 6.0007e-04 | validation loss: 1.0736e-04\n",
      "Epoch: 33840 | training loss: 6.0001e-04 | validation loss: 1.0739e-04\n",
      "Epoch: 33850 | training loss: 5.9996e-04 | validation loss: 1.0737e-04\n",
      "Epoch: 33860 | training loss: 5.9991e-04 | validation loss: 1.0736e-04\n",
      "Epoch: 33870 | training loss: 5.9987e-04 | validation loss: 1.0736e-04\n",
      "Epoch: 33880 | training loss: 5.9983e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 33890 | training loss: 5.9978e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 33900 | training loss: 5.9974e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 33910 | training loss: 5.9969e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 33920 | training loss: 5.9965e-04 | validation loss: 1.0734e-04\n",
      "Epoch: 33930 | training loss: 5.9960e-04 | validation loss: 1.0734e-04\n",
      "Epoch: 33940 | training loss: 5.9956e-04 | validation loss: 1.0734e-04\n",
      "Epoch: 33950 | training loss: 5.9951e-04 | validation loss: 1.0733e-04\n",
      "Epoch: 33960 | training loss: 5.9946e-04 | validation loss: 1.0733e-04\n",
      "Epoch: 33970 | training loss: 5.9944e-04 | validation loss: 1.0737e-04\n",
      "Epoch: 33980 | training loss: 6.0242e-04 | validation loss: 1.0984e-04\n",
      "Epoch: 33990 | training loss: 6.0102e-04 | validation loss: 1.0839e-04\n",
      "Epoch: 34000 | training loss: 5.9973e-04 | validation loss: 1.0790e-04\n",
      "Epoch: 34010 | training loss: 5.9983e-04 | validation loss: 1.0792e-04\n",
      "Epoch: 34020 | training loss: 5.9956e-04 | validation loss: 1.0762e-04\n",
      "Epoch: 34030 | training loss: 5.9931e-04 | validation loss: 1.0739e-04\n",
      "Epoch: 34040 | training loss: 5.9914e-04 | validation loss: 1.0730e-04\n",
      "Epoch: 34050 | training loss: 5.9907e-04 | validation loss: 1.0732e-04\n",
      "Epoch: 34060 | training loss: 5.9904e-04 | validation loss: 1.0732e-04\n",
      "Epoch: 34070 | training loss: 5.9899e-04 | validation loss: 1.0730e-04\n",
      "Epoch: 34080 | training loss: 5.9895e-04 | validation loss: 1.0730e-04\n",
      "Epoch: 34090 | training loss: 5.9890e-04 | validation loss: 1.0730e-04\n",
      "Epoch: 34100 | training loss: 5.9886e-04 | validation loss: 1.0729e-04\n",
      "Epoch: 34110 | training loss: 5.9882e-04 | validation loss: 1.0729e-04\n",
      "Epoch: 34120 | training loss: 5.9877e-04 | validation loss: 1.0729e-04\n",
      "Epoch: 34130 | training loss: 5.9873e-04 | validation loss: 1.0729e-04\n",
      "Epoch: 34140 | training loss: 5.9868e-04 | validation loss: 1.0728e-04\n",
      "Epoch: 34150 | training loss: 5.9864e-04 | validation loss: 1.0728e-04\n",
      "Epoch: 34160 | training loss: 5.9859e-04 | validation loss: 1.0728e-04\n",
      "Epoch: 34170 | training loss: 5.9855e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 34180 | training loss: 5.9850e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 34190 | training loss: 5.9846e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 34200 | training loss: 5.9841e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 34210 | training loss: 5.9837e-04 | validation loss: 1.0734e-04\n",
      "Epoch: 34220 | training loss: 5.9902e-04 | validation loss: 1.0885e-04\n",
      "Epoch: 34230 | training loss: 5.9951e-04 | validation loss: 1.0670e-04\n",
      "Epoch: 34240 | training loss: 6.0056e-04 | validation loss: 1.0871e-04\n",
      "Epoch: 34250 | training loss: 5.9852e-04 | validation loss: 1.0722e-04\n",
      "Epoch: 34260 | training loss: 5.9863e-04 | validation loss: 1.0718e-04\n",
      "Epoch: 34270 | training loss: 5.9840e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 34280 | training loss: 5.9811e-04 | validation loss: 1.0709e-04\n",
      "Epoch: 34290 | training loss: 5.9804e-04 | validation loss: 1.0714e-04\n",
      "Epoch: 34300 | training loss: 5.9798e-04 | validation loss: 1.0719e-04\n",
      "Epoch: 34310 | training loss: 5.9796e-04 | validation loss: 1.0724e-04\n",
      "Epoch: 34320 | training loss: 5.9811e-04 | validation loss: 1.0743e-04\n",
      "Epoch: 34330 | training loss: 6.0087e-04 | validation loss: 1.0966e-04\n",
      "Epoch: 34340 | training loss: 5.9783e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 34350 | training loss: 5.9777e-04 | validation loss: 1.0720e-04\n",
      "Epoch: 34360 | training loss: 5.9772e-04 | validation loss: 1.0723e-04\n",
      "Epoch: 34370 | training loss: 5.9769e-04 | validation loss: 1.0720e-04\n",
      "Epoch: 34380 | training loss: 5.9766e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 34390 | training loss: 5.9760e-04 | validation loss: 1.0720e-04\n",
      "Epoch: 34400 | training loss: 5.9754e-04 | validation loss: 1.0720e-04\n",
      "Epoch: 34410 | training loss: 5.9750e-04 | validation loss: 1.0721e-04\n",
      "Epoch: 34420 | training loss: 5.9747e-04 | validation loss: 1.0723e-04\n",
      "Epoch: 34430 | training loss: 5.9754e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 34440 | training loss: 6.0019e-04 | validation loss: 1.0951e-04\n",
      "Epoch: 34450 | training loss: 5.9745e-04 | validation loss: 1.0736e-04\n",
      "Epoch: 34460 | training loss: 5.9735e-04 | validation loss: 1.0729e-04\n",
      "Epoch: 34470 | training loss: 5.9746e-04 | validation loss: 1.0725e-04\n",
      "Epoch: 34480 | training loss: 5.9734e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 34490 | training loss: 5.9721e-04 | validation loss: 1.0717e-04\n",
      "Epoch: 34500 | training loss: 5.9713e-04 | validation loss: 1.0721e-04\n",
      "Epoch: 34510 | training loss: 5.9707e-04 | validation loss: 1.0717e-04\n",
      "Epoch: 34520 | training loss: 5.9702e-04 | validation loss: 1.0716e-04\n",
      "Epoch: 34530 | training loss: 5.9698e-04 | validation loss: 1.0718e-04\n",
      "Epoch: 34540 | training loss: 5.9693e-04 | validation loss: 1.0717e-04\n",
      "Epoch: 34550 | training loss: 5.9689e-04 | validation loss: 1.0717e-04\n",
      "Epoch: 34560 | training loss: 5.9686e-04 | validation loss: 1.0719e-04\n",
      "Epoch: 34570 | training loss: 5.9717e-04 | validation loss: 1.0752e-04\n",
      "Epoch: 34580 | training loss: 6.0645e-04 | validation loss: 1.1473e-04\n",
      "Epoch: 34590 | training loss: 5.9986e-04 | validation loss: 1.0906e-04\n",
      "Epoch: 34600 | training loss: 5.9667e-04 | validation loss: 1.0718e-04\n",
      "Epoch: 34610 | training loss: 5.9702e-04 | validation loss: 1.0756e-04\n",
      "Epoch: 34620 | training loss: 5.9666e-04 | validation loss: 1.0713e-04\n",
      "Epoch: 34630 | training loss: 5.9655e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 34640 | training loss: 5.9652e-04 | validation loss: 1.0717e-04\n",
      "Epoch: 34650 | training loss: 5.9647e-04 | validation loss: 1.0713e-04\n",
      "Epoch: 34660 | training loss: 5.9642e-04 | validation loss: 1.0714e-04\n",
      "Epoch: 34670 | training loss: 5.9638e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 34680 | training loss: 5.9633e-04 | validation loss: 1.0713e-04\n",
      "Epoch: 34690 | training loss: 5.9629e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 34700 | training loss: 5.9624e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 34710 | training loss: 5.9620e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 34720 | training loss: 5.9616e-04 | validation loss: 1.0711e-04\n",
      "Epoch: 34730 | training loss: 5.9611e-04 | validation loss: 1.0711e-04\n",
      "Epoch: 34740 | training loss: 5.9608e-04 | validation loss: 1.0710e-04\n",
      "Epoch: 34750 | training loss: 5.9665e-04 | validation loss: 1.0743e-04\n",
      "Epoch: 34760 | training loss: 6.0750e-04 | validation loss: 1.1480e-04\n",
      "Epoch: 34770 | training loss: 5.9633e-04 | validation loss: 1.0747e-04\n",
      "Epoch: 34780 | training loss: 5.9647e-04 | validation loss: 1.0760e-04\n",
      "Epoch: 34790 | training loss: 5.9634e-04 | validation loss: 1.0738e-04\n",
      "Epoch: 34800 | training loss: 5.9584e-04 | validation loss: 1.0713e-04\n",
      "Epoch: 34810 | training loss: 5.9581e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 34820 | training loss: 5.9574e-04 | validation loss: 1.0709e-04\n",
      "Epoch: 34830 | training loss: 5.9569e-04 | validation loss: 1.0709e-04\n",
      "Epoch: 34840 | training loss: 5.9565e-04 | validation loss: 1.0708e-04\n",
      "Epoch: 34850 | training loss: 5.9561e-04 | validation loss: 1.0708e-04\n",
      "Epoch: 34860 | training loss: 5.9556e-04 | validation loss: 1.0708e-04\n",
      "Epoch: 34870 | training loss: 5.9552e-04 | validation loss: 1.0708e-04\n",
      "Epoch: 34880 | training loss: 5.9548e-04 | validation loss: 1.0707e-04\n",
      "Epoch: 34890 | training loss: 5.9543e-04 | validation loss: 1.0707e-04\n",
      "Epoch: 34900 | training loss: 5.9539e-04 | validation loss: 1.0706e-04\n",
      "Epoch: 34910 | training loss: 5.9535e-04 | validation loss: 1.0702e-04\n",
      "Epoch: 34920 | training loss: 5.9539e-04 | validation loss: 1.0672e-04\n",
      "Epoch: 34930 | training loss: 5.9715e-04 | validation loss: 1.0646e-04\n",
      "Epoch: 34940 | training loss: 5.9524e-04 | validation loss: 1.0694e-04\n",
      "Epoch: 34950 | training loss: 5.9535e-04 | validation loss: 1.0774e-04\n",
      "Epoch: 34960 | training loss: 5.9519e-04 | validation loss: 1.0738e-04\n",
      "Epoch: 34970 | training loss: 5.9520e-04 | validation loss: 1.0706e-04\n",
      "Epoch: 34980 | training loss: 5.9654e-04 | validation loss: 1.0815e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34990 | training loss: 5.9763e-04 | validation loss: 1.0919e-04\n",
      "Epoch: 35000 | training loss: 5.9585e-04 | validation loss: 1.0756e-04\n",
      "Epoch: 35010 | training loss: 5.9519e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 35020 | training loss: 5.9499e-04 | validation loss: 1.0706e-04\n",
      "Epoch: 35030 | training loss: 5.9490e-04 | validation loss: 1.0711e-04\n",
      "Epoch: 35040 | training loss: 5.9482e-04 | validation loss: 1.0701e-04\n",
      "Epoch: 35050 | training loss: 5.9475e-04 | validation loss: 1.0703e-04\n",
      "Epoch: 35060 | training loss: 5.9471e-04 | validation loss: 1.0704e-04\n",
      "Epoch: 35070 | training loss: 5.9467e-04 | validation loss: 1.0703e-04\n",
      "Epoch: 35080 | training loss: 5.9463e-04 | validation loss: 1.0703e-04\n",
      "Epoch: 35090 | training loss: 5.9466e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 35100 | training loss: 5.9738e-04 | validation loss: 1.0933e-04\n",
      "Epoch: 35110 | training loss: 5.9456e-04 | validation loss: 1.0713e-04\n",
      "Epoch: 35120 | training loss: 5.9519e-04 | validation loss: 1.0768e-04\n",
      "Epoch: 35130 | training loss: 5.9501e-04 | validation loss: 1.0726e-04\n",
      "Epoch: 35140 | training loss: 5.9443e-04 | validation loss: 1.0708e-04\n",
      "Epoch: 35150 | training loss: 5.9433e-04 | validation loss: 1.0701e-04\n",
      "Epoch: 35160 | training loss: 5.9430e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 35170 | training loss: 5.9425e-04 | validation loss: 1.0701e-04\n",
      "Epoch: 35180 | training loss: 5.9420e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 35190 | training loss: 5.9416e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 35200 | training loss: 5.9412e-04 | validation loss: 1.0699e-04\n",
      "Epoch: 35210 | training loss: 5.9408e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 35220 | training loss: 5.9403e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 35230 | training loss: 5.9399e-04 | validation loss: 1.0697e-04\n",
      "Epoch: 35240 | training loss: 5.9395e-04 | validation loss: 1.0696e-04\n",
      "Epoch: 35250 | training loss: 5.9399e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 35260 | training loss: 5.9871e-04 | validation loss: 1.1013e-04\n",
      "Epoch: 35270 | training loss: 5.9567e-04 | validation loss: 1.0840e-04\n",
      "Epoch: 35280 | training loss: 5.9530e-04 | validation loss: 1.0786e-04\n",
      "Epoch: 35290 | training loss: 5.9391e-04 | validation loss: 1.0714e-04\n",
      "Epoch: 35300 | training loss: 5.9389e-04 | validation loss: 1.0708e-04\n",
      "Epoch: 35310 | training loss: 5.9366e-04 | validation loss: 1.0696e-04\n",
      "Epoch: 35320 | training loss: 5.9365e-04 | validation loss: 1.0697e-04\n",
      "Epoch: 35330 | training loss: 5.9358e-04 | validation loss: 1.0696e-04\n",
      "Epoch: 35340 | training loss: 5.9353e-04 | validation loss: 1.0694e-04\n",
      "Epoch: 35350 | training loss: 5.9349e-04 | validation loss: 1.0695e-04\n",
      "Epoch: 35360 | training loss: 5.9345e-04 | validation loss: 1.0694e-04\n",
      "Epoch: 35370 | training loss: 5.9340e-04 | validation loss: 1.0694e-04\n",
      "Epoch: 35380 | training loss: 5.9336e-04 | validation loss: 1.0693e-04\n",
      "Epoch: 35390 | training loss: 5.9332e-04 | validation loss: 1.0692e-04\n",
      "Epoch: 35400 | training loss: 5.9328e-04 | validation loss: 1.0687e-04\n",
      "Epoch: 35410 | training loss: 5.9339e-04 | validation loss: 1.0650e-04\n",
      "Epoch: 35420 | training loss: 5.9419e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 35430 | training loss: 5.9336e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 35440 | training loss: 5.9355e-04 | validation loss: 1.0758e-04\n",
      "Epoch: 35450 | training loss: 5.9489e-04 | validation loss: 1.0833e-04\n",
      "Epoch: 35460 | training loss: 5.9368e-04 | validation loss: 1.0726e-04\n",
      "Epoch: 35470 | training loss: 5.9355e-04 | validation loss: 1.0728e-04\n",
      "Epoch: 35480 | training loss: 5.9295e-04 | validation loss: 1.0682e-04\n",
      "Epoch: 35490 | training loss: 5.9303e-04 | validation loss: 1.0696e-04\n",
      "Epoch: 35500 | training loss: 5.9289e-04 | validation loss: 1.0693e-04\n",
      "Epoch: 35510 | training loss: 5.9284e-04 | validation loss: 1.0689e-04\n",
      "Epoch: 35520 | training loss: 5.9298e-04 | validation loss: 1.0697e-04\n",
      "Epoch: 35530 | training loss: 5.9669e-04 | validation loss: 1.0947e-04\n",
      "Epoch: 35540 | training loss: 5.9284e-04 | validation loss: 1.0704e-04\n",
      "Epoch: 35550 | training loss: 5.9298e-04 | validation loss: 1.0702e-04\n",
      "Epoch: 35560 | training loss: 5.9288e-04 | validation loss: 1.0717e-04\n",
      "Epoch: 35570 | training loss: 5.9270e-04 | validation loss: 1.0692e-04\n",
      "Epoch: 35580 | training loss: 5.9258e-04 | validation loss: 1.0695e-04\n",
      "Epoch: 35590 | training loss: 5.9250e-04 | validation loss: 1.0687e-04\n",
      "Epoch: 35600 | training loss: 5.9245e-04 | validation loss: 1.0687e-04\n",
      "Epoch: 35610 | training loss: 5.9241e-04 | validation loss: 1.0689e-04\n",
      "Epoch: 35620 | training loss: 5.9236e-04 | validation loss: 1.0687e-04\n",
      "Epoch: 35630 | training loss: 5.9232e-04 | validation loss: 1.0686e-04\n",
      "Epoch: 35640 | training loss: 5.9229e-04 | validation loss: 1.0686e-04\n",
      "Epoch: 35650 | training loss: 5.9238e-04 | validation loss: 1.0691e-04\n",
      "Epoch: 35660 | training loss: 5.9726e-04 | validation loss: 1.1017e-04\n",
      "Epoch: 35670 | training loss: 5.9348e-04 | validation loss: 1.0796e-04\n",
      "Epoch: 35680 | training loss: 5.9360e-04 | validation loss: 1.0771e-04\n",
      "Epoch: 35690 | training loss: 5.9218e-04 | validation loss: 1.0703e-04\n",
      "Epoch: 35700 | training loss: 5.9208e-04 | validation loss: 1.0689e-04\n",
      "Epoch: 35710 | training loss: 5.9206e-04 | validation loss: 1.0685e-04\n",
      "Epoch: 35720 | training loss: 5.9198e-04 | validation loss: 1.0690e-04\n",
      "Epoch: 35730 | training loss: 5.9192e-04 | validation loss: 1.0682e-04\n",
      "Epoch: 35740 | training loss: 5.9187e-04 | validation loss: 1.0686e-04\n",
      "Epoch: 35750 | training loss: 5.9183e-04 | validation loss: 1.0683e-04\n",
      "Epoch: 35760 | training loss: 5.9179e-04 | validation loss: 1.0684e-04\n",
      "Epoch: 35770 | training loss: 5.9175e-04 | validation loss: 1.0684e-04\n",
      "Epoch: 35780 | training loss: 5.9170e-04 | validation loss: 1.0683e-04\n",
      "Epoch: 35790 | training loss: 5.9166e-04 | validation loss: 1.0682e-04\n",
      "Epoch: 35800 | training loss: 5.9162e-04 | validation loss: 1.0681e-04\n",
      "Epoch: 35810 | training loss: 5.9161e-04 | validation loss: 1.0679e-04\n",
      "Epoch: 35820 | training loss: 5.9300e-04 | validation loss: 1.0758e-04\n",
      "Epoch: 35830 | training loss: 5.9468e-04 | validation loss: 1.0903e-04\n",
      "Epoch: 35840 | training loss: 5.9232e-04 | validation loss: 1.0687e-04\n",
      "Epoch: 35850 | training loss: 5.9201e-04 | validation loss: 1.0763e-04\n",
      "Epoch: 35860 | training loss: 5.9151e-04 | validation loss: 1.0712e-04\n",
      "Epoch: 35870 | training loss: 5.9142e-04 | validation loss: 1.0670e-04\n",
      "Epoch: 35880 | training loss: 5.9130e-04 | validation loss: 1.0678e-04\n",
      "Epoch: 35890 | training loss: 5.9127e-04 | validation loss: 1.0689e-04\n",
      "Epoch: 35900 | training loss: 5.9122e-04 | validation loss: 1.0676e-04\n",
      "Epoch: 35910 | training loss: 5.9117e-04 | validation loss: 1.0682e-04\n",
      "Epoch: 35920 | training loss: 5.9113e-04 | validation loss: 1.0679e-04\n",
      "Epoch: 35930 | training loss: 5.9109e-04 | validation loss: 1.0680e-04\n",
      "Epoch: 35940 | training loss: 5.9105e-04 | validation loss: 1.0679e-04\n",
      "Epoch: 35950 | training loss: 5.9101e-04 | validation loss: 1.0679e-04\n",
      "Epoch: 35960 | training loss: 5.9097e-04 | validation loss: 1.0674e-04\n",
      "Epoch: 35970 | training loss: 5.9106e-04 | validation loss: 1.0642e-04\n",
      "Epoch: 35980 | training loss: 5.9363e-04 | validation loss: 1.0711e-04\n",
      "Epoch: 35990 | training loss: 5.9141e-04 | validation loss: 1.0620e-04\n",
      "Epoch: 36000 | training loss: 5.9114e-04 | validation loss: 1.0672e-04\n",
      "Epoch: 36010 | training loss: 5.9084e-04 | validation loss: 1.0688e-04\n",
      "Epoch: 36020 | training loss: 5.9077e-04 | validation loss: 1.0697e-04\n",
      "Epoch: 36030 | training loss: 5.9070e-04 | validation loss: 1.0691e-04\n",
      "Epoch: 36040 | training loss: 5.9067e-04 | validation loss: 1.0683e-04\n",
      "Epoch: 36050 | training loss: 5.9093e-04 | validation loss: 1.0694e-04\n",
      "Epoch: 36060 | training loss: 5.9538e-04 | validation loss: 1.1001e-04\n",
      "Epoch: 36070 | training loss: 5.9125e-04 | validation loss: 1.0735e-04\n",
      "Epoch: 36080 | training loss: 5.9093e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 36090 | training loss: 5.9067e-04 | validation loss: 1.0696e-04\n",
      "Epoch: 36100 | training loss: 5.9048e-04 | validation loss: 1.0677e-04\n",
      "Epoch: 36110 | training loss: 5.9038e-04 | validation loss: 1.0677e-04\n",
      "Epoch: 36120 | training loss: 5.9032e-04 | validation loss: 1.0675e-04\n",
      "Epoch: 36130 | training loss: 5.9029e-04 | validation loss: 1.0674e-04\n",
      "Epoch: 36140 | training loss: 5.9024e-04 | validation loss: 1.0674e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36150 | training loss: 5.9020e-04 | validation loss: 1.0674e-04\n",
      "Epoch: 36160 | training loss: 5.9017e-04 | validation loss: 1.0676e-04\n",
      "Epoch: 36170 | training loss: 5.9034e-04 | validation loss: 1.0695e-04\n",
      "Epoch: 36180 | training loss: 5.9555e-04 | validation loss: 1.1097e-04\n",
      "Epoch: 36190 | training loss: 5.9137e-04 | validation loss: 1.0754e-04\n",
      "Epoch: 36200 | training loss: 5.9114e-04 | validation loss: 1.0775e-04\n",
      "Epoch: 36210 | training loss: 5.9029e-04 | validation loss: 1.0686e-04\n",
      "Epoch: 36220 | training loss: 5.8995e-04 | validation loss: 1.0676e-04\n",
      "Epoch: 36230 | training loss: 5.8988e-04 | validation loss: 1.0671e-04\n",
      "Epoch: 36240 | training loss: 5.8984e-04 | validation loss: 1.0672e-04\n",
      "Epoch: 36250 | training loss: 5.8980e-04 | validation loss: 1.0671e-04\n",
      "Epoch: 36260 | training loss: 5.8976e-04 | validation loss: 1.0672e-04\n",
      "Epoch: 36270 | training loss: 5.8972e-04 | validation loss: 1.0670e-04\n",
      "Epoch: 36280 | training loss: 5.8968e-04 | validation loss: 1.0670e-04\n",
      "Epoch: 36290 | training loss: 5.8964e-04 | validation loss: 1.0670e-04\n",
      "Epoch: 36300 | training loss: 5.8960e-04 | validation loss: 1.0670e-04\n",
      "Epoch: 36310 | training loss: 5.8956e-04 | validation loss: 1.0671e-04\n",
      "Epoch: 36320 | training loss: 5.8974e-04 | validation loss: 1.0693e-04\n",
      "Epoch: 36330 | training loss: 5.9988e-04 | validation loss: 1.1470e-04\n",
      "Epoch: 36340 | training loss: 5.9377e-04 | validation loss: 1.0949e-04\n",
      "Epoch: 36350 | training loss: 5.8947e-04 | validation loss: 1.0682e-04\n",
      "Epoch: 36360 | training loss: 5.8985e-04 | validation loss: 1.0711e-04\n",
      "Epoch: 36370 | training loss: 5.8934e-04 | validation loss: 1.0664e-04\n",
      "Epoch: 36380 | training loss: 5.8935e-04 | validation loss: 1.0675e-04\n",
      "Epoch: 36390 | training loss: 5.8924e-04 | validation loss: 1.0668e-04\n",
      "Epoch: 36400 | training loss: 5.8921e-04 | validation loss: 1.0668e-04\n",
      "Epoch: 36410 | training loss: 5.8917e-04 | validation loss: 1.0668e-04\n",
      "Epoch: 36420 | training loss: 5.8912e-04 | validation loss: 1.0667e-04\n",
      "Epoch: 36430 | training loss: 5.8908e-04 | validation loss: 1.0667e-04\n",
      "Epoch: 36440 | training loss: 5.8904e-04 | validation loss: 1.0667e-04\n",
      "Epoch: 36450 | training loss: 5.8900e-04 | validation loss: 1.0667e-04\n",
      "Epoch: 36460 | training loss: 5.8896e-04 | validation loss: 1.0666e-04\n",
      "Epoch: 36470 | training loss: 5.8892e-04 | validation loss: 1.0666e-04\n",
      "Epoch: 36480 | training loss: 5.8888e-04 | validation loss: 1.0666e-04\n",
      "Epoch: 36490 | training loss: 5.8884e-04 | validation loss: 1.0671e-04\n",
      "Epoch: 36500 | training loss: 5.8900e-04 | validation loss: 1.0738e-04\n",
      "Epoch: 36510 | training loss: 5.8927e-04 | validation loss: 1.0793e-04\n",
      "Epoch: 36520 | training loss: 5.9000e-04 | validation loss: 1.0863e-04\n",
      "Epoch: 36530 | training loss: 5.9318e-04 | validation loss: 1.1051e-04\n",
      "Epoch: 36540 | training loss: 5.9002e-04 | validation loss: 1.0759e-04\n",
      "Epoch: 36550 | training loss: 5.8908e-04 | validation loss: 1.0710e-04\n",
      "Epoch: 36560 | training loss: 5.8871e-04 | validation loss: 1.0668e-04\n",
      "Epoch: 36570 | training loss: 5.8854e-04 | validation loss: 1.0662e-04\n",
      "Epoch: 36580 | training loss: 5.8849e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 36590 | training loss: 5.8846e-04 | validation loss: 1.0658e-04\n",
      "Epoch: 36600 | training loss: 5.8841e-04 | validation loss: 1.0660e-04\n",
      "Epoch: 36610 | training loss: 5.8837e-04 | validation loss: 1.0662e-04\n",
      "Epoch: 36620 | training loss: 5.8833e-04 | validation loss: 1.0662e-04\n",
      "Epoch: 36630 | training loss: 5.8831e-04 | validation loss: 1.0661e-04\n",
      "Epoch: 36640 | training loss: 5.8946e-04 | validation loss: 1.0736e-04\n",
      "Epoch: 36650 | training loss: 5.9299e-04 | validation loss: 1.0971e-04\n",
      "Epoch: 36660 | training loss: 5.8906e-04 | validation loss: 1.0710e-04\n",
      "Epoch: 36670 | training loss: 5.8869e-04 | validation loss: 1.0713e-04\n",
      "Epoch: 36680 | training loss: 5.8834e-04 | validation loss: 1.0686e-04\n",
      "Epoch: 36690 | training loss: 5.8810e-04 | validation loss: 1.0661e-04\n",
      "Epoch: 36700 | training loss: 5.8805e-04 | validation loss: 1.0660e-04\n",
      "Epoch: 36710 | training loss: 5.8800e-04 | validation loss: 1.0663e-04\n",
      "Epoch: 36720 | training loss: 5.8794e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 36730 | training loss: 5.8791e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 36740 | training loss: 5.8787e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 36750 | training loss: 5.8783e-04 | validation loss: 1.0658e-04\n",
      "Epoch: 36760 | training loss: 5.8779e-04 | validation loss: 1.0658e-04\n",
      "Epoch: 36770 | training loss: 5.8775e-04 | validation loss: 1.0658e-04\n",
      "Epoch: 36780 | training loss: 5.8771e-04 | validation loss: 1.0658e-04\n",
      "Epoch: 36790 | training loss: 5.8767e-04 | validation loss: 1.0658e-04\n",
      "Epoch: 36800 | training loss: 5.8763e-04 | validation loss: 1.0657e-04\n",
      "Epoch: 36810 | training loss: 5.8759e-04 | validation loss: 1.0657e-04\n",
      "Epoch: 36820 | training loss: 5.8755e-04 | validation loss: 1.0657e-04\n",
      "Epoch: 36830 | training loss: 5.8751e-04 | validation loss: 1.0657e-04\n",
      "Epoch: 36840 | training loss: 5.8753e-04 | validation loss: 1.0664e-04\n",
      "Epoch: 36850 | training loss: 5.9492e-04 | validation loss: 1.1234e-04\n",
      "Epoch: 36860 | training loss: 5.9458e-04 | validation loss: 1.1139e-04\n",
      "Epoch: 36870 | training loss: 5.8788e-04 | validation loss: 1.0698e-04\n",
      "Epoch: 36880 | training loss: 5.8735e-04 | validation loss: 1.0670e-04\n",
      "Epoch: 36890 | training loss: 5.8745e-04 | validation loss: 1.0671e-04\n",
      "Epoch: 36900 | training loss: 5.8736e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 36910 | training loss: 5.8722e-04 | validation loss: 1.0653e-04\n",
      "Epoch: 36920 | training loss: 5.8717e-04 | validation loss: 1.0656e-04\n",
      "Epoch: 36930 | training loss: 5.8714e-04 | validation loss: 1.0655e-04\n",
      "Epoch: 36940 | training loss: 5.8710e-04 | validation loss: 1.0653e-04\n",
      "Epoch: 36950 | training loss: 5.8706e-04 | validation loss: 1.0654e-04\n",
      "Epoch: 36960 | training loss: 5.8702e-04 | validation loss: 1.0653e-04\n",
      "Epoch: 36970 | training loss: 5.8698e-04 | validation loss: 1.0653e-04\n",
      "Epoch: 36980 | training loss: 5.8694e-04 | validation loss: 1.0653e-04\n",
      "Epoch: 36990 | training loss: 5.8690e-04 | validation loss: 1.0653e-04\n",
      "Epoch: 37000 | training loss: 5.8686e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37010 | training loss: 5.8683e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37020 | training loss: 5.8679e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37030 | training loss: 5.8675e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37040 | training loss: 5.8671e-04 | validation loss: 1.0651e-04\n",
      "Epoch: 37050 | training loss: 5.8667e-04 | validation loss: 1.0651e-04\n",
      "Epoch: 37060 | training loss: 5.8663e-04 | validation loss: 1.0651e-04\n",
      "Epoch: 37070 | training loss: 5.8659e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37080 | training loss: 5.8661e-04 | validation loss: 1.0686e-04\n",
      "Epoch: 37090 | training loss: 5.8954e-04 | validation loss: 1.1082e-04\n",
      "Epoch: 37100 | training loss: 5.8932e-04 | validation loss: 1.1014e-04\n",
      "Epoch: 37110 | training loss: 5.8849e-04 | validation loss: 1.0908e-04\n",
      "Epoch: 37120 | training loss: 5.8682e-04 | validation loss: 1.0685e-04\n",
      "Epoch: 37130 | training loss: 5.8647e-04 | validation loss: 1.0634e-04\n",
      "Epoch: 37140 | training loss: 5.8637e-04 | validation loss: 1.0629e-04\n",
      "Epoch: 37150 | training loss: 5.8631e-04 | validation loss: 1.0646e-04\n",
      "Epoch: 37160 | training loss: 5.8627e-04 | validation loss: 1.0650e-04\n",
      "Epoch: 37170 | training loss: 5.8621e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37180 | training loss: 5.8617e-04 | validation loss: 1.0650e-04\n",
      "Epoch: 37190 | training loss: 5.8613e-04 | validation loss: 1.0648e-04\n",
      "Epoch: 37200 | training loss: 5.8610e-04 | validation loss: 1.0647e-04\n",
      "Epoch: 37210 | training loss: 5.8610e-04 | validation loss: 1.0648e-04\n",
      "Epoch: 37220 | training loss: 5.8730e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 37230 | training loss: 5.9041e-04 | validation loss: 1.0939e-04\n",
      "Epoch: 37240 | training loss: 5.8606e-04 | validation loss: 1.0657e-04\n",
      "Epoch: 37250 | training loss: 5.8627e-04 | validation loss: 1.0678e-04\n",
      "Epoch: 37260 | training loss: 5.8615e-04 | validation loss: 1.0658e-04\n",
      "Epoch: 37270 | training loss: 5.8588e-04 | validation loss: 1.0651e-04\n",
      "Epoch: 37280 | training loss: 5.8580e-04 | validation loss: 1.0644e-04\n",
      "Epoch: 37290 | training loss: 5.8576e-04 | validation loss: 1.0645e-04\n",
      "Epoch: 37300 | training loss: 5.8572e-04 | validation loss: 1.0644e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37310 | training loss: 5.8568e-04 | validation loss: 1.0645e-04\n",
      "Epoch: 37320 | training loss: 5.8564e-04 | validation loss: 1.0644e-04\n",
      "Epoch: 37330 | training loss: 5.8561e-04 | validation loss: 1.0644e-04\n",
      "Epoch: 37340 | training loss: 5.8557e-04 | validation loss: 1.0644e-04\n",
      "Epoch: 37350 | training loss: 5.8553e-04 | validation loss: 1.0643e-04\n",
      "Epoch: 37360 | training loss: 5.8549e-04 | validation loss: 1.0644e-04\n",
      "Epoch: 37370 | training loss: 5.8550e-04 | validation loss: 1.0649e-04\n",
      "Epoch: 37380 | training loss: 5.8786e-04 | validation loss: 1.0839e-04\n",
      "Epoch: 37390 | training loss: 5.8558e-04 | validation loss: 1.0665e-04\n",
      "Epoch: 37400 | training loss: 5.8723e-04 | validation loss: 1.0799e-04\n",
      "Epoch: 37410 | training loss: 5.8547e-04 | validation loss: 1.0648e-04\n",
      "Epoch: 37420 | training loss: 5.8549e-04 | validation loss: 1.0651e-04\n",
      "Epoch: 37430 | training loss: 5.8528e-04 | validation loss: 1.0648e-04\n",
      "Epoch: 37440 | training loss: 5.8520e-04 | validation loss: 1.0642e-04\n",
      "Epoch: 37450 | training loss: 5.8517e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 37460 | training loss: 5.8512e-04 | validation loss: 1.0642e-04\n",
      "Epoch: 37470 | training loss: 5.8508e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 37480 | training loss: 5.8504e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 37490 | training loss: 5.8501e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 37500 | training loss: 5.8497e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 37510 | training loss: 5.8493e-04 | validation loss: 1.0639e-04\n",
      "Epoch: 37520 | training loss: 5.8489e-04 | validation loss: 1.0639e-04\n",
      "Epoch: 37530 | training loss: 5.8485e-04 | validation loss: 1.0639e-04\n",
      "Epoch: 37540 | training loss: 5.8482e-04 | validation loss: 1.0638e-04\n",
      "Epoch: 37550 | training loss: 5.8478e-04 | validation loss: 1.0638e-04\n",
      "Epoch: 37560 | training loss: 5.8474e-04 | validation loss: 1.0638e-04\n",
      "Epoch: 37570 | training loss: 5.8472e-04 | validation loss: 1.0637e-04\n",
      "Epoch: 37580 | training loss: 5.8819e-04 | validation loss: 1.0869e-04\n",
      "Epoch: 37590 | training loss: 5.8795e-04 | validation loss: 1.0894e-04\n",
      "Epoch: 37600 | training loss: 5.8460e-04 | validation loss: 1.0624e-04\n",
      "Epoch: 37610 | training loss: 5.8467e-04 | validation loss: 1.0630e-04\n",
      "Epoch: 37620 | training loss: 5.8464e-04 | validation loss: 1.0636e-04\n",
      "Epoch: 37630 | training loss: 5.8458e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 37640 | training loss: 5.8450e-04 | validation loss: 1.0641e-04\n",
      "Epoch: 37650 | training loss: 5.8443e-04 | validation loss: 1.0639e-04\n",
      "Epoch: 37660 | training loss: 5.8438e-04 | validation loss: 1.0636e-04\n",
      "Epoch: 37670 | training loss: 5.8434e-04 | validation loss: 1.0635e-04\n",
      "Epoch: 37680 | training loss: 5.8430e-04 | validation loss: 1.0635e-04\n",
      "Epoch: 37690 | training loss: 5.8427e-04 | validation loss: 1.0635e-04\n",
      "Epoch: 37700 | training loss: 5.8423e-04 | validation loss: 1.0635e-04\n",
      "Epoch: 37710 | training loss: 5.8419e-04 | validation loss: 1.0635e-04\n",
      "Epoch: 37720 | training loss: 5.8416e-04 | validation loss: 1.0634e-04\n",
      "Epoch: 37730 | training loss: 5.8412e-04 | validation loss: 1.0634e-04\n",
      "Epoch: 37740 | training loss: 5.8408e-04 | validation loss: 1.0634e-04\n",
      "Epoch: 37750 | training loss: 5.8404e-04 | validation loss: 1.0634e-04\n",
      "Epoch: 37760 | training loss: 5.8401e-04 | validation loss: 1.0633e-04\n",
      "Epoch: 37770 | training loss: 5.8397e-04 | validation loss: 1.0633e-04\n",
      "Epoch: 37780 | training loss: 5.8393e-04 | validation loss: 1.0633e-04\n",
      "Epoch: 37790 | training loss: 5.8389e-04 | validation loss: 1.0633e-04\n",
      "Epoch: 37800 | training loss: 5.8385e-04 | validation loss: 1.0632e-04\n",
      "Epoch: 37810 | training loss: 5.8382e-04 | validation loss: 1.0632e-04\n",
      "Epoch: 37820 | training loss: 5.8378e-04 | validation loss: 1.0633e-04\n",
      "Epoch: 37830 | training loss: 5.8376e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37840 | training loss: 5.8659e-04 | validation loss: 1.1044e-04\n",
      "Epoch: 37850 | training loss: 5.8407e-04 | validation loss: 1.0605e-04\n",
      "Epoch: 37860 | training loss: 5.8945e-04 | validation loss: 1.0995e-04\n",
      "Epoch: 37870 | training loss: 5.8499e-04 | validation loss: 1.0701e-04\n",
      "Epoch: 37880 | training loss: 5.8452e-04 | validation loss: 1.0722e-04\n",
      "Epoch: 37890 | training loss: 5.8387e-04 | validation loss: 1.0667e-04\n",
      "Epoch: 37900 | training loss: 5.8357e-04 | validation loss: 1.0652e-04\n",
      "Epoch: 37910 | training loss: 5.8347e-04 | validation loss: 1.0637e-04\n",
      "Epoch: 37920 | training loss: 5.8342e-04 | validation loss: 1.0634e-04\n",
      "Epoch: 37930 | training loss: 5.8338e-04 | validation loss: 1.0630e-04\n",
      "Epoch: 37940 | training loss: 5.8334e-04 | validation loss: 1.0630e-04\n",
      "Epoch: 37950 | training loss: 5.8330e-04 | validation loss: 1.0629e-04\n",
      "Epoch: 37960 | training loss: 5.8326e-04 | validation loss: 1.0628e-04\n",
      "Epoch: 37970 | training loss: 5.8322e-04 | validation loss: 1.0628e-04\n",
      "Epoch: 37980 | training loss: 5.8320e-04 | validation loss: 1.0627e-04\n",
      "Epoch: 37990 | training loss: 5.8348e-04 | validation loss: 1.0646e-04\n",
      "Epoch: 38000 | training loss: 5.9235e-04 | validation loss: 1.1264e-04\n",
      "Epoch: 38010 | training loss: 5.8660e-04 | validation loss: 1.0907e-04\n",
      "Epoch: 38020 | training loss: 5.8317e-04 | validation loss: 1.0633e-04\n",
      "Epoch: 38030 | training loss: 5.8326e-04 | validation loss: 1.0639e-04\n",
      "Epoch: 38040 | training loss: 5.8311e-04 | validation loss: 1.0642e-04\n",
      "Epoch: 38050 | training loss: 5.8294e-04 | validation loss: 1.0626e-04\n",
      "Epoch: 38060 | training loss: 5.8290e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 38070 | training loss: 5.8286e-04 | validation loss: 1.0626e-04\n",
      "Epoch: 38080 | training loss: 5.8282e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 38090 | training loss: 5.8279e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 38100 | training loss: 5.8275e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 38110 | training loss: 5.8271e-04 | validation loss: 1.0624e-04\n",
      "Epoch: 38120 | training loss: 5.8268e-04 | validation loss: 1.0624e-04\n",
      "Epoch: 38130 | training loss: 5.8264e-04 | validation loss: 1.0624e-04\n",
      "Epoch: 38140 | training loss: 5.8260e-04 | validation loss: 1.0624e-04\n",
      "Epoch: 38150 | training loss: 5.8257e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 38160 | training loss: 5.8271e-04 | validation loss: 1.0642e-04\n",
      "Epoch: 38170 | training loss: 5.9255e-04 | validation loss: 1.1389e-04\n",
      "Epoch: 38180 | training loss: 5.8739e-04 | validation loss: 1.0949e-04\n",
      "Epoch: 38190 | training loss: 5.8247e-04 | validation loss: 1.0626e-04\n",
      "Epoch: 38200 | training loss: 5.8291e-04 | validation loss: 1.0673e-04\n",
      "Epoch: 38210 | training loss: 5.8240e-04 | validation loss: 1.0630e-04\n",
      "Epoch: 38220 | training loss: 5.8238e-04 | validation loss: 1.0623e-04\n",
      "Epoch: 38230 | training loss: 5.8228e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 38240 | training loss: 5.8225e-04 | validation loss: 1.0624e-04\n",
      "Epoch: 38250 | training loss: 5.8221e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 38260 | training loss: 5.8217e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 38270 | training loss: 5.8213e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 38280 | training loss: 5.8210e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 38290 | training loss: 5.8206e-04 | validation loss: 1.0620e-04\n",
      "Epoch: 38300 | training loss: 5.8202e-04 | validation loss: 1.0620e-04\n",
      "Epoch: 38310 | training loss: 5.8198e-04 | validation loss: 1.0620e-04\n",
      "Epoch: 38320 | training loss: 5.8195e-04 | validation loss: 1.0620e-04\n",
      "Epoch: 38330 | training loss: 5.8191e-04 | validation loss: 1.0619e-04\n",
      "Epoch: 38340 | training loss: 5.8187e-04 | validation loss: 1.0619e-04\n",
      "Epoch: 38350 | training loss: 5.8184e-04 | validation loss: 1.0619e-04\n",
      "Epoch: 38360 | training loss: 5.8180e-04 | validation loss: 1.0619e-04\n",
      "Epoch: 38370 | training loss: 5.8176e-04 | validation loss: 1.0619e-04\n",
      "Epoch: 38380 | training loss: 5.8250e-04 | validation loss: 1.0683e-04\n",
      "Epoch: 38390 | training loss: 5.8966e-04 | validation loss: 1.1242e-04\n",
      "Epoch: 38400 | training loss: 5.8677e-04 | validation loss: 1.0995e-04\n",
      "Epoch: 38410 | training loss: 5.8329e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 38420 | training loss: 5.8208e-04 | validation loss: 1.0642e-04\n",
      "Epoch: 38430 | training loss: 5.8170e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 38440 | training loss: 5.8157e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 38450 | training loss: 5.8150e-04 | validation loss: 1.0617e-04\n",
      "Epoch: 38460 | training loss: 5.8146e-04 | validation loss: 1.0616e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38470 | training loss: 5.8141e-04 | validation loss: 1.0617e-04\n",
      "Epoch: 38480 | training loss: 5.8138e-04 | validation loss: 1.0616e-04\n",
      "Epoch: 38490 | training loss: 5.8134e-04 | validation loss: 1.0616e-04\n",
      "Epoch: 38500 | training loss: 5.8131e-04 | validation loss: 1.0616e-04\n",
      "Epoch: 38510 | training loss: 5.8127e-04 | validation loss: 1.0615e-04\n",
      "Epoch: 38520 | training loss: 5.8123e-04 | validation loss: 1.0615e-04\n",
      "Epoch: 38530 | training loss: 5.8120e-04 | validation loss: 1.0615e-04\n",
      "Epoch: 38540 | training loss: 5.8116e-04 | validation loss: 1.0615e-04\n",
      "Epoch: 38550 | training loss: 5.8113e-04 | validation loss: 1.0614e-04\n",
      "Epoch: 38560 | training loss: 5.8109e-04 | validation loss: 1.0614e-04\n",
      "Epoch: 38570 | training loss: 5.8105e-04 | validation loss: 1.0614e-04\n",
      "Epoch: 38580 | training loss: 5.8102e-04 | validation loss: 1.0614e-04\n",
      "Epoch: 38590 | training loss: 5.8098e-04 | validation loss: 1.0613e-04\n",
      "Epoch: 38600 | training loss: 5.8095e-04 | validation loss: 1.0611e-04\n",
      "Epoch: 38610 | training loss: 5.8098e-04 | validation loss: 1.0582e-04\n",
      "Epoch: 38620 | training loss: 5.8285e-04 | validation loss: 1.0564e-04\n",
      "Epoch: 38630 | training loss: 5.8177e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 38640 | training loss: 5.8110e-04 | validation loss: 1.0560e-04\n",
      "Epoch: 38650 | training loss: 5.8086e-04 | validation loss: 1.0578e-04\n",
      "Epoch: 38660 | training loss: 5.8076e-04 | validation loss: 1.0591e-04\n",
      "Epoch: 38670 | training loss: 5.8070e-04 | validation loss: 1.0599e-04\n",
      "Epoch: 38680 | training loss: 5.8066e-04 | validation loss: 1.0603e-04\n",
      "Epoch: 38690 | training loss: 5.8067e-04 | validation loss: 1.0610e-04\n",
      "Epoch: 38700 | training loss: 5.8255e-04 | validation loss: 1.0762e-04\n",
      "Epoch: 38710 | training loss: 5.8185e-04 | validation loss: 1.0715e-04\n",
      "Epoch: 38720 | training loss: 5.8147e-04 | validation loss: 1.0689e-04\n",
      "Epoch: 38730 | training loss: 5.8110e-04 | validation loss: 1.0644e-04\n",
      "Epoch: 38740 | training loss: 5.8047e-04 | validation loss: 1.0609e-04\n",
      "Epoch: 38750 | training loss: 5.8052e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 38760 | training loss: 5.8039e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 38770 | training loss: 5.8034e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 38780 | training loss: 5.8031e-04 | validation loss: 1.0609e-04\n",
      "Epoch: 38790 | training loss: 5.8027e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 38800 | training loss: 5.8024e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 38810 | training loss: 5.8020e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 38820 | training loss: 5.8017e-04 | validation loss: 1.0607e-04\n",
      "Epoch: 38830 | training loss: 5.8013e-04 | validation loss: 1.0607e-04\n",
      "Epoch: 38840 | training loss: 5.8009e-04 | validation loss: 1.0607e-04\n",
      "Epoch: 38850 | training loss: 5.8006e-04 | validation loss: 1.0607e-04\n",
      "Epoch: 38860 | training loss: 5.8002e-04 | validation loss: 1.0607e-04\n",
      "Epoch: 38870 | training loss: 5.7999e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 38880 | training loss: 5.8045e-04 | validation loss: 1.0650e-04\n",
      "Epoch: 38890 | training loss: 5.9365e-04 | validation loss: 1.1644e-04\n",
      "Epoch: 38900 | training loss: 5.7993e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 38910 | training loss: 5.8117e-04 | validation loss: 1.0684e-04\n",
      "Epoch: 38920 | training loss: 5.8009e-04 | validation loss: 1.0617e-04\n",
      "Epoch: 38930 | training loss: 5.7980e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 38940 | training loss: 5.7981e-04 | validation loss: 1.0613e-04\n",
      "Epoch: 38950 | training loss: 5.7971e-04 | validation loss: 1.0605e-04\n",
      "Epoch: 38960 | training loss: 5.7968e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 38970 | training loss: 5.7964e-04 | validation loss: 1.0605e-04\n",
      "Epoch: 38980 | training loss: 5.7960e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 38990 | training loss: 5.7957e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 39000 | training loss: 5.7953e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 39010 | training loss: 5.7950e-04 | validation loss: 1.0603e-04\n",
      "Epoch: 39020 | training loss: 5.7946e-04 | validation loss: 1.0603e-04\n",
      "Epoch: 39030 | training loss: 5.7943e-04 | validation loss: 1.0603e-04\n",
      "Epoch: 39040 | training loss: 5.7939e-04 | validation loss: 1.0603e-04\n",
      "Epoch: 39050 | training loss: 5.7936e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 39060 | training loss: 5.7932e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 39070 | training loss: 5.7928e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 39080 | training loss: 5.7925e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 39090 | training loss: 5.7921e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 39100 | training loss: 5.7927e-04 | validation loss: 1.0611e-04\n",
      "Epoch: 39110 | training loss: 5.9027e-04 | validation loss: 1.1441e-04\n",
      "Epoch: 39120 | training loss: 5.8592e-04 | validation loss: 1.1064e-04\n",
      "Epoch: 39130 | training loss: 5.8104e-04 | validation loss: 1.0743e-04\n",
      "Epoch: 39140 | training loss: 5.7930e-04 | validation loss: 1.0628e-04\n",
      "Epoch: 39150 | training loss: 5.7900e-04 | validation loss: 1.0600e-04\n",
      "Epoch: 39160 | training loss: 5.7901e-04 | validation loss: 1.0600e-04\n",
      "Epoch: 39170 | training loss: 5.7898e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 39180 | training loss: 5.7891e-04 | validation loss: 1.0600e-04\n",
      "Epoch: 39190 | training loss: 5.7887e-04 | validation loss: 1.0599e-04\n",
      "Epoch: 39200 | training loss: 5.7883e-04 | validation loss: 1.0600e-04\n",
      "Epoch: 39210 | training loss: 5.7880e-04 | validation loss: 1.0599e-04\n",
      "Epoch: 39220 | training loss: 5.7876e-04 | validation loss: 1.0599e-04\n",
      "Epoch: 39230 | training loss: 5.7873e-04 | validation loss: 1.0598e-04\n",
      "Epoch: 39240 | training loss: 5.7869e-04 | validation loss: 1.0598e-04\n",
      "Epoch: 39250 | training loss: 5.7866e-04 | validation loss: 1.0598e-04\n",
      "Epoch: 39260 | training loss: 5.7862e-04 | validation loss: 1.0598e-04\n",
      "Epoch: 39270 | training loss: 5.7859e-04 | validation loss: 1.0597e-04\n",
      "Epoch: 39280 | training loss: 5.7855e-04 | validation loss: 1.0597e-04\n",
      "Epoch: 39290 | training loss: 5.7852e-04 | validation loss: 1.0597e-04\n",
      "Epoch: 39300 | training loss: 5.7848e-04 | validation loss: 1.0597e-04\n",
      "Epoch: 39310 | training loss: 5.7845e-04 | validation loss: 1.0600e-04\n",
      "Epoch: 39320 | training loss: 5.7856e-04 | validation loss: 1.0657e-04\n",
      "Epoch: 39330 | training loss: 5.7879e-04 | validation loss: 1.0704e-04\n",
      "Epoch: 39340 | training loss: 5.7908e-04 | validation loss: 1.0747e-04\n",
      "Epoch: 39350 | training loss: 5.7880e-04 | validation loss: 1.0694e-04\n",
      "Epoch: 39360 | training loss: 5.7900e-04 | validation loss: 1.0688e-04\n",
      "Epoch: 39370 | training loss: 5.7959e-04 | validation loss: 1.0720e-04\n",
      "Epoch: 39380 | training loss: 5.7840e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 39390 | training loss: 5.7829e-04 | validation loss: 1.0605e-04\n",
      "Epoch: 39400 | training loss: 5.7848e-04 | validation loss: 1.0617e-04\n",
      "Epoch: 39410 | training loss: 5.7887e-04 | validation loss: 1.0645e-04\n",
      "Epoch: 39420 | training loss: 5.7931e-04 | validation loss: 1.0676e-04\n",
      "Epoch: 39430 | training loss: 5.7812e-04 | validation loss: 1.0598e-04\n",
      "Epoch: 39440 | training loss: 5.7812e-04 | validation loss: 1.0606e-04\n",
      "Epoch: 39450 | training loss: 5.7835e-04 | validation loss: 1.0627e-04\n",
      "Epoch: 39460 | training loss: 5.7908e-04 | validation loss: 1.0686e-04\n",
      "Epoch: 39470 | training loss: 5.7889e-04 | validation loss: 1.0674e-04\n",
      "Epoch: 39480 | training loss: 5.7789e-04 | validation loss: 1.0593e-04\n",
      "Epoch: 39490 | training loss: 5.7812e-04 | validation loss: 1.0609e-04\n",
      "Epoch: 39500 | training loss: 5.7802e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 39510 | training loss: 5.7812e-04 | validation loss: 1.0613e-04\n",
      "Epoch: 39520 | training loss: 5.7915e-04 | validation loss: 1.0684e-04\n",
      "Epoch: 39530 | training loss: 5.7874e-04 | validation loss: 1.0657e-04\n",
      "Epoch: 39540 | training loss: 5.7795e-04 | validation loss: 1.0618e-04\n",
      "Epoch: 39550 | training loss: 5.7773e-04 | validation loss: 1.0603e-04\n",
      "Epoch: 39560 | training loss: 5.7760e-04 | validation loss: 1.0591e-04\n",
      "Epoch: 39570 | training loss: 5.7769e-04 | validation loss: 1.0597e-04\n",
      "Epoch: 39580 | training loss: 5.7832e-04 | validation loss: 1.0641e-04\n",
      "Epoch: 39590 | training loss: 5.8049e-04 | validation loss: 1.0791e-04\n",
      "Epoch: 39600 | training loss: 5.7775e-04 | validation loss: 1.0618e-04\n",
      "Epoch: 39610 | training loss: 5.7743e-04 | validation loss: 1.0593e-04\n",
      "Epoch: 39620 | training loss: 5.7754e-04 | validation loss: 1.0597e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39630 | training loss: 5.7733e-04 | validation loss: 1.0590e-04\n",
      "Epoch: 39640 | training loss: 5.7735e-04 | validation loss: 1.0595e-04\n",
      "Epoch: 39650 | training loss: 5.7738e-04 | validation loss: 1.0601e-04\n",
      "Epoch: 39660 | training loss: 5.7804e-04 | validation loss: 1.0656e-04\n",
      "Epoch: 39670 | training loss: 5.8091e-04 | validation loss: 1.0877e-04\n",
      "Epoch: 39680 | training loss: 5.7787e-04 | validation loss: 1.0630e-04\n",
      "Epoch: 39690 | training loss: 5.7717e-04 | validation loss: 1.0593e-04\n",
      "Epoch: 39700 | training loss: 5.7712e-04 | validation loss: 1.0591e-04\n",
      "Epoch: 39710 | training loss: 5.7714e-04 | validation loss: 1.0590e-04\n",
      "Epoch: 39720 | training loss: 5.7702e-04 | validation loss: 1.0587e-04\n",
      "Epoch: 39730 | training loss: 5.7701e-04 | validation loss: 1.0590e-04\n",
      "Epoch: 39740 | training loss: 5.7702e-04 | validation loss: 1.0595e-04\n",
      "Epoch: 39750 | training loss: 5.7764e-04 | validation loss: 1.0648e-04\n",
      "Epoch: 39760 | training loss: 5.8175e-04 | validation loss: 1.0962e-04\n",
      "Epoch: 39770 | training loss: 5.7816e-04 | validation loss: 1.0669e-04\n",
      "Epoch: 39780 | training loss: 5.7724e-04 | validation loss: 1.0624e-04\n",
      "Epoch: 39790 | training loss: 5.7689e-04 | validation loss: 1.0589e-04\n",
      "Epoch: 39800 | training loss: 5.7674e-04 | validation loss: 1.0586e-04\n",
      "Epoch: 39810 | training loss: 5.7672e-04 | validation loss: 1.0587e-04\n",
      "Epoch: 39820 | training loss: 5.7668e-04 | validation loss: 1.0584e-04\n",
      "Epoch: 39830 | training loss: 5.7664e-04 | validation loss: 1.0584e-04\n",
      "Epoch: 39840 | training loss: 5.7660e-04 | validation loss: 1.0584e-04\n",
      "Epoch: 39850 | training loss: 5.7658e-04 | validation loss: 1.0584e-04\n",
      "Epoch: 39860 | training loss: 5.7685e-04 | validation loss: 1.0601e-04\n",
      "Epoch: 39870 | training loss: 5.8508e-04 | validation loss: 1.1177e-04\n",
      "Epoch: 39880 | training loss: 5.7991e-04 | validation loss: 1.0848e-04\n",
      "Epoch: 39890 | training loss: 5.7689e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 39900 | training loss: 5.7646e-04 | validation loss: 1.0590e-04\n",
      "Epoch: 39910 | training loss: 5.7651e-04 | validation loss: 1.0593e-04\n",
      "Epoch: 39920 | training loss: 5.7637e-04 | validation loss: 1.0586e-04\n",
      "Epoch: 39930 | training loss: 5.7630e-04 | validation loss: 1.0583e-04\n",
      "Epoch: 39940 | training loss: 5.7626e-04 | validation loss: 1.0581e-04\n",
      "Epoch: 39950 | training loss: 5.7622e-04 | validation loss: 1.0581e-04\n",
      "Epoch: 39960 | training loss: 5.7619e-04 | validation loss: 1.0581e-04\n",
      "Epoch: 39970 | training loss: 5.7615e-04 | validation loss: 1.0581e-04\n",
      "Epoch: 39980 | training loss: 5.7612e-04 | validation loss: 1.0579e-04\n",
      "Epoch: 39990 | training loss: 5.7609e-04 | validation loss: 1.0568e-04\n",
      "Epoch: 40000 | training loss: 5.7712e-04 | validation loss: 1.0513e-04\n",
      "Epoch: 40010 | training loss: 5.7687e-04 | validation loss: 1.0755e-04\n",
      "Epoch: 40020 | training loss: 5.7601e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40030 | training loss: 5.7632e-04 | validation loss: 1.0563e-04\n",
      "Epoch: 40040 | training loss: 5.8028e-04 | validation loss: 1.0864e-04\n",
      "Epoch: 40050 | training loss: 5.7616e-04 | validation loss: 1.0594e-04\n",
      "Epoch: 40060 | training loss: 5.7609e-04 | validation loss: 1.0592e-04\n",
      "Epoch: 40070 | training loss: 5.7596e-04 | validation loss: 1.0596e-04\n",
      "Epoch: 40080 | training loss: 5.7583e-04 | validation loss: 1.0584e-04\n",
      "Epoch: 40090 | training loss: 5.7575e-04 | validation loss: 1.0582e-04\n",
      "Epoch: 40100 | training loss: 5.7571e-04 | validation loss: 1.0579e-04\n",
      "Epoch: 40110 | training loss: 5.7568e-04 | validation loss: 1.0577e-04\n",
      "Epoch: 40120 | training loss: 5.7564e-04 | validation loss: 1.0577e-04\n",
      "Epoch: 40130 | training loss: 5.7561e-04 | validation loss: 1.0578e-04\n",
      "Epoch: 40140 | training loss: 5.7558e-04 | validation loss: 1.0579e-04\n",
      "Epoch: 40150 | training loss: 5.7571e-04 | validation loss: 1.0592e-04\n",
      "Epoch: 40160 | training loss: 5.8017e-04 | validation loss: 1.0931e-04\n",
      "Epoch: 40170 | training loss: 5.7606e-04 | validation loss: 1.0614e-04\n",
      "Epoch: 40180 | training loss: 5.7652e-04 | validation loss: 1.0666e-04\n",
      "Epoch: 40190 | training loss: 5.7585e-04 | validation loss: 1.0601e-04\n",
      "Epoch: 40200 | training loss: 5.7543e-04 | validation loss: 1.0582e-04\n",
      "Epoch: 40210 | training loss: 5.7534e-04 | validation loss: 1.0575e-04\n",
      "Epoch: 40220 | training loss: 5.7530e-04 | validation loss: 1.0576e-04\n",
      "Epoch: 40230 | training loss: 5.7527e-04 | validation loss: 1.0575e-04\n",
      "Epoch: 40240 | training loss: 5.7524e-04 | validation loss: 1.0575e-04\n",
      "Epoch: 40250 | training loss: 5.7520e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40260 | training loss: 5.7517e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40270 | training loss: 5.7513e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40280 | training loss: 5.7510e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40290 | training loss: 5.7508e-04 | validation loss: 1.0576e-04\n",
      "Epoch: 40300 | training loss: 5.7540e-04 | validation loss: 1.0606e-04\n",
      "Epoch: 40310 | training loss: 5.8513e-04 | validation loss: 1.1337e-04\n",
      "Epoch: 40320 | training loss: 5.7839e-04 | validation loss: 1.0801e-04\n",
      "Epoch: 40330 | training loss: 5.7494e-04 | validation loss: 1.0581e-04\n",
      "Epoch: 40340 | training loss: 5.7530e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 40350 | training loss: 5.7495e-04 | validation loss: 1.0573e-04\n",
      "Epoch: 40360 | training loss: 5.7483e-04 | validation loss: 1.0576e-04\n",
      "Epoch: 40370 | training loss: 5.7481e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40380 | training loss: 5.7477e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40390 | training loss: 5.7473e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40400 | training loss: 5.7470e-04 | validation loss: 1.0572e-04\n",
      "Epoch: 40410 | training loss: 5.7466e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40420 | training loss: 5.7463e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40430 | training loss: 5.7460e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40440 | training loss: 5.7456e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40450 | training loss: 5.7453e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40460 | training loss: 5.7449e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40470 | training loss: 5.7453e-04 | validation loss: 1.0608e-04\n",
      "Epoch: 40480 | training loss: 5.7650e-04 | validation loss: 1.0882e-04\n",
      "Epoch: 40490 | training loss: 5.7709e-04 | validation loss: 1.0736e-04\n",
      "Epoch: 40500 | training loss: 5.7475e-04 | validation loss: 1.0532e-04\n",
      "Epoch: 40510 | training loss: 5.7524e-04 | validation loss: 1.0602e-04\n",
      "Epoch: 40520 | training loss: 5.7487e-04 | validation loss: 1.0609e-04\n",
      "Epoch: 40530 | training loss: 5.7427e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40540 | training loss: 5.7426e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 40550 | training loss: 5.7423e-04 | validation loss: 1.0575e-04\n",
      "Epoch: 40560 | training loss: 5.7417e-04 | validation loss: 1.0569e-04\n",
      "Epoch: 40570 | training loss: 5.7413e-04 | validation loss: 1.0569e-04\n",
      "Epoch: 40580 | training loss: 5.7410e-04 | validation loss: 1.0567e-04\n",
      "Epoch: 40590 | training loss: 5.7406e-04 | validation loss: 1.0566e-04\n",
      "Epoch: 40600 | training loss: 5.7403e-04 | validation loss: 1.0566e-04\n",
      "Epoch: 40610 | training loss: 5.7400e-04 | validation loss: 1.0566e-04\n",
      "Epoch: 40620 | training loss: 5.7396e-04 | validation loss: 1.0566e-04\n",
      "Epoch: 40630 | training loss: 5.7393e-04 | validation loss: 1.0566e-04\n",
      "Epoch: 40640 | training loss: 5.7390e-04 | validation loss: 1.0566e-04\n",
      "Epoch: 40650 | training loss: 5.7403e-04 | validation loss: 1.0575e-04\n",
      "Epoch: 40660 | training loss: 5.8307e-04 | validation loss: 1.1214e-04\n",
      "Epoch: 40670 | training loss: 5.7885e-04 | validation loss: 1.0954e-04\n",
      "Epoch: 40680 | training loss: 5.7378e-04 | validation loss: 1.0563e-04\n",
      "Epoch: 40690 | training loss: 5.7436e-04 | validation loss: 1.0601e-04\n",
      "Epoch: 40700 | training loss: 5.7371e-04 | validation loss: 1.0563e-04\n",
      "Epoch: 40710 | training loss: 5.7375e-04 | validation loss: 1.0572e-04\n",
      "Epoch: 40720 | training loss: 5.7364e-04 | validation loss: 1.0564e-04\n",
      "Epoch: 40730 | training loss: 5.7361e-04 | validation loss: 1.0564e-04\n",
      "Epoch: 40740 | training loss: 5.7358e-04 | validation loss: 1.0565e-04\n",
      "Epoch: 40750 | training loss: 5.7354e-04 | validation loss: 1.0563e-04\n",
      "Epoch: 40760 | training loss: 5.7351e-04 | validation loss: 1.0563e-04\n",
      "Epoch: 40770 | training loss: 5.7348e-04 | validation loss: 1.0563e-04\n",
      "Epoch: 40780 | training loss: 5.7344e-04 | validation loss: 1.0563e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40790 | training loss: 5.7341e-04 | validation loss: 1.0563e-04\n",
      "Epoch: 40800 | training loss: 5.7338e-04 | validation loss: 1.0562e-04\n",
      "Epoch: 40810 | training loss: 5.7334e-04 | validation loss: 1.0562e-04\n",
      "Epoch: 40820 | training loss: 5.7331e-04 | validation loss: 1.0562e-04\n",
      "Epoch: 40830 | training loss: 5.7328e-04 | validation loss: 1.0562e-04\n",
      "Epoch: 40840 | training loss: 5.7324e-04 | validation loss: 1.0562e-04\n",
      "Epoch: 40850 | training loss: 5.7330e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 40860 | training loss: 5.8145e-04 | validation loss: 1.1183e-04\n",
      "Epoch: 40870 | training loss: 5.7947e-04 | validation loss: 1.1000e-04\n",
      "Epoch: 40880 | training loss: 5.7320e-04 | validation loss: 1.0577e-04\n",
      "Epoch: 40890 | training loss: 5.7346e-04 | validation loss: 1.0594e-04\n",
      "Epoch: 40900 | training loss: 5.7333e-04 | validation loss: 1.0575e-04\n",
      "Epoch: 40910 | training loss: 5.7302e-04 | validation loss: 1.0557e-04\n",
      "Epoch: 40920 | training loss: 5.7301e-04 | validation loss: 1.0565e-04\n",
      "Epoch: 40930 | training loss: 5.7296e-04 | validation loss: 1.0560e-04\n",
      "Epoch: 40940 | training loss: 5.7292e-04 | validation loss: 1.0559e-04\n",
      "Epoch: 40950 | training loss: 5.7289e-04 | validation loss: 1.0560e-04\n",
      "Epoch: 40960 | training loss: 5.7286e-04 | validation loss: 1.0559e-04\n",
      "Epoch: 40970 | training loss: 5.7282e-04 | validation loss: 1.0559e-04\n",
      "Epoch: 40980 | training loss: 5.7279e-04 | validation loss: 1.0559e-04\n",
      "Epoch: 40990 | training loss: 5.7276e-04 | validation loss: 1.0558e-04\n",
      "Epoch: 41000 | training loss: 5.7272e-04 | validation loss: 1.0558e-04\n",
      "Epoch: 41010 | training loss: 5.7269e-04 | validation loss: 1.0558e-04\n",
      "Epoch: 41020 | training loss: 5.7266e-04 | validation loss: 1.0558e-04\n",
      "Epoch: 41030 | training loss: 5.7262e-04 | validation loss: 1.0558e-04\n",
      "Epoch: 41040 | training loss: 5.7259e-04 | validation loss: 1.0559e-04\n",
      "Epoch: 41050 | training loss: 5.7258e-04 | validation loss: 1.0578e-04\n",
      "Epoch: 41060 | training loss: 5.7463e-04 | validation loss: 1.0883e-04\n",
      "Epoch: 41070 | training loss: 5.7326e-04 | validation loss: 1.0507e-04\n",
      "Epoch: 41080 | training loss: 5.7491e-04 | validation loss: 1.0654e-04\n",
      "Epoch: 41090 | training loss: 5.7323e-04 | validation loss: 1.0577e-04\n",
      "Epoch: 41100 | training loss: 5.7307e-04 | validation loss: 1.0583e-04\n",
      "Epoch: 41110 | training loss: 5.7267e-04 | validation loss: 1.0573e-04\n",
      "Epoch: 41120 | training loss: 5.7236e-04 | validation loss: 1.0556e-04\n",
      "Epoch: 41130 | training loss: 5.7233e-04 | validation loss: 1.0560e-04\n",
      "Epoch: 41140 | training loss: 5.7227e-04 | validation loss: 1.0560e-04\n",
      "Epoch: 41150 | training loss: 5.7227e-04 | validation loss: 1.0560e-04\n",
      "Epoch: 41160 | training loss: 5.7239e-04 | validation loss: 1.0570e-04\n",
      "Epoch: 41170 | training loss: 5.7469e-04 | validation loss: 1.0744e-04\n",
      "Epoch: 41180 | training loss: 5.7268e-04 | validation loss: 1.0598e-04\n",
      "Epoch: 41190 | training loss: 5.7237e-04 | validation loss: 1.0569e-04\n",
      "Epoch: 41200 | training loss: 5.7220e-04 | validation loss: 1.0565e-04\n",
      "Epoch: 41210 | training loss: 5.7213e-04 | validation loss: 1.0557e-04\n",
      "Epoch: 41220 | training loss: 5.7207e-04 | validation loss: 1.0559e-04\n",
      "Epoch: 41230 | training loss: 5.7198e-04 | validation loss: 1.0553e-04\n",
      "Epoch: 41240 | training loss: 5.7195e-04 | validation loss: 1.0553e-04\n",
      "Epoch: 41250 | training loss: 5.7191e-04 | validation loss: 1.0552e-04\n",
      "Epoch: 41260 | training loss: 5.7188e-04 | validation loss: 1.0553e-04\n",
      "Epoch: 41270 | training loss: 5.7189e-04 | validation loss: 1.0557e-04\n",
      "Epoch: 41280 | training loss: 5.7324e-04 | validation loss: 1.0664e-04\n",
      "Epoch: 41290 | training loss: 5.7580e-04 | validation loss: 1.0860e-04\n",
      "Epoch: 41300 | training loss: 5.7185e-04 | validation loss: 1.0553e-04\n",
      "Epoch: 41310 | training loss: 5.7203e-04 | validation loss: 1.0567e-04\n",
      "Epoch: 41320 | training loss: 5.7197e-04 | validation loss: 1.0576e-04\n",
      "Epoch: 41330 | training loss: 5.7172e-04 | validation loss: 1.0554e-04\n",
      "Epoch: 41340 | training loss: 5.7163e-04 | validation loss: 1.0552e-04\n",
      "Epoch: 41350 | training loss: 5.7159e-04 | validation loss: 1.0550e-04\n",
      "Epoch: 41360 | training loss: 5.7155e-04 | validation loss: 1.0551e-04\n",
      "Epoch: 41370 | training loss: 5.7152e-04 | validation loss: 1.0550e-04\n",
      "Epoch: 41380 | training loss: 5.7149e-04 | validation loss: 1.0550e-04\n",
      "Epoch: 41390 | training loss: 5.7146e-04 | validation loss: 1.0550e-04\n",
      "Epoch: 41400 | training loss: 5.7142e-04 | validation loss: 1.0549e-04\n",
      "Epoch: 41410 | training loss: 5.7139e-04 | validation loss: 1.0549e-04\n",
      "Epoch: 41420 | training loss: 5.7136e-04 | validation loss: 1.0549e-04\n",
      "Epoch: 41430 | training loss: 5.7148e-04 | validation loss: 1.0557e-04\n",
      "Epoch: 41440 | training loss: 5.7889e-04 | validation loss: 1.1079e-04\n",
      "Epoch: 41450 | training loss: 5.7529e-04 | validation loss: 1.0853e-04\n",
      "Epoch: 41460 | training loss: 5.7180e-04 | validation loss: 1.0578e-04\n",
      "Epoch: 41470 | training loss: 5.7158e-04 | validation loss: 1.0578e-04\n",
      "Epoch: 41480 | training loss: 5.7128e-04 | validation loss: 1.0558e-04\n",
      "Epoch: 41490 | training loss: 5.7115e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41500 | training loss: 5.7113e-04 | validation loss: 1.0551e-04\n",
      "Epoch: 41510 | training loss: 5.7108e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41520 | training loss: 5.7104e-04 | validation loss: 1.0547e-04\n",
      "Epoch: 41530 | training loss: 5.7101e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41540 | training loss: 5.7097e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41550 | training loss: 5.7094e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41560 | training loss: 5.7091e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41570 | training loss: 5.7088e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41580 | training loss: 5.7084e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41590 | training loss: 5.7081e-04 | validation loss: 1.0549e-04\n",
      "Epoch: 41600 | training loss: 5.7083e-04 | validation loss: 1.0578e-04\n",
      "Epoch: 41610 | training loss: 5.7296e-04 | validation loss: 1.0882e-04\n",
      "Epoch: 41620 | training loss: 5.7095e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 41630 | training loss: 5.7442e-04 | validation loss: 1.0740e-04\n",
      "Epoch: 41640 | training loss: 5.7078e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 41650 | training loss: 5.7075e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 41660 | training loss: 5.7074e-04 | validation loss: 1.0536e-04\n",
      "Epoch: 41670 | training loss: 5.7063e-04 | validation loss: 1.0541e-04\n",
      "Epoch: 41680 | training loss: 5.7055e-04 | validation loss: 1.0541e-04\n",
      "Epoch: 41690 | training loss: 5.7049e-04 | validation loss: 1.0543e-04\n",
      "Epoch: 41700 | training loss: 5.7047e-04 | validation loss: 1.0545e-04\n",
      "Epoch: 41710 | training loss: 5.7043e-04 | validation loss: 1.0544e-04\n",
      "Epoch: 41720 | training loss: 5.7040e-04 | validation loss: 1.0542e-04\n",
      "Epoch: 41730 | training loss: 5.7037e-04 | validation loss: 1.0541e-04\n",
      "Epoch: 41740 | training loss: 5.7034e-04 | validation loss: 1.0541e-04\n",
      "Epoch: 41750 | training loss: 5.7033e-04 | validation loss: 1.0543e-04\n",
      "Epoch: 41760 | training loss: 5.7198e-04 | validation loss: 1.0660e-04\n",
      "Epoch: 41770 | training loss: 5.7253e-04 | validation loss: 1.0691e-04\n",
      "Epoch: 41780 | training loss: 5.7150e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 41790 | training loss: 5.7064e-04 | validation loss: 1.0581e-04\n",
      "Epoch: 41800 | training loss: 5.7034e-04 | validation loss: 1.0559e-04\n",
      "Epoch: 41810 | training loss: 5.7019e-04 | validation loss: 1.0545e-04\n",
      "Epoch: 41820 | training loss: 5.7009e-04 | validation loss: 1.0540e-04\n",
      "Epoch: 41830 | training loss: 5.7007e-04 | validation loss: 1.0542e-04\n",
      "Epoch: 41840 | training loss: 5.7003e-04 | validation loss: 1.0539e-04\n",
      "Epoch: 41850 | training loss: 5.6999e-04 | validation loss: 1.0540e-04\n",
      "Epoch: 41860 | training loss: 5.6996e-04 | validation loss: 1.0539e-04\n",
      "Epoch: 41870 | training loss: 5.6993e-04 | validation loss: 1.0539e-04\n",
      "Epoch: 41880 | training loss: 5.6990e-04 | validation loss: 1.0539e-04\n",
      "Epoch: 41890 | training loss: 5.6987e-04 | validation loss: 1.0539e-04\n",
      "Epoch: 41900 | training loss: 5.6983e-04 | validation loss: 1.0538e-04\n",
      "Epoch: 41910 | training loss: 5.6980e-04 | validation loss: 1.0538e-04\n",
      "Epoch: 41920 | training loss: 5.6977e-04 | validation loss: 1.0538e-04\n",
      "Epoch: 41930 | training loss: 5.6974e-04 | validation loss: 1.0538e-04\n",
      "Epoch: 41940 | training loss: 5.6971e-04 | validation loss: 1.0537e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41950 | training loss: 5.6983e-04 | validation loss: 1.0546e-04\n",
      "Epoch: 41960 | training loss: 5.8123e-04 | validation loss: 1.1356e-04\n",
      "Epoch: 41970 | training loss: 5.7520e-04 | validation loss: 1.0961e-04\n",
      "Epoch: 41980 | training loss: 5.7040e-04 | validation loss: 1.0589e-04\n",
      "Epoch: 41990 | training loss: 5.6961e-04 | validation loss: 1.0533e-04\n",
      "Epoch: 42000 | training loss: 5.6976e-04 | validation loss: 1.0557e-04\n",
      "Epoch: 42010 | training loss: 5.6952e-04 | validation loss: 1.0542e-04\n",
      "Epoch: 42020 | training loss: 5.6948e-04 | validation loss: 1.0534e-04\n",
      "Epoch: 42030 | training loss: 5.6943e-04 | validation loss: 1.0536e-04\n",
      "Epoch: 42040 | training loss: 5.6940e-04 | validation loss: 1.0536e-04\n",
      "Epoch: 42050 | training loss: 5.6937e-04 | validation loss: 1.0535e-04\n",
      "Epoch: 42060 | training loss: 5.6934e-04 | validation loss: 1.0535e-04\n",
      "Epoch: 42070 | training loss: 5.6930e-04 | validation loss: 1.0535e-04\n",
      "Epoch: 42080 | training loss: 5.6927e-04 | validation loss: 1.0535e-04\n",
      "Epoch: 42090 | training loss: 5.6924e-04 | validation loss: 1.0535e-04\n",
      "Epoch: 42100 | training loss: 5.6921e-04 | validation loss: 1.0534e-04\n",
      "Epoch: 42110 | training loss: 5.6918e-04 | validation loss: 1.0534e-04\n",
      "Epoch: 42120 | training loss: 5.6915e-04 | validation loss: 1.0534e-04\n",
      "Epoch: 42130 | training loss: 5.6911e-04 | validation loss: 1.0534e-04\n",
      "Epoch: 42140 | training loss: 5.6908e-04 | validation loss: 1.0537e-04\n",
      "Epoch: 42150 | training loss: 5.6913e-04 | validation loss: 1.0575e-04\n",
      "Epoch: 42160 | training loss: 5.7099e-04 | validation loss: 1.0845e-04\n",
      "Epoch: 42170 | training loss: 5.6964e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 42180 | training loss: 5.7248e-04 | validation loss: 1.0783e-04\n",
      "Epoch: 42190 | training loss: 5.6904e-04 | validation loss: 1.0524e-04\n",
      "Epoch: 42200 | training loss: 5.6894e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 42210 | training loss: 5.6902e-04 | validation loss: 1.0534e-04\n",
      "Epoch: 42220 | training loss: 5.6892e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42230 | training loss: 5.6880e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 42240 | training loss: 5.6879e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42250 | training loss: 5.6879e-04 | validation loss: 1.0534e-04\n",
      "Epoch: 42260 | training loss: 5.6913e-04 | validation loss: 1.0564e-04\n",
      "Epoch: 42270 | training loss: 5.7323e-04 | validation loss: 1.0869e-04\n",
      "Epoch: 42280 | training loss: 5.6910e-04 | validation loss: 1.0560e-04\n",
      "Epoch: 42290 | training loss: 5.6874e-04 | validation loss: 1.0541e-04\n",
      "Epoch: 42300 | training loss: 5.6860e-04 | validation loss: 1.0530e-04\n",
      "Epoch: 42310 | training loss: 5.6855e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42320 | training loss: 5.6855e-04 | validation loss: 1.0532e-04\n",
      "Epoch: 42330 | training loss: 5.6851e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42340 | training loss: 5.6846e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42350 | training loss: 5.6843e-04 | validation loss: 1.0528e-04\n",
      "Epoch: 42360 | training loss: 5.6840e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42370 | training loss: 5.6838e-04 | validation loss: 1.0530e-04\n",
      "Epoch: 42380 | training loss: 5.6918e-04 | validation loss: 1.0594e-04\n",
      "Epoch: 42390 | training loss: 5.7729e-04 | validation loss: 1.1199e-04\n",
      "Epoch: 42400 | training loss: 5.6836e-04 | validation loss: 1.0527e-04\n",
      "Epoch: 42410 | training loss: 5.6929e-04 | validation loss: 1.0593e-04\n",
      "Epoch: 42420 | training loss: 5.6825e-04 | validation loss: 1.0531e-04\n",
      "Epoch: 42430 | training loss: 5.6829e-04 | validation loss: 1.0538e-04\n",
      "Epoch: 42440 | training loss: 5.6819e-04 | validation loss: 1.0528e-04\n",
      "Epoch: 42450 | training loss: 5.6812e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42460 | training loss: 5.6809e-04 | validation loss: 1.0527e-04\n",
      "Epoch: 42470 | training loss: 5.6806e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42480 | training loss: 5.6803e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42490 | training loss: 5.6800e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42500 | training loss: 5.6797e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42510 | training loss: 5.6794e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 42520 | training loss: 5.6791e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 42530 | training loss: 5.6787e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 42540 | training loss: 5.6784e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 42550 | training loss: 5.6781e-04 | validation loss: 1.0524e-04\n",
      "Epoch: 42560 | training loss: 5.6780e-04 | validation loss: 1.0525e-04\n",
      "Epoch: 42570 | training loss: 5.6949e-04 | validation loss: 1.0643e-04\n",
      "Epoch: 42580 | training loss: 5.6943e-04 | validation loss: 1.0632e-04\n",
      "Epoch: 42590 | training loss: 5.7054e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 42600 | training loss: 5.6768e-04 | validation loss: 1.0533e-04\n",
      "Epoch: 42610 | training loss: 5.6792e-04 | validation loss: 1.0540e-04\n",
      "Epoch: 42620 | training loss: 5.6769e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42630 | training loss: 5.6758e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42640 | training loss: 5.6755e-04 | validation loss: 1.0523e-04\n",
      "Epoch: 42650 | training loss: 5.6751e-04 | validation loss: 1.0523e-04\n",
      "Epoch: 42660 | training loss: 5.6748e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 42670 | training loss: 5.6745e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 42680 | training loss: 5.6742e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 42690 | training loss: 5.6739e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 42700 | training loss: 5.6736e-04 | validation loss: 1.0521e-04\n",
      "Epoch: 42710 | training loss: 5.6733e-04 | validation loss: 1.0521e-04\n",
      "Epoch: 42720 | training loss: 5.6729e-04 | validation loss: 1.0521e-04\n",
      "Epoch: 42730 | training loss: 5.6726e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 42740 | training loss: 5.6724e-04 | validation loss: 1.0528e-04\n",
      "Epoch: 42750 | training loss: 5.6762e-04 | validation loss: 1.0632e-04\n",
      "Epoch: 42760 | training loss: 5.6730e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 42770 | training loss: 5.6754e-04 | validation loss: 1.0619e-04\n",
      "Epoch: 42780 | training loss: 5.6782e-04 | validation loss: 1.0625e-04\n",
      "Epoch: 42790 | training loss: 5.7014e-04 | validation loss: 1.0767e-04\n",
      "Epoch: 42800 | training loss: 5.6706e-04 | validation loss: 1.0521e-04\n",
      "Epoch: 42810 | training loss: 5.6723e-04 | validation loss: 1.0527e-04\n",
      "Epoch: 42820 | training loss: 5.6721e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42830 | training loss: 5.6696e-04 | validation loss: 1.0513e-04\n",
      "Epoch: 42840 | training loss: 5.6698e-04 | validation loss: 1.0520e-04\n",
      "Epoch: 42850 | training loss: 5.6699e-04 | validation loss: 1.0524e-04\n",
      "Epoch: 42860 | training loss: 5.6731e-04 | validation loss: 1.0548e-04\n",
      "Epoch: 42870 | training loss: 5.7036e-04 | validation loss: 1.0765e-04\n",
      "Epoch: 42880 | training loss: 5.6684e-04 | validation loss: 1.0519e-04\n",
      "Epoch: 42890 | training loss: 5.6684e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 42900 | training loss: 5.6691e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42910 | training loss: 5.6682e-04 | validation loss: 1.0526e-04\n",
      "Epoch: 42920 | training loss: 5.6668e-04 | validation loss: 1.0516e-04\n",
      "Epoch: 42930 | training loss: 5.6668e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 42940 | training loss: 5.6666e-04 | validation loss: 1.0518e-04\n",
      "Epoch: 42950 | training loss: 5.6681e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42960 | training loss: 5.6940e-04 | validation loss: 1.0713e-04\n",
      "Epoch: 42970 | training loss: 5.6680e-04 | validation loss: 1.0530e-04\n",
      "Epoch: 42980 | training loss: 5.6665e-04 | validation loss: 1.0529e-04\n",
      "Epoch: 42990 | training loss: 5.6656e-04 | validation loss: 1.0519e-04\n",
      "Epoch: 43000 | training loss: 5.6652e-04 | validation loss: 1.0522e-04\n",
      "Epoch: 43010 | training loss: 5.6647e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 43020 | training loss: 5.6639e-04 | validation loss: 1.0516e-04\n",
      "Epoch: 43030 | training loss: 5.6636e-04 | validation loss: 1.0515e-04\n",
      "Epoch: 43040 | training loss: 5.6632e-04 | validation loss: 1.0514e-04\n",
      "Epoch: 43050 | training loss: 5.6629e-04 | validation loss: 1.0513e-04\n",
      "Epoch: 43060 | training loss: 5.6629e-04 | validation loss: 1.0515e-04\n",
      "Epoch: 43070 | training loss: 5.6721e-04 | validation loss: 1.0579e-04\n",
      "Epoch: 43080 | training loss: 5.7353e-04 | validation loss: 1.1028e-04\n",
      "Epoch: 43090 | training loss: 5.6662e-04 | validation loss: 1.0554e-04\n",
      "Epoch: 43100 | training loss: 5.6655e-04 | validation loss: 1.0542e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43110 | training loss: 5.6643e-04 | validation loss: 1.0531e-04\n",
      "Epoch: 43120 | training loss: 5.6609e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 43130 | training loss: 5.6605e-04 | validation loss: 1.0510e-04\n",
      "Epoch: 43140 | training loss: 5.6603e-04 | validation loss: 1.0513e-04\n",
      "Epoch: 43150 | training loss: 5.6599e-04 | validation loss: 1.0511e-04\n",
      "Epoch: 43160 | training loss: 5.6596e-04 | validation loss: 1.0512e-04\n",
      "Epoch: 43170 | training loss: 5.6593e-04 | validation loss: 1.0510e-04\n",
      "Epoch: 43180 | training loss: 5.6590e-04 | validation loss: 1.0511e-04\n",
      "Epoch: 43190 | training loss: 5.6586e-04 | validation loss: 1.0511e-04\n",
      "Epoch: 43200 | training loss: 5.6583e-04 | validation loss: 1.0511e-04\n",
      "Epoch: 43210 | training loss: 5.6580e-04 | validation loss: 1.0510e-04\n",
      "Epoch: 43220 | training loss: 5.6577e-04 | validation loss: 1.0510e-04\n",
      "Epoch: 43230 | training loss: 5.6576e-04 | validation loss: 1.0514e-04\n",
      "Epoch: 43240 | training loss: 5.6668e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 43250 | training loss: 5.7358e-04 | validation loss: 1.1034e-04\n",
      "Epoch: 43260 | training loss: 5.6713e-04 | validation loss: 1.0751e-04\n",
      "Epoch: 43270 | training loss: 5.6653e-04 | validation loss: 1.0665e-04\n",
      "Epoch: 43280 | training loss: 5.6560e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 43290 | training loss: 5.6566e-04 | validation loss: 1.0489e-04\n",
      "Epoch: 43300 | training loss: 5.6557e-04 | validation loss: 1.0489e-04\n",
      "Epoch: 43310 | training loss: 5.6552e-04 | validation loss: 1.0497e-04\n",
      "Epoch: 43320 | training loss: 5.6548e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 43330 | training loss: 5.6545e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43340 | training loss: 5.6542e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43350 | training loss: 5.6539e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43360 | training loss: 5.6536e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43370 | training loss: 5.6533e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43380 | training loss: 5.6530e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43390 | training loss: 5.6527e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43400 | training loss: 5.6524e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43410 | training loss: 5.6521e-04 | validation loss: 1.0505e-04\n",
      "Epoch: 43420 | training loss: 5.6518e-04 | validation loss: 1.0505e-04\n",
      "Epoch: 43430 | training loss: 5.6526e-04 | validation loss: 1.0509e-04\n",
      "Epoch: 43440 | training loss: 5.7506e-04 | validation loss: 1.1196e-04\n",
      "Epoch: 43450 | training loss: 5.7195e-04 | validation loss: 1.1021e-04\n",
      "Epoch: 43460 | training loss: 5.6572e-04 | validation loss: 1.0555e-04\n",
      "Epoch: 43470 | training loss: 5.6510e-04 | validation loss: 1.0504e-04\n",
      "Epoch: 43480 | training loss: 5.6526e-04 | validation loss: 1.0516e-04\n",
      "Epoch: 43490 | training loss: 5.6505e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 43500 | training loss: 5.6495e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 43510 | training loss: 5.6494e-04 | validation loss: 1.0505e-04\n",
      "Epoch: 43520 | training loss: 5.6490e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 43530 | training loss: 5.6487e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 43540 | training loss: 5.6484e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 43550 | training loss: 5.6481e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 43560 | training loss: 5.6478e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 43570 | training loss: 5.6475e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 43580 | training loss: 5.6472e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 43590 | training loss: 5.6469e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 43600 | training loss: 5.6466e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 43610 | training loss: 5.6463e-04 | validation loss: 1.0501e-04\n",
      "Epoch: 43620 | training loss: 5.6460e-04 | validation loss: 1.0501e-04\n",
      "Epoch: 43630 | training loss: 5.6457e-04 | validation loss: 1.0501e-04\n",
      "Epoch: 43640 | training loss: 5.6454e-04 | validation loss: 1.0501e-04\n",
      "Epoch: 43650 | training loss: 5.6451e-04 | validation loss: 1.0500e-04\n",
      "Epoch: 43660 | training loss: 5.6448e-04 | validation loss: 1.0500e-04\n",
      "Epoch: 43670 | training loss: 5.6456e-04 | validation loss: 1.0510e-04\n",
      "Epoch: 43680 | training loss: 5.7934e-04 | validation loss: 1.1609e-04\n",
      "Epoch: 43690 | training loss: 5.6892e-04 | validation loss: 1.0813e-04\n",
      "Epoch: 43700 | training loss: 5.6688e-04 | validation loss: 1.0673e-04\n",
      "Epoch: 43710 | training loss: 5.6525e-04 | validation loss: 1.0562e-04\n",
      "Epoch: 43720 | training loss: 5.6458e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 43730 | training loss: 5.6433e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 43740 | training loss: 5.6425e-04 | validation loss: 1.0498e-04\n",
      "Epoch: 43750 | training loss: 5.6423e-04 | validation loss: 1.0499e-04\n",
      "Epoch: 43760 | training loss: 5.6420e-04 | validation loss: 1.0499e-04\n",
      "Epoch: 43770 | training loss: 5.6417e-04 | validation loss: 1.0498e-04\n",
      "Epoch: 43780 | training loss: 5.6414e-04 | validation loss: 1.0498e-04\n",
      "Epoch: 43790 | training loss: 5.6411e-04 | validation loss: 1.0498e-04\n",
      "Epoch: 43800 | training loss: 5.6408e-04 | validation loss: 1.0498e-04\n",
      "Epoch: 43810 | training loss: 5.6405e-04 | validation loss: 1.0497e-04\n",
      "Epoch: 43820 | training loss: 5.6402e-04 | validation loss: 1.0497e-04\n",
      "Epoch: 43830 | training loss: 5.6400e-04 | validation loss: 1.0497e-04\n",
      "Epoch: 43840 | training loss: 5.6397e-04 | validation loss: 1.0497e-04\n",
      "Epoch: 43850 | training loss: 5.6394e-04 | validation loss: 1.0496e-04\n",
      "Epoch: 43860 | training loss: 5.6391e-04 | validation loss: 1.0496e-04\n",
      "Epoch: 43870 | training loss: 5.6388e-04 | validation loss: 1.0496e-04\n",
      "Epoch: 43880 | training loss: 5.6385e-04 | validation loss: 1.0496e-04\n",
      "Epoch: 43890 | training loss: 5.6382e-04 | validation loss: 1.0495e-04\n",
      "Epoch: 43900 | training loss: 5.6379e-04 | validation loss: 1.0493e-04\n",
      "Epoch: 43910 | training loss: 5.6382e-04 | validation loss: 1.0467e-04\n",
      "Epoch: 43920 | training loss: 5.6612e-04 | validation loss: 1.0447e-04\n",
      "Epoch: 43930 | training loss: 5.6466e-04 | validation loss: 1.0441e-04\n",
      "Epoch: 43940 | training loss: 5.6542e-04 | validation loss: 1.0550e-04\n",
      "Epoch: 43950 | training loss: 5.6532e-04 | validation loss: 1.0565e-04\n",
      "Epoch: 43960 | training loss: 5.6436e-04 | validation loss: 1.0520e-04\n",
      "Epoch: 43970 | training loss: 5.6362e-04 | validation loss: 1.0479e-04\n",
      "Epoch: 43980 | training loss: 5.6366e-04 | validation loss: 1.0492e-04\n",
      "Epoch: 43990 | training loss: 5.6353e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 44000 | training loss: 5.6355e-04 | validation loss: 1.0493e-04\n",
      "Epoch: 44010 | training loss: 5.6375e-04 | validation loss: 1.0510e-04\n",
      "Epoch: 44020 | training loss: 5.6608e-04 | validation loss: 1.0680e-04\n",
      "Epoch: 44030 | training loss: 5.6375e-04 | validation loss: 1.0513e-04\n",
      "Epoch: 44040 | training loss: 5.6382e-04 | validation loss: 1.0524e-04\n",
      "Epoch: 44050 | training loss: 5.6366e-04 | validation loss: 1.0512e-04\n",
      "Epoch: 44060 | training loss: 5.6343e-04 | validation loss: 1.0500e-04\n",
      "Epoch: 44070 | training loss: 5.6329e-04 | validation loss: 1.0491e-04\n",
      "Epoch: 44080 | training loss: 5.6330e-04 | validation loss: 1.0493e-04\n",
      "Epoch: 44090 | training loss: 5.6325e-04 | validation loss: 1.0492e-04\n",
      "Epoch: 44100 | training loss: 5.6324e-04 | validation loss: 1.0492e-04\n",
      "Epoch: 44110 | training loss: 5.6357e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 44120 | training loss: 5.6933e-04 | validation loss: 1.0932e-04\n",
      "Epoch: 44130 | training loss: 5.6477e-04 | validation loss: 1.0615e-04\n",
      "Epoch: 44140 | training loss: 5.6398e-04 | validation loss: 1.0550e-04\n",
      "Epoch: 44150 | training loss: 5.6342e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 44160 | training loss: 5.6316e-04 | validation loss: 1.0497e-04\n",
      "Epoch: 44170 | training loss: 5.6306e-04 | validation loss: 1.0494e-04\n",
      "Epoch: 44180 | training loss: 5.6299e-04 | validation loss: 1.0490e-04\n",
      "Epoch: 44190 | training loss: 5.6295e-04 | validation loss: 1.0489e-04\n",
      "Epoch: 44200 | training loss: 5.6292e-04 | validation loss: 1.0489e-04\n",
      "Epoch: 44210 | training loss: 5.6289e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 44220 | training loss: 5.6286e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 44230 | training loss: 5.6284e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 44240 | training loss: 5.6312e-04 | validation loss: 1.0509e-04\n",
      "Epoch: 44250 | training loss: 5.7112e-04 | validation loss: 1.1083e-04\n",
      "Epoch: 44260 | training loss: 5.6611e-04 | validation loss: 1.0741e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44270 | training loss: 5.6343e-04 | validation loss: 1.0533e-04\n",
      "Epoch: 44280 | training loss: 5.6270e-04 | validation loss: 1.0486e-04\n",
      "Epoch: 44290 | training loss: 5.6278e-04 | validation loss: 1.0498e-04\n",
      "Epoch: 44300 | training loss: 5.6269e-04 | validation loss: 1.0490e-04\n",
      "Epoch: 44310 | training loss: 5.6262e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 44320 | training loss: 5.6258e-04 | validation loss: 1.0486e-04\n",
      "Epoch: 44330 | training loss: 5.6255e-04 | validation loss: 1.0486e-04\n",
      "Epoch: 44340 | training loss: 5.6252e-04 | validation loss: 1.0485e-04\n",
      "Epoch: 44350 | training loss: 5.6249e-04 | validation loss: 1.0485e-04\n",
      "Epoch: 44360 | training loss: 5.6246e-04 | validation loss: 1.0485e-04\n",
      "Epoch: 44370 | training loss: 5.6243e-04 | validation loss: 1.0485e-04\n",
      "Epoch: 44380 | training loss: 5.6240e-04 | validation loss: 1.0485e-04\n",
      "Epoch: 44390 | training loss: 5.6237e-04 | validation loss: 1.0484e-04\n",
      "Epoch: 44400 | training loss: 5.6234e-04 | validation loss: 1.0484e-04\n",
      "Epoch: 44410 | training loss: 5.6235e-04 | validation loss: 1.0487e-04\n",
      "Epoch: 44420 | training loss: 5.6753e-04 | validation loss: 1.0874e-04\n",
      "Epoch: 44430 | training loss: 5.6833e-04 | validation loss: 1.0919e-04\n",
      "Epoch: 44440 | training loss: 5.6234e-04 | validation loss: 1.0500e-04\n",
      "Epoch: 44450 | training loss: 5.6225e-04 | validation loss: 1.0489e-04\n",
      "Epoch: 44460 | training loss: 5.6231e-04 | validation loss: 1.0489e-04\n",
      "Epoch: 44470 | training loss: 5.6227e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 44480 | training loss: 5.6217e-04 | validation loss: 1.0486e-04\n",
      "Epoch: 44490 | training loss: 5.6209e-04 | validation loss: 1.0482e-04\n",
      "Epoch: 44500 | training loss: 5.6206e-04 | validation loss: 1.0482e-04\n",
      "Epoch: 44510 | training loss: 5.6204e-04 | validation loss: 1.0483e-04\n",
      "Epoch: 44520 | training loss: 5.6201e-04 | validation loss: 1.0482e-04\n",
      "Epoch: 44530 | training loss: 5.6198e-04 | validation loss: 1.0482e-04\n",
      "Epoch: 44540 | training loss: 5.6195e-04 | validation loss: 1.0481e-04\n",
      "Epoch: 44550 | training loss: 5.6192e-04 | validation loss: 1.0481e-04\n",
      "Epoch: 44560 | training loss: 5.6189e-04 | validation loss: 1.0481e-04\n",
      "Epoch: 44570 | training loss: 5.6186e-04 | validation loss: 1.0481e-04\n",
      "Epoch: 44580 | training loss: 5.6184e-04 | validation loss: 1.0480e-04\n",
      "Epoch: 44590 | training loss: 5.6181e-04 | validation loss: 1.0480e-04\n",
      "Epoch: 44600 | training loss: 5.6178e-04 | validation loss: 1.0480e-04\n",
      "Epoch: 44610 | training loss: 5.6175e-04 | validation loss: 1.0480e-04\n",
      "Epoch: 44620 | training loss: 5.6172e-04 | validation loss: 1.0482e-04\n",
      "Epoch: 44630 | training loss: 5.6177e-04 | validation loss: 1.0521e-04\n",
      "Epoch: 44640 | training loss: 5.6331e-04 | validation loss: 1.0751e-04\n",
      "Epoch: 44650 | training loss: 5.6247e-04 | validation loss: 1.0651e-04\n",
      "Epoch: 44660 | training loss: 5.6188e-04 | validation loss: 1.0565e-04\n",
      "Epoch: 44670 | training loss: 5.6167e-04 | validation loss: 1.0523e-04\n",
      "Epoch: 44680 | training loss: 5.6159e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 44690 | training loss: 5.6191e-04 | validation loss: 1.0517e-04\n",
      "Epoch: 44700 | training loss: 5.7192e-04 | validation loss: 1.1241e-04\n",
      "Epoch: 44710 | training loss: 5.6498e-04 | validation loss: 1.0731e-04\n",
      "Epoch: 44720 | training loss: 5.6145e-04 | validation loss: 1.0481e-04\n",
      "Epoch: 44730 | training loss: 5.6182e-04 | validation loss: 1.0510e-04\n",
      "Epoch: 44740 | training loss: 5.6147e-04 | validation loss: 1.0483e-04\n",
      "Epoch: 44750 | training loss: 5.6136e-04 | validation loss: 1.0476e-04\n",
      "Epoch: 44760 | training loss: 5.6134e-04 | validation loss: 1.0477e-04\n",
      "Epoch: 44770 | training loss: 5.6131e-04 | validation loss: 1.0476e-04\n",
      "Epoch: 44780 | training loss: 5.6128e-04 | validation loss: 1.0476e-04\n",
      "Epoch: 44790 | training loss: 5.6124e-04 | validation loss: 1.0475e-04\n",
      "Epoch: 44800 | training loss: 5.6122e-04 | validation loss: 1.0475e-04\n",
      "Epoch: 44810 | training loss: 5.6119e-04 | validation loss: 1.0475e-04\n",
      "Epoch: 44820 | training loss: 5.6116e-04 | validation loss: 1.0475e-04\n",
      "Epoch: 44830 | training loss: 5.6113e-04 | validation loss: 1.0474e-04\n",
      "Epoch: 44840 | training loss: 5.6110e-04 | validation loss: 1.0474e-04\n",
      "Epoch: 44850 | training loss: 5.6107e-04 | validation loss: 1.0474e-04\n",
      "Epoch: 44860 | training loss: 5.6105e-04 | validation loss: 1.0474e-04\n",
      "Epoch: 44870 | training loss: 5.6127e-04 | validation loss: 1.0491e-04\n",
      "Epoch: 44880 | training loss: 5.7680e-04 | validation loss: 1.1612e-04\n",
      "Epoch: 44890 | training loss: 5.6303e-04 | validation loss: 1.0635e-04\n",
      "Epoch: 44900 | training loss: 5.6286e-04 | validation loss: 1.0622e-04\n",
      "Epoch: 44910 | training loss: 5.6117e-04 | validation loss: 1.0496e-04\n",
      "Epoch: 44920 | training loss: 5.6090e-04 | validation loss: 1.0474e-04\n",
      "Epoch: 44930 | training loss: 5.6094e-04 | validation loss: 1.0477e-04\n",
      "Epoch: 44940 | training loss: 5.6083e-04 | validation loss: 1.0472e-04\n",
      "Epoch: 44950 | training loss: 5.6081e-04 | validation loss: 1.0473e-04\n",
      "Epoch: 44960 | training loss: 5.6077e-04 | validation loss: 1.0472e-04\n",
      "Epoch: 44970 | training loss: 5.6075e-04 | validation loss: 1.0472e-04\n",
      "Epoch: 44980 | training loss: 5.6072e-04 | validation loss: 1.0472e-04\n",
      "Epoch: 44990 | training loss: 5.6069e-04 | validation loss: 1.0471e-04\n",
      "Epoch: 45000 | training loss: 5.6066e-04 | validation loss: 1.0471e-04\n",
      "Epoch: 45010 | training loss: 5.6063e-04 | validation loss: 1.0471e-04\n",
      "Epoch: 45020 | training loss: 5.6061e-04 | validation loss: 1.0471e-04\n",
      "Epoch: 45030 | training loss: 5.6058e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 45040 | training loss: 5.6055e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 45050 | training loss: 5.6052e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 45060 | training loss: 5.6049e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 45070 | training loss: 5.6046e-04 | validation loss: 1.0469e-04\n",
      "Epoch: 45080 | training loss: 5.6044e-04 | validation loss: 1.0469e-04\n",
      "Epoch: 45090 | training loss: 5.6041e-04 | validation loss: 1.0469e-04\n",
      "Epoch: 45100 | training loss: 5.6038e-04 | validation loss: 1.0469e-04\n",
      "Epoch: 45110 | training loss: 5.6035e-04 | validation loss: 1.0469e-04\n",
      "Epoch: 45120 | training loss: 5.6084e-04 | validation loss: 1.0504e-04\n",
      "Epoch: 45130 | training loss: 5.7690e-04 | validation loss: 1.1656e-04\n",
      "Epoch: 45140 | training loss: 5.6707e-04 | validation loss: 1.0963e-04\n",
      "Epoch: 45150 | training loss: 5.6202e-04 | validation loss: 1.0604e-04\n",
      "Epoch: 45160 | training loss: 5.6044e-04 | validation loss: 1.0490e-04\n",
      "Epoch: 45170 | training loss: 5.6019e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 45180 | training loss: 5.6017e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45190 | training loss: 5.6014e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45200 | training loss: 5.6011e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45210 | training loss: 5.6009e-04 | validation loss: 1.0467e-04\n",
      "Epoch: 45220 | training loss: 5.6006e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45230 | training loss: 5.6003e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45240 | training loss: 5.6001e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45250 | training loss: 5.5998e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45260 | training loss: 5.5995e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 45270 | training loss: 5.5992e-04 | validation loss: 1.0465e-04\n",
      "Epoch: 45280 | training loss: 5.5990e-04 | validation loss: 1.0465e-04\n",
      "Epoch: 45290 | training loss: 5.5987e-04 | validation loss: 1.0465e-04\n",
      "Epoch: 45300 | training loss: 5.5984e-04 | validation loss: 1.0465e-04\n",
      "Epoch: 45310 | training loss: 5.5982e-04 | validation loss: 1.0464e-04\n",
      "Epoch: 45320 | training loss: 5.5979e-04 | validation loss: 1.0464e-04\n",
      "Epoch: 45330 | training loss: 5.5976e-04 | validation loss: 1.0464e-04\n",
      "Epoch: 45340 | training loss: 5.5973e-04 | validation loss: 1.0464e-04\n",
      "Epoch: 45350 | training loss: 5.5970e-04 | validation loss: 1.0463e-04\n",
      "Epoch: 45360 | training loss: 5.5968e-04 | validation loss: 1.0461e-04\n",
      "Epoch: 45370 | training loss: 5.5975e-04 | validation loss: 1.0429e-04\n",
      "Epoch: 45380 | training loss: 5.6062e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 45390 | training loss: 5.6031e-04 | validation loss: 1.0400e-04\n",
      "Epoch: 45400 | training loss: 5.5982e-04 | validation loss: 1.0414e-04\n",
      "Epoch: 45410 | training loss: 5.5963e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 45420 | training loss: 5.5954e-04 | validation loss: 1.0441e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45430 | training loss: 5.5949e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 45440 | training loss: 5.5946e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 45450 | training loss: 5.5946e-04 | validation loss: 1.0459e-04\n",
      "Epoch: 45460 | training loss: 5.6121e-04 | validation loss: 1.0591e-04\n",
      "Epoch: 45470 | training loss: 5.6138e-04 | validation loss: 1.0599e-04\n",
      "Epoch: 45480 | training loss: 5.6099e-04 | validation loss: 1.0574e-04\n",
      "Epoch: 45490 | training loss: 5.5964e-04 | validation loss: 1.0482e-04\n",
      "Epoch: 45500 | training loss: 5.5957e-04 | validation loss: 1.0479e-04\n",
      "Epoch: 45510 | training loss: 5.5930e-04 | validation loss: 1.0461e-04\n",
      "Epoch: 45520 | training loss: 5.5926e-04 | validation loss: 1.0460e-04\n",
      "Epoch: 45530 | training loss: 5.5923e-04 | validation loss: 1.0460e-04\n",
      "Epoch: 45540 | training loss: 5.5919e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 45550 | training loss: 5.5916e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 45560 | training loss: 5.5913e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 45570 | training loss: 5.5910e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 45580 | training loss: 5.5908e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 45590 | training loss: 5.5905e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 45600 | training loss: 5.5902e-04 | validation loss: 1.0457e-04\n",
      "Epoch: 45610 | training loss: 5.5899e-04 | validation loss: 1.0457e-04\n",
      "Epoch: 45620 | training loss: 5.5897e-04 | validation loss: 1.0457e-04\n",
      "Epoch: 45630 | training loss: 5.5894e-04 | validation loss: 1.0457e-04\n",
      "Epoch: 45640 | training loss: 5.5891e-04 | validation loss: 1.0456e-04\n",
      "Epoch: 45650 | training loss: 5.5890e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 45660 | training loss: 5.6041e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 45670 | training loss: 5.6127e-04 | validation loss: 1.0640e-04\n",
      "Epoch: 45680 | training loss: 5.6242e-04 | validation loss: 1.0724e-04\n",
      "Epoch: 45690 | training loss: 5.5909e-04 | validation loss: 1.0477e-04\n",
      "Epoch: 45700 | training loss: 5.5880e-04 | validation loss: 1.0454e-04\n",
      "Epoch: 45710 | training loss: 5.5888e-04 | validation loss: 1.0463e-04\n",
      "Epoch: 45720 | training loss: 5.5872e-04 | validation loss: 1.0455e-04\n",
      "Epoch: 45730 | training loss: 5.5868e-04 | validation loss: 1.0456e-04\n",
      "Epoch: 45740 | training loss: 5.5865e-04 | validation loss: 1.0456e-04\n",
      "Epoch: 45750 | training loss: 5.5862e-04 | validation loss: 1.0454e-04\n",
      "Epoch: 45760 | training loss: 5.5859e-04 | validation loss: 1.0454e-04\n",
      "Epoch: 45770 | training loss: 5.5856e-04 | validation loss: 1.0454e-04\n",
      "Epoch: 45780 | training loss: 5.5854e-04 | validation loss: 1.0453e-04\n",
      "Epoch: 45790 | training loss: 5.5851e-04 | validation loss: 1.0453e-04\n",
      "Epoch: 45800 | training loss: 5.5848e-04 | validation loss: 1.0453e-04\n",
      "Epoch: 45810 | training loss: 5.5846e-04 | validation loss: 1.0453e-04\n",
      "Epoch: 45820 | training loss: 5.5843e-04 | validation loss: 1.0453e-04\n",
      "Epoch: 45830 | training loss: 5.5840e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 45840 | training loss: 5.5837e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 45850 | training loss: 5.5835e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 45860 | training loss: 5.5832e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 45870 | training loss: 5.5829e-04 | validation loss: 1.0451e-04\n",
      "Epoch: 45880 | training loss: 5.5826e-04 | validation loss: 1.0451e-04\n",
      "Epoch: 45890 | training loss: 5.5825e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 45900 | training loss: 5.6067e-04 | validation loss: 1.0629e-04\n",
      "Epoch: 45910 | training loss: 5.5839e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 45920 | training loss: 5.5967e-04 | validation loss: 1.0558e-04\n",
      "Epoch: 45930 | training loss: 5.5916e-04 | validation loss: 1.0536e-04\n",
      "Epoch: 45940 | training loss: 5.5858e-04 | validation loss: 1.0491e-04\n",
      "Epoch: 45950 | training loss: 5.5825e-04 | validation loss: 1.0464e-04\n",
      "Epoch: 45960 | training loss: 5.5808e-04 | validation loss: 1.0454e-04\n",
      "Epoch: 45970 | training loss: 5.5802e-04 | validation loss: 1.0449e-04\n",
      "Epoch: 45980 | training loss: 5.5800e-04 | validation loss: 1.0449e-04\n",
      "Epoch: 45990 | training loss: 5.5797e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 46000 | training loss: 5.5794e-04 | validation loss: 1.0449e-04\n",
      "Epoch: 46010 | training loss: 5.5792e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 46020 | training loss: 5.5789e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 46030 | training loss: 5.5786e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 46040 | training loss: 5.5784e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 46050 | training loss: 5.5781e-04 | validation loss: 1.0447e-04\n",
      "Epoch: 46060 | training loss: 5.5778e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 46070 | training loss: 5.5776e-04 | validation loss: 1.0451e-04\n",
      "Epoch: 46080 | training loss: 5.5787e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 46090 | training loss: 5.5842e-04 | validation loss: 1.0601e-04\n",
      "Epoch: 46100 | training loss: 5.5808e-04 | validation loss: 1.0551e-04\n",
      "Epoch: 46110 | training loss: 5.5765e-04 | validation loss: 1.0451e-04\n",
      "Epoch: 46120 | training loss: 5.5766e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 46130 | training loss: 5.5761e-04 | validation loss: 1.0428e-04\n",
      "Epoch: 46140 | training loss: 5.5757e-04 | validation loss: 1.0446e-04\n",
      "Epoch: 46150 | training loss: 5.5755e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 46160 | training loss: 5.5759e-04 | validation loss: 1.0449e-04\n",
      "Epoch: 46170 | training loss: 5.6015e-04 | validation loss: 1.0634e-04\n",
      "Epoch: 46180 | training loss: 5.5787e-04 | validation loss: 1.0469e-04\n",
      "Epoch: 46190 | training loss: 5.5811e-04 | validation loss: 1.0491e-04\n",
      "Epoch: 46200 | training loss: 5.5811e-04 | validation loss: 1.0499e-04\n",
      "Epoch: 46210 | training loss: 5.5743e-04 | validation loss: 1.0447e-04\n",
      "Epoch: 46220 | training loss: 5.5736e-04 | validation loss: 1.0444e-04\n",
      "Epoch: 46230 | training loss: 5.5735e-04 | validation loss: 1.0444e-04\n",
      "Epoch: 46240 | training loss: 5.5731e-04 | validation loss: 1.0443e-04\n",
      "Epoch: 46250 | training loss: 5.5728e-04 | validation loss: 1.0443e-04\n",
      "Epoch: 46260 | training loss: 5.5725e-04 | validation loss: 1.0442e-04\n",
      "Epoch: 46270 | training loss: 5.5722e-04 | validation loss: 1.0442e-04\n",
      "Epoch: 46280 | training loss: 5.5719e-04 | validation loss: 1.0442e-04\n",
      "Epoch: 46290 | training loss: 5.5716e-04 | validation loss: 1.0441e-04\n",
      "Epoch: 46300 | training loss: 5.5714e-04 | validation loss: 1.0441e-04\n",
      "Epoch: 46310 | training loss: 5.5711e-04 | validation loss: 1.0441e-04\n",
      "Epoch: 46320 | training loss: 5.5710e-04 | validation loss: 1.0441e-04\n",
      "Epoch: 46330 | training loss: 5.5777e-04 | validation loss: 1.0491e-04\n",
      "Epoch: 46340 | training loss: 5.6807e-04 | validation loss: 1.1235e-04\n",
      "Epoch: 46350 | training loss: 5.5729e-04 | validation loss: 1.0466e-04\n",
      "Epoch: 46360 | training loss: 5.5814e-04 | validation loss: 1.0524e-04\n",
      "Epoch: 46370 | training loss: 5.5698e-04 | validation loss: 1.0437e-04\n",
      "Epoch: 46380 | training loss: 5.5707e-04 | validation loss: 1.0451e-04\n",
      "Epoch: 46390 | training loss: 5.5692e-04 | validation loss: 1.0442e-04\n",
      "Epoch: 46400 | training loss: 5.5688e-04 | validation loss: 1.0437e-04\n",
      "Epoch: 46410 | training loss: 5.5685e-04 | validation loss: 1.0440e-04\n",
      "Epoch: 46420 | training loss: 5.5682e-04 | validation loss: 1.0438e-04\n",
      "Epoch: 46430 | training loss: 5.5679e-04 | validation loss: 1.0439e-04\n",
      "Epoch: 46440 | training loss: 5.5677e-04 | validation loss: 1.0438e-04\n",
      "Epoch: 46450 | training loss: 5.5674e-04 | validation loss: 1.0438e-04\n",
      "Epoch: 46460 | training loss: 5.5671e-04 | validation loss: 1.0437e-04\n",
      "Epoch: 46470 | training loss: 5.5668e-04 | validation loss: 1.0437e-04\n",
      "Epoch: 46480 | training loss: 5.5666e-04 | validation loss: 1.0437e-04\n",
      "Epoch: 46490 | training loss: 5.5663e-04 | validation loss: 1.0436e-04\n",
      "Epoch: 46500 | training loss: 5.5660e-04 | validation loss: 1.0435e-04\n",
      "Epoch: 46510 | training loss: 5.5658e-04 | validation loss: 1.0427e-04\n",
      "Epoch: 46520 | training loss: 5.5733e-04 | validation loss: 1.0388e-04\n",
      "Epoch: 46530 | training loss: 5.6135e-04 | validation loss: 1.0877e-04\n",
      "Epoch: 46540 | training loss: 5.5689e-04 | validation loss: 1.0499e-04\n",
      "Epoch: 46550 | training loss: 5.5775e-04 | validation loss: 1.0578e-04\n",
      "Epoch: 46560 | training loss: 5.5696e-04 | validation loss: 1.0514e-04\n",
      "Epoch: 46570 | training loss: 5.5646e-04 | validation loss: 1.0458e-04\n",
      "Epoch: 46580 | training loss: 5.5640e-04 | validation loss: 1.0440e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46590 | training loss: 5.5637e-04 | validation loss: 1.0433e-04\n",
      "Epoch: 46600 | training loss: 5.5634e-04 | validation loss: 1.0432e-04\n",
      "Epoch: 46610 | training loss: 5.5631e-04 | validation loss: 1.0432e-04\n",
      "Epoch: 46620 | training loss: 5.5629e-04 | validation loss: 1.0432e-04\n",
      "Epoch: 46630 | training loss: 5.5626e-04 | validation loss: 1.0433e-04\n",
      "Epoch: 46640 | training loss: 5.5623e-04 | validation loss: 1.0433e-04\n",
      "Epoch: 46650 | training loss: 5.5621e-04 | validation loss: 1.0433e-04\n",
      "Epoch: 46660 | training loss: 5.5618e-04 | validation loss: 1.0432e-04\n",
      "Epoch: 46670 | training loss: 5.5617e-04 | validation loss: 1.0433e-04\n",
      "Epoch: 46680 | training loss: 5.5665e-04 | validation loss: 1.0467e-04\n",
      "Epoch: 46690 | training loss: 5.6797e-04 | validation loss: 1.1285e-04\n",
      "Epoch: 46700 | training loss: 5.5781e-04 | validation loss: 1.0553e-04\n",
      "Epoch: 46710 | training loss: 5.5661e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 46720 | training loss: 5.5633e-04 | validation loss: 1.0452e-04\n",
      "Epoch: 46730 | training loss: 5.5603e-04 | validation loss: 1.0432e-04\n",
      "Epoch: 46740 | training loss: 5.5604e-04 | validation loss: 1.0434e-04\n",
      "Epoch: 46750 | training loss: 5.5596e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 46760 | training loss: 5.5592e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 46770 | training loss: 5.5590e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 46780 | training loss: 5.5587e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 46790 | training loss: 5.5584e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 46800 | training loss: 5.5582e-04 | validation loss: 1.0429e-04\n",
      "Epoch: 46810 | training loss: 5.5579e-04 | validation loss: 1.0429e-04\n",
      "Epoch: 46820 | training loss: 5.5577e-04 | validation loss: 1.0429e-04\n",
      "Epoch: 46830 | training loss: 5.5574e-04 | validation loss: 1.0429e-04\n",
      "Epoch: 46840 | training loss: 5.5571e-04 | validation loss: 1.0428e-04\n",
      "Epoch: 46850 | training loss: 5.5569e-04 | validation loss: 1.0428e-04\n",
      "Epoch: 46860 | training loss: 5.5568e-04 | validation loss: 1.0429e-04\n",
      "Epoch: 46870 | training loss: 5.5715e-04 | validation loss: 1.0538e-04\n",
      "Epoch: 46880 | training loss: 5.5899e-04 | validation loss: 1.0666e-04\n",
      "Epoch: 46890 | training loss: 5.5789e-04 | validation loss: 1.0595e-04\n",
      "Epoch: 46900 | training loss: 5.5561e-04 | validation loss: 1.0438e-04\n",
      "Epoch: 46910 | training loss: 5.5594e-04 | validation loss: 1.0460e-04\n",
      "Epoch: 46920 | training loss: 5.5553e-04 | validation loss: 1.0426e-04\n",
      "Epoch: 46930 | training loss: 5.5552e-04 | validation loss: 1.0426e-04\n",
      "Epoch: 46940 | training loss: 5.5546e-04 | validation loss: 1.0427e-04\n",
      "Epoch: 46950 | training loss: 5.5544e-04 | validation loss: 1.0427e-04\n",
      "Epoch: 46960 | training loss: 5.5540e-04 | validation loss: 1.0425e-04\n",
      "Epoch: 46970 | training loss: 5.5538e-04 | validation loss: 1.0425e-04\n",
      "Epoch: 46980 | training loss: 5.5535e-04 | validation loss: 1.0425e-04\n",
      "Epoch: 46990 | training loss: 5.5532e-04 | validation loss: 1.0425e-04\n",
      "Epoch: 47000 | training loss: 5.5530e-04 | validation loss: 1.0425e-04\n",
      "Epoch: 47010 | training loss: 5.5527e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 47020 | training loss: 5.5525e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 47030 | training loss: 5.5522e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 47040 | training loss: 5.5519e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 47050 | training loss: 5.5517e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47060 | training loss: 5.5514e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47070 | training loss: 5.5511e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47080 | training loss: 5.5509e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47090 | training loss: 5.5543e-04 | validation loss: 1.0450e-04\n",
      "Epoch: 47100 | training loss: 5.7582e-04 | validation loss: 1.1944e-04\n",
      "Epoch: 47110 | training loss: 5.5650e-04 | validation loss: 1.0520e-04\n",
      "Epoch: 47120 | training loss: 5.5504e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47130 | training loss: 5.5496e-04 | validation loss: 1.0422e-04\n",
      "Epoch: 47140 | training loss: 5.5496e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47150 | training loss: 5.5495e-04 | validation loss: 1.0425e-04\n",
      "Epoch: 47160 | training loss: 5.5491e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 47170 | training loss: 5.5487e-04 | validation loss: 1.0421e-04\n",
      "Epoch: 47180 | training loss: 5.5483e-04 | validation loss: 1.0420e-04\n",
      "Epoch: 47190 | training loss: 5.5481e-04 | validation loss: 1.0420e-04\n",
      "Epoch: 47200 | training loss: 5.5478e-04 | validation loss: 1.0420e-04\n",
      "Epoch: 47210 | training loss: 5.5476e-04 | validation loss: 1.0419e-04\n",
      "Epoch: 47220 | training loss: 5.5473e-04 | validation loss: 1.0419e-04\n",
      "Epoch: 47230 | training loss: 5.5470e-04 | validation loss: 1.0419e-04\n",
      "Epoch: 47240 | training loss: 5.5468e-04 | validation loss: 1.0419e-04\n",
      "Epoch: 47250 | training loss: 5.5465e-04 | validation loss: 1.0419e-04\n",
      "Epoch: 47260 | training loss: 5.5463e-04 | validation loss: 1.0422e-04\n",
      "Epoch: 47270 | training loss: 5.5474e-04 | validation loss: 1.0474e-04\n",
      "Epoch: 47280 | training loss: 5.5507e-04 | validation loss: 1.0539e-04\n",
      "Epoch: 47290 | training loss: 5.5513e-04 | validation loss: 1.0552e-04\n",
      "Epoch: 47300 | training loss: 5.5466e-04 | validation loss: 1.0473e-04\n",
      "Epoch: 47310 | training loss: 5.5451e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 47320 | training loss: 5.5447e-04 | validation loss: 1.0411e-04\n",
      "Epoch: 47330 | training loss: 5.5445e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 47340 | training loss: 5.5442e-04 | validation loss: 1.0409e-04\n",
      "Epoch: 47350 | training loss: 5.5439e-04 | validation loss: 1.0416e-04\n",
      "Epoch: 47360 | training loss: 5.5437e-04 | validation loss: 1.0418e-04\n",
      "Epoch: 47370 | training loss: 5.5434e-04 | validation loss: 1.0415e-04\n",
      "Epoch: 47380 | training loss: 5.5437e-04 | validation loss: 1.0417e-04\n",
      "Epoch: 47390 | training loss: 5.6194e-04 | validation loss: 1.0960e-04\n",
      "Epoch: 47400 | training loss: 5.6237e-04 | validation loss: 1.1004e-04\n",
      "Epoch: 47410 | training loss: 5.5496e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 47420 | training loss: 5.5422e-04 | validation loss: 1.0417e-04\n",
      "Epoch: 47430 | training loss: 5.5428e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47440 | training loss: 5.5428e-04 | validation loss: 1.0423e-04\n",
      "Epoch: 47450 | training loss: 5.5418e-04 | validation loss: 1.0418e-04\n",
      "Epoch: 47460 | training loss: 5.5412e-04 | validation loss: 1.0414e-04\n",
      "Epoch: 47470 | training loss: 5.5410e-04 | validation loss: 1.0414e-04\n",
      "Epoch: 47480 | training loss: 5.5407e-04 | validation loss: 1.0413e-04\n",
      "Epoch: 47490 | training loss: 5.5404e-04 | validation loss: 1.0412e-04\n",
      "Epoch: 47500 | training loss: 5.5402e-04 | validation loss: 1.0412e-04\n",
      "Epoch: 47510 | training loss: 5.5399e-04 | validation loss: 1.0412e-04\n",
      "Epoch: 47520 | training loss: 5.5397e-04 | validation loss: 1.0412e-04\n",
      "Epoch: 47530 | training loss: 5.5394e-04 | validation loss: 1.0411e-04\n",
      "Epoch: 47540 | training loss: 5.5392e-04 | validation loss: 1.0411e-04\n",
      "Epoch: 47550 | training loss: 5.5389e-04 | validation loss: 1.0411e-04\n",
      "Epoch: 47560 | training loss: 5.5387e-04 | validation loss: 1.0411e-04\n",
      "Epoch: 47570 | training loss: 5.5384e-04 | validation loss: 1.0410e-04\n",
      "Epoch: 47580 | training loss: 5.5381e-04 | validation loss: 1.0410e-04\n",
      "Epoch: 47590 | training loss: 5.5379e-04 | validation loss: 1.0410e-04\n",
      "Epoch: 47600 | training loss: 5.5376e-04 | validation loss: 1.0410e-04\n",
      "Epoch: 47610 | training loss: 5.5374e-04 | validation loss: 1.0409e-04\n",
      "Epoch: 47620 | training loss: 5.5371e-04 | validation loss: 1.0409e-04\n",
      "Epoch: 47630 | training loss: 5.5368e-04 | validation loss: 1.0409e-04\n",
      "Epoch: 47640 | training loss: 5.5366e-04 | validation loss: 1.0409e-04\n",
      "Epoch: 47650 | training loss: 5.5495e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 47660 | training loss: 5.5565e-04 | validation loss: 1.0542e-04\n",
      "Epoch: 47670 | training loss: 5.5700e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 47680 | training loss: 5.5480e-04 | validation loss: 1.0512e-04\n",
      "Epoch: 47690 | training loss: 5.5395e-04 | validation loss: 1.0450e-04\n",
      "Epoch: 47700 | training loss: 5.5367e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 47710 | training loss: 5.5355e-04 | validation loss: 1.0414e-04\n",
      "Epoch: 47720 | training loss: 5.5349e-04 | validation loss: 1.0412e-04\n",
      "Epoch: 47730 | training loss: 5.5345e-04 | validation loss: 1.0409e-04\n",
      "Epoch: 47740 | training loss: 5.5341e-04 | validation loss: 1.0406e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47750 | training loss: 5.5339e-04 | validation loss: 1.0406e-04\n",
      "Epoch: 47760 | training loss: 5.5336e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 47770 | training loss: 5.5334e-04 | validation loss: 1.0406e-04\n",
      "Epoch: 47780 | training loss: 5.5331e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 47790 | training loss: 5.5329e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 47800 | training loss: 5.5326e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 47810 | training loss: 5.5324e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 47820 | training loss: 5.5321e-04 | validation loss: 1.0404e-04\n",
      "Epoch: 47830 | training loss: 5.5319e-04 | validation loss: 1.0404e-04\n",
      "Epoch: 47840 | training loss: 5.5316e-04 | validation loss: 1.0404e-04\n",
      "Epoch: 47850 | training loss: 5.5314e-04 | validation loss: 1.0402e-04\n",
      "Epoch: 47860 | training loss: 5.5313e-04 | validation loss: 1.0386e-04\n",
      "Epoch: 47870 | training loss: 5.5547e-04 | validation loss: 1.0364e-04\n",
      "Epoch: 47880 | training loss: 5.5321e-04 | validation loss: 1.0461e-04\n",
      "Epoch: 47890 | training loss: 5.5330e-04 | validation loss: 1.0483e-04\n",
      "Epoch: 47900 | training loss: 5.5311e-04 | validation loss: 1.0449e-04\n",
      "Epoch: 47910 | training loss: 5.5300e-04 | validation loss: 1.0419e-04\n",
      "Epoch: 47920 | training loss: 5.5296e-04 | validation loss: 1.0400e-04\n",
      "Epoch: 47930 | training loss: 5.5294e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 47940 | training loss: 5.5300e-04 | validation loss: 1.0403e-04\n",
      "Epoch: 47950 | training loss: 5.5659e-04 | validation loss: 1.0672e-04\n",
      "Epoch: 47960 | training loss: 5.5294e-04 | validation loss: 1.0407e-04\n",
      "Epoch: 47970 | training loss: 5.5459e-04 | validation loss: 1.0528e-04\n",
      "Epoch: 47980 | training loss: 5.5308e-04 | validation loss: 1.0421e-04\n",
      "Epoch: 47990 | training loss: 5.5285e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 48000 | training loss: 5.5285e-04 | validation loss: 1.0406e-04\n",
      "Epoch: 48010 | training loss: 5.5275e-04 | validation loss: 1.0401e-04\n",
      "Epoch: 48020 | training loss: 5.5271e-04 | validation loss: 1.0399e-04\n",
      "Epoch: 48030 | training loss: 5.5268e-04 | validation loss: 1.0399e-04\n",
      "Epoch: 48040 | training loss: 5.5266e-04 | validation loss: 1.0399e-04\n",
      "Epoch: 48050 | training loss: 5.5263e-04 | validation loss: 1.0398e-04\n",
      "Epoch: 48060 | training loss: 5.5261e-04 | validation loss: 1.0398e-04\n",
      "Epoch: 48070 | training loss: 5.5258e-04 | validation loss: 1.0398e-04\n",
      "Epoch: 48080 | training loss: 5.5256e-04 | validation loss: 1.0398e-04\n",
      "Epoch: 48090 | training loss: 5.5253e-04 | validation loss: 1.0397e-04\n",
      "Epoch: 48100 | training loss: 5.5251e-04 | validation loss: 1.0397e-04\n",
      "Epoch: 48110 | training loss: 5.5249e-04 | validation loss: 1.0398e-04\n",
      "Epoch: 48120 | training loss: 5.5308e-04 | validation loss: 1.0442e-04\n",
      "Epoch: 48130 | training loss: 5.6528e-04 | validation loss: 1.1335e-04\n",
      "Epoch: 48140 | training loss: 5.5255e-04 | validation loss: 1.0402e-04\n",
      "Epoch: 48150 | training loss: 5.5380e-04 | validation loss: 1.0497e-04\n",
      "Epoch: 48160 | training loss: 5.5240e-04 | validation loss: 1.0402e-04\n",
      "Epoch: 48170 | training loss: 5.5248e-04 | validation loss: 1.0408e-04\n",
      "Epoch: 48180 | training loss: 5.5232e-04 | validation loss: 1.0395e-04\n",
      "Epoch: 48190 | training loss: 5.5231e-04 | validation loss: 1.0396e-04\n",
      "Epoch: 48200 | training loss: 5.5226e-04 | validation loss: 1.0396e-04\n",
      "Epoch: 48210 | training loss: 5.5224e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48220 | training loss: 5.5221e-04 | validation loss: 1.0395e-04\n",
      "Epoch: 48230 | training loss: 5.5218e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48240 | training loss: 5.5216e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48250 | training loss: 5.5213e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48260 | training loss: 5.5211e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48270 | training loss: 5.5208e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 48280 | training loss: 5.5206e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 48290 | training loss: 5.5203e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 48300 | training loss: 5.5201e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 48310 | training loss: 5.5198e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 48320 | training loss: 5.5197e-04 | validation loss: 1.0395e-04\n",
      "Epoch: 48330 | training loss: 5.5346e-04 | validation loss: 1.0518e-04\n",
      "Epoch: 48340 | training loss: 5.5499e-04 | validation loss: 1.0568e-04\n",
      "Epoch: 48350 | training loss: 5.5547e-04 | validation loss: 1.0727e-04\n",
      "Epoch: 48360 | training loss: 5.5232e-04 | validation loss: 1.0482e-04\n",
      "Epoch: 48370 | training loss: 5.5185e-04 | validation loss: 1.0404e-04\n",
      "Epoch: 48380 | training loss: 5.5188e-04 | validation loss: 1.0375e-04\n",
      "Epoch: 48390 | training loss: 5.5185e-04 | validation loss: 1.0371e-04\n",
      "Epoch: 48400 | training loss: 5.5177e-04 | validation loss: 1.0384e-04\n",
      "Epoch: 48410 | training loss: 5.5174e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48420 | training loss: 5.5172e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48430 | training loss: 5.5169e-04 | validation loss: 1.0390e-04\n",
      "Epoch: 48440 | training loss: 5.5166e-04 | validation loss: 1.0388e-04\n",
      "Epoch: 48450 | training loss: 5.5164e-04 | validation loss: 1.0390e-04\n",
      "Epoch: 48460 | training loss: 5.5161e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 48470 | training loss: 5.5159e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 48480 | training loss: 5.5156e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 48490 | training loss: 5.5154e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 48500 | training loss: 5.5151e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 48510 | training loss: 5.5149e-04 | validation loss: 1.0388e-04\n",
      "Epoch: 48520 | training loss: 5.5146e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 48530 | training loss: 5.5146e-04 | validation loss: 1.0401e-04\n",
      "Epoch: 48540 | training loss: 5.5383e-04 | validation loss: 1.0677e-04\n",
      "Epoch: 48550 | training loss: 5.5354e-04 | validation loss: 1.0420e-04\n",
      "Epoch: 48560 | training loss: 5.5204e-04 | validation loss: 1.0366e-04\n",
      "Epoch: 48570 | training loss: 5.5201e-04 | validation loss: 1.0400e-04\n",
      "Epoch: 48580 | training loss: 5.5139e-04 | validation loss: 1.0395e-04\n",
      "Epoch: 48590 | training loss: 5.5130e-04 | validation loss: 1.0397e-04\n",
      "Epoch: 48600 | training loss: 5.5129e-04 | validation loss: 1.0395e-04\n",
      "Epoch: 48610 | training loss: 5.5126e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 48620 | training loss: 5.5122e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 48630 | training loss: 5.5120e-04 | validation loss: 1.0388e-04\n",
      "Epoch: 48640 | training loss: 5.5117e-04 | validation loss: 1.0386e-04\n",
      "Epoch: 48650 | training loss: 5.5115e-04 | validation loss: 1.0385e-04\n",
      "Epoch: 48660 | training loss: 5.5112e-04 | validation loss: 1.0385e-04\n",
      "Epoch: 48670 | training loss: 5.5110e-04 | validation loss: 1.0384e-04\n",
      "Epoch: 48680 | training loss: 5.5107e-04 | validation loss: 1.0384e-04\n",
      "Epoch: 48690 | training loss: 5.5106e-04 | validation loss: 1.0386e-04\n",
      "Epoch: 48700 | training loss: 5.5150e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 48710 | training loss: 5.6396e-04 | validation loss: 1.1343e-04\n",
      "Epoch: 48720 | training loss: 5.5268e-04 | validation loss: 1.0513e-04\n",
      "Epoch: 48730 | training loss: 5.5184e-04 | validation loss: 1.0450e-04\n",
      "Epoch: 48740 | training loss: 5.5108e-04 | validation loss: 1.0398e-04\n",
      "Epoch: 48750 | training loss: 5.5103e-04 | validation loss: 1.0394e-04\n",
      "Epoch: 48760 | training loss: 5.5092e-04 | validation loss: 1.0386e-04\n",
      "Epoch: 48770 | training loss: 5.5086e-04 | validation loss: 1.0383e-04\n",
      "Epoch: 48780 | training loss: 5.5084e-04 | validation loss: 1.0383e-04\n",
      "Epoch: 48790 | training loss: 5.5081e-04 | validation loss: 1.0382e-04\n",
      "Epoch: 48800 | training loss: 5.5078e-04 | validation loss: 1.0382e-04\n",
      "Epoch: 48810 | training loss: 5.5076e-04 | validation loss: 1.0382e-04\n",
      "Epoch: 48820 | training loss: 5.5073e-04 | validation loss: 1.0382e-04\n",
      "Epoch: 48830 | training loss: 5.5071e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 48840 | training loss: 5.5069e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 48850 | training loss: 5.5066e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 48860 | training loss: 5.5064e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 48870 | training loss: 5.5061e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 48880 | training loss: 5.5059e-04 | validation loss: 1.0380e-04\n",
      "Epoch: 48890 | training loss: 5.5056e-04 | validation loss: 1.0380e-04\n",
      "Epoch: 48900 | training loss: 5.5073e-04 | validation loss: 1.0396e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48910 | training loss: 5.6759e-04 | validation loss: 1.1632e-04\n",
      "Epoch: 48920 | training loss: 5.5286e-04 | validation loss: 1.0561e-04\n",
      "Epoch: 48930 | training loss: 5.5263e-04 | validation loss: 1.0533e-04\n",
      "Epoch: 48940 | training loss: 5.5113e-04 | validation loss: 1.0416e-04\n",
      "Epoch: 48950 | training loss: 5.5050e-04 | validation loss: 1.0372e-04\n",
      "Epoch: 48960 | training loss: 5.5040e-04 | validation loss: 1.0376e-04\n",
      "Epoch: 48970 | training loss: 5.5040e-04 | validation loss: 1.0385e-04\n",
      "Epoch: 48980 | training loss: 5.5035e-04 | validation loss: 1.0382e-04\n",
      "Epoch: 48990 | training loss: 5.5032e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49000 | training loss: 5.5030e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49010 | training loss: 5.5028e-04 | validation loss: 1.0379e-04\n",
      "Epoch: 49020 | training loss: 5.5025e-04 | validation loss: 1.0378e-04\n",
      "Epoch: 49030 | training loss: 5.5023e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49040 | training loss: 5.5020e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49050 | training loss: 5.5018e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49060 | training loss: 5.5016e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49070 | training loss: 5.5013e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49080 | training loss: 5.5011e-04 | validation loss: 1.0376e-04\n",
      "Epoch: 49090 | training loss: 5.5008e-04 | validation loss: 1.0376e-04\n",
      "Epoch: 49100 | training loss: 5.5006e-04 | validation loss: 1.0376e-04\n",
      "Epoch: 49110 | training loss: 5.5003e-04 | validation loss: 1.0376e-04\n",
      "Epoch: 49120 | training loss: 5.5001e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49130 | training loss: 5.5000e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 49140 | training loss: 5.5211e-04 | validation loss: 1.0700e-04\n",
      "Epoch: 49150 | training loss: 5.5172e-04 | validation loss: 1.0392e-04\n",
      "Epoch: 49160 | training loss: 5.5468e-04 | validation loss: 1.0611e-04\n",
      "Epoch: 49170 | training loss: 5.5113e-04 | validation loss: 1.0427e-04\n",
      "Epoch: 49180 | training loss: 5.5005e-04 | validation loss: 1.0370e-04\n",
      "Epoch: 49190 | training loss: 5.4986e-04 | validation loss: 1.0374e-04\n",
      "Epoch: 49200 | training loss: 5.4982e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49210 | training loss: 5.4980e-04 | validation loss: 1.0377e-04\n",
      "Epoch: 49220 | training loss: 5.4978e-04 | validation loss: 1.0375e-04\n",
      "Epoch: 49230 | training loss: 5.4974e-04 | validation loss: 1.0374e-04\n",
      "Epoch: 49240 | training loss: 5.4972e-04 | validation loss: 1.0373e-04\n",
      "Epoch: 49250 | training loss: 5.4969e-04 | validation loss: 1.0372e-04\n",
      "Epoch: 49260 | training loss: 5.4967e-04 | validation loss: 1.0372e-04\n",
      "Epoch: 49270 | training loss: 5.4965e-04 | validation loss: 1.0372e-04\n",
      "Epoch: 49280 | training loss: 5.4989e-04 | validation loss: 1.0390e-04\n",
      "Epoch: 49290 | training loss: 5.6097e-04 | validation loss: 1.1190e-04\n",
      "Epoch: 49300 | training loss: 5.5410e-04 | validation loss: 1.0703e-04\n",
      "Epoch: 49310 | training loss: 5.4958e-04 | validation loss: 1.0373e-04\n",
      "Epoch: 49320 | training loss: 5.5009e-04 | validation loss: 1.0411e-04\n",
      "Epoch: 49330 | training loss: 5.4950e-04 | validation loss: 1.0370e-04\n",
      "Epoch: 49340 | training loss: 5.4955e-04 | validation loss: 1.0376e-04\n",
      "Epoch: 49350 | training loss: 5.4947e-04 | validation loss: 1.0371e-04\n",
      "Epoch: 49360 | training loss: 5.4943e-04 | validation loss: 1.0371e-04\n",
      "Epoch: 49370 | training loss: 5.4941e-04 | validation loss: 1.0371e-04\n",
      "Epoch: 49380 | training loss: 5.4939e-04 | validation loss: 1.0370e-04\n",
      "Epoch: 49390 | training loss: 5.4936e-04 | validation loss: 1.0370e-04\n",
      "Epoch: 49400 | training loss: 5.4934e-04 | validation loss: 1.0370e-04\n",
      "Epoch: 49410 | training loss: 5.4931e-04 | validation loss: 1.0370e-04\n",
      "Epoch: 49420 | training loss: 5.4929e-04 | validation loss: 1.0369e-04\n",
      "Epoch: 49430 | training loss: 5.4926e-04 | validation loss: 1.0369e-04\n",
      "Epoch: 49440 | training loss: 5.4924e-04 | validation loss: 1.0369e-04\n",
      "Epoch: 49450 | training loss: 5.4922e-04 | validation loss: 1.0369e-04\n",
      "Epoch: 49460 | training loss: 5.4919e-04 | validation loss: 1.0369e-04\n",
      "Epoch: 49470 | training loss: 5.4922e-04 | validation loss: 1.0372e-04\n",
      "Epoch: 49480 | training loss: 5.5358e-04 | validation loss: 1.0688e-04\n",
      "Epoch: 49490 | training loss: 5.5091e-04 | validation loss: 1.0502e-04\n",
      "Epoch: 49500 | training loss: 5.5068e-04 | validation loss: 1.0486e-04\n",
      "Epoch: 49510 | training loss: 5.4992e-04 | validation loss: 1.0427e-04\n",
      "Epoch: 49520 | training loss: 5.4905e-04 | validation loss: 1.0364e-04\n",
      "Epoch: 49530 | training loss: 5.4913e-04 | validation loss: 1.0374e-04\n",
      "Epoch: 49540 | training loss: 5.4902e-04 | validation loss: 1.0370e-04\n",
      "Epoch: 49550 | training loss: 5.4899e-04 | validation loss: 1.0369e-04\n",
      "Epoch: 49560 | training loss: 5.4896e-04 | validation loss: 1.0366e-04\n",
      "Epoch: 49570 | training loss: 5.4894e-04 | validation loss: 1.0367e-04\n",
      "Epoch: 49580 | training loss: 5.4891e-04 | validation loss: 1.0367e-04\n",
      "Epoch: 49590 | training loss: 5.4889e-04 | validation loss: 1.0366e-04\n",
      "Epoch: 49600 | training loss: 5.4886e-04 | validation loss: 1.0366e-04\n",
      "Epoch: 49610 | training loss: 5.4884e-04 | validation loss: 1.0366e-04\n",
      "Epoch: 49620 | training loss: 5.4881e-04 | validation loss: 1.0366e-04\n",
      "Epoch: 49630 | training loss: 5.4879e-04 | validation loss: 1.0366e-04\n",
      "Epoch: 49640 | training loss: 5.4877e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 49650 | training loss: 5.4874e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 49660 | training loss: 5.4872e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 49670 | training loss: 5.4869e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 49680 | training loss: 5.4867e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 49690 | training loss: 5.4865e-04 | validation loss: 1.0367e-04\n",
      "Epoch: 49700 | training loss: 5.4952e-04 | validation loss: 1.0445e-04\n",
      "Epoch: 49710 | training loss: 5.5845e-04 | validation loss: 1.1033e-04\n",
      "Epoch: 49720 | training loss: 5.5226e-04 | validation loss: 1.0742e-04\n",
      "Epoch: 49730 | training loss: 5.4950e-04 | validation loss: 1.0541e-04\n",
      "Epoch: 49740 | training loss: 5.4901e-04 | validation loss: 1.0480e-04\n",
      "Epoch: 49750 | training loss: 5.4868e-04 | validation loss: 1.0425e-04\n",
      "Epoch: 49760 | training loss: 5.4851e-04 | validation loss: 1.0384e-04\n",
      "Epoch: 49770 | training loss: 5.4847e-04 | validation loss: 1.0368e-04\n",
      "Epoch: 49780 | training loss: 5.4844e-04 | validation loss: 1.0364e-04\n",
      "Epoch: 49790 | training loss: 5.4842e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 49800 | training loss: 5.4839e-04 | validation loss: 1.0364e-04\n",
      "Epoch: 49810 | training loss: 5.4837e-04 | validation loss: 1.0363e-04\n",
      "Epoch: 49820 | training loss: 5.4835e-04 | validation loss: 1.0364e-04\n",
      "Epoch: 49830 | training loss: 5.4832e-04 | validation loss: 1.0363e-04\n",
      "Epoch: 49840 | training loss: 5.4830e-04 | validation loss: 1.0362e-04\n",
      "Epoch: 49850 | training loss: 5.4828e-04 | validation loss: 1.0362e-04\n",
      "Epoch: 49860 | training loss: 5.4825e-04 | validation loss: 1.0362e-04\n",
      "Epoch: 49870 | training loss: 5.4823e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 49880 | training loss: 5.4821e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 49890 | training loss: 5.4818e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 49900 | training loss: 5.4816e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 49910 | training loss: 5.4813e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 49920 | training loss: 5.4811e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 49930 | training loss: 5.4809e-04 | validation loss: 1.0363e-04\n",
      "Epoch: 49940 | training loss: 5.4854e-04 | validation loss: 1.0421e-04\n",
      "Epoch: 49950 | training loss: 5.6436e-04 | validation loss: 1.1588e-04\n",
      "Epoch: 49960 | training loss: 5.4975e-04 | validation loss: 1.0536e-04\n",
      "Epoch: 49970 | training loss: 5.4800e-04 | validation loss: 1.0367e-04\n",
      "Epoch: 49980 | training loss: 5.4816e-04 | validation loss: 1.0344e-04\n",
      "Epoch: 49990 | training loss: 5.4816e-04 | validation loss: 1.0345e-04\n",
      "Epoch: 50000 | training loss: 5.4800e-04 | validation loss: 1.0349e-04\n",
      "Epoch: 50010 | training loss: 5.4791e-04 | validation loss: 1.0354e-04\n",
      "Epoch: 50020 | training loss: 5.4789e-04 | validation loss: 1.0359e-04\n",
      "Epoch: 50030 | training loss: 5.4786e-04 | validation loss: 1.0359e-04\n",
      "Epoch: 50040 | training loss: 5.4784e-04 | validation loss: 1.0359e-04\n",
      "Epoch: 50050 | training loss: 5.4781e-04 | validation loss: 1.0359e-04\n",
      "Epoch: 50060 | training loss: 5.4779e-04 | validation loss: 1.0358e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50070 | training loss: 5.4777e-04 | validation loss: 1.0358e-04\n",
      "Epoch: 50080 | training loss: 5.4775e-04 | validation loss: 1.0358e-04\n",
      "Epoch: 50090 | training loss: 5.4772e-04 | validation loss: 1.0358e-04\n",
      "Epoch: 50100 | training loss: 5.4770e-04 | validation loss: 1.0358e-04\n",
      "Epoch: 50110 | training loss: 5.4768e-04 | validation loss: 1.0358e-04\n",
      "Epoch: 50120 | training loss: 5.4765e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 50130 | training loss: 5.4763e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 50140 | training loss: 5.4761e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 50150 | training loss: 5.4758e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 50160 | training loss: 5.4756e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 50170 | training loss: 5.4753e-04 | validation loss: 1.0356e-04\n",
      "Epoch: 50180 | training loss: 5.4751e-04 | validation loss: 1.0356e-04\n",
      "Epoch: 50190 | training loss: 5.4749e-04 | validation loss: 1.0356e-04\n",
      "Epoch: 50200 | training loss: 5.4765e-04 | validation loss: 1.0372e-04\n",
      "Epoch: 50210 | training loss: 5.7040e-04 | validation loss: 1.2051e-04\n",
      "Epoch: 50220 | training loss: 5.4745e-04 | validation loss: 1.0380e-04\n",
      "Epoch: 50230 | training loss: 5.4749e-04 | validation loss: 1.0386e-04\n",
      "Epoch: 50240 | training loss: 5.4741e-04 | validation loss: 1.0379e-04\n",
      "Epoch: 50250 | training loss: 5.4737e-04 | validation loss: 1.0369e-04\n",
      "Epoch: 50260 | training loss: 5.4734e-04 | validation loss: 1.0362e-04\n",
      "Epoch: 50270 | training loss: 5.4732e-04 | validation loss: 1.0355e-04\n",
      "Epoch: 50280 | training loss: 5.4729e-04 | validation loss: 1.0351e-04\n",
      "Epoch: 50290 | training loss: 5.4727e-04 | validation loss: 1.0350e-04\n",
      "Epoch: 50300 | training loss: 5.4724e-04 | validation loss: 1.0353e-04\n",
      "Epoch: 50310 | training loss: 5.4722e-04 | validation loss: 1.0355e-04\n",
      "Epoch: 50320 | training loss: 5.4720e-04 | validation loss: 1.0355e-04\n",
      "Epoch: 50330 | training loss: 5.4717e-04 | validation loss: 1.0354e-04\n",
      "Epoch: 50340 | training loss: 5.4715e-04 | validation loss: 1.0354e-04\n",
      "Epoch: 50350 | training loss: 5.4713e-04 | validation loss: 1.0354e-04\n",
      "Epoch: 50360 | training loss: 5.4710e-04 | validation loss: 1.0353e-04\n",
      "Epoch: 50370 | training loss: 5.4708e-04 | validation loss: 1.0353e-04\n",
      "Epoch: 50380 | training loss: 5.4706e-04 | validation loss: 1.0353e-04\n",
      "Epoch: 50390 | training loss: 5.4704e-04 | validation loss: 1.0353e-04\n",
      "Epoch: 50400 | training loss: 5.4701e-04 | validation loss: 1.0353e-04\n",
      "Epoch: 50410 | training loss: 5.4699e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 50420 | training loss: 5.4696e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 50430 | training loss: 5.4694e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 50440 | training loss: 5.4692e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 50450 | training loss: 5.4689e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 50460 | training loss: 5.4687e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 50470 | training loss: 5.4685e-04 | validation loss: 1.0355e-04\n",
      "Epoch: 50480 | training loss: 5.4695e-04 | validation loss: 1.0405e-04\n",
      "Epoch: 50490 | training loss: 5.4864e-04 | validation loss: 1.0586e-04\n",
      "Epoch: 50500 | training loss: 5.5294e-04 | validation loss: 1.0916e-04\n",
      "Epoch: 50510 | training loss: 5.4717e-04 | validation loss: 1.0403e-04\n",
      "Epoch: 50520 | training loss: 5.4698e-04 | validation loss: 1.0333e-04\n",
      "Epoch: 50530 | training loss: 5.4702e-04 | validation loss: 1.0339e-04\n",
      "Epoch: 50540 | training loss: 5.4677e-04 | validation loss: 1.0355e-04\n",
      "Epoch: 50550 | training loss: 5.4668e-04 | validation loss: 1.0358e-04\n",
      "Epoch: 50560 | training loss: 5.4665e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 50570 | training loss: 5.4662e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 50580 | training loss: 5.4660e-04 | validation loss: 1.0350e-04\n",
      "Epoch: 50590 | training loss: 5.4657e-04 | validation loss: 1.0349e-04\n",
      "Epoch: 50600 | training loss: 5.4655e-04 | validation loss: 1.0348e-04\n",
      "Epoch: 50610 | training loss: 5.4653e-04 | validation loss: 1.0348e-04\n",
      "Epoch: 50620 | training loss: 5.4650e-04 | validation loss: 1.0348e-04\n",
      "Epoch: 50630 | training loss: 5.4648e-04 | validation loss: 1.0349e-04\n",
      "Epoch: 50640 | training loss: 5.4655e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 50650 | training loss: 5.5186e-04 | validation loss: 1.0758e-04\n",
      "Epoch: 50660 | training loss: 5.4848e-04 | validation loss: 1.0490e-04\n",
      "Epoch: 50670 | training loss: 5.4810e-04 | validation loss: 1.0477e-04\n",
      "Epoch: 50680 | training loss: 5.4656e-04 | validation loss: 1.0363e-04\n",
      "Epoch: 50690 | training loss: 5.4656e-04 | validation loss: 1.0362e-04\n",
      "Epoch: 50700 | training loss: 5.4633e-04 | validation loss: 1.0348e-04\n",
      "Epoch: 50710 | training loss: 5.4634e-04 | validation loss: 1.0351e-04\n",
      "Epoch: 50720 | training loss: 5.4628e-04 | validation loss: 1.0347e-04\n",
      "Epoch: 50730 | training loss: 5.4625e-04 | validation loss: 1.0347e-04\n",
      "Epoch: 50740 | training loss: 5.4623e-04 | validation loss: 1.0347e-04\n",
      "Epoch: 50750 | training loss: 5.4621e-04 | validation loss: 1.0347e-04\n",
      "Epoch: 50760 | training loss: 5.4619e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 50770 | training loss: 5.4616e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 50780 | training loss: 5.4614e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 50790 | training loss: 5.4612e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 50800 | training loss: 5.4609e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 50810 | training loss: 5.4607e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 50820 | training loss: 5.4605e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 50830 | training loss: 5.4604e-04 | validation loss: 1.0347e-04\n",
      "Epoch: 50840 | training loss: 5.4705e-04 | validation loss: 1.0426e-04\n",
      "Epoch: 50850 | training loss: 5.5419e-04 | validation loss: 1.0951e-04\n",
      "Epoch: 50860 | training loss: 5.4730e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 50870 | training loss: 5.4624e-04 | validation loss: 1.0368e-04\n",
      "Epoch: 50880 | training loss: 5.4641e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 50890 | training loss: 5.4592e-04 | validation loss: 1.0347e-04\n",
      "Epoch: 50900 | training loss: 5.4591e-04 | validation loss: 1.0348e-04\n",
      "Epoch: 50910 | training loss: 5.4585e-04 | validation loss: 1.0344e-04\n",
      "Epoch: 50920 | training loss: 5.4583e-04 | validation loss: 1.0344e-04\n",
      "Epoch: 50930 | training loss: 5.4580e-04 | validation loss: 1.0344e-04\n",
      "Epoch: 50940 | training loss: 5.4578e-04 | validation loss: 1.0344e-04\n",
      "Epoch: 50950 | training loss: 5.4576e-04 | validation loss: 1.0343e-04\n",
      "Epoch: 50960 | training loss: 5.4573e-04 | validation loss: 1.0343e-04\n",
      "Epoch: 50970 | training loss: 5.4571e-04 | validation loss: 1.0343e-04\n",
      "Epoch: 50980 | training loss: 5.4569e-04 | validation loss: 1.0343e-04\n",
      "Epoch: 50990 | training loss: 5.4567e-04 | validation loss: 1.0343e-04\n",
      "Epoch: 51000 | training loss: 5.4564e-04 | validation loss: 1.0343e-04\n",
      "Epoch: 51010 | training loss: 5.4562e-04 | validation loss: 1.0342e-04\n",
      "Epoch: 51020 | training loss: 5.4560e-04 | validation loss: 1.0342e-04\n",
      "Epoch: 51030 | training loss: 5.4557e-04 | validation loss: 1.0342e-04\n",
      "Epoch: 51040 | training loss: 5.4555e-04 | validation loss: 1.0342e-04\n",
      "Epoch: 51050 | training loss: 5.4553e-04 | validation loss: 1.0342e-04\n",
      "Epoch: 51060 | training loss: 5.4558e-04 | validation loss: 1.0349e-04\n",
      "Epoch: 51070 | training loss: 5.5603e-04 | validation loss: 1.1125e-04\n",
      "Epoch: 51080 | training loss: 5.5398e-04 | validation loss: 1.0948e-04\n",
      "Epoch: 51090 | training loss: 5.4744e-04 | validation loss: 1.0467e-04\n",
      "Epoch: 51100 | training loss: 5.4568e-04 | validation loss: 1.0350e-04\n",
      "Epoch: 51110 | training loss: 5.4539e-04 | validation loss: 1.0341e-04\n",
      "Epoch: 51120 | training loss: 5.4541e-04 | validation loss: 1.0345e-04\n",
      "Epoch: 51130 | training loss: 5.4539e-04 | validation loss: 1.0345e-04\n",
      "Epoch: 51140 | training loss: 5.4534e-04 | validation loss: 1.0343e-04\n",
      "Epoch: 51150 | training loss: 5.4531e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51160 | training loss: 5.4529e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51170 | training loss: 5.4526e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51180 | training loss: 5.4524e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51190 | training loss: 5.4522e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51200 | training loss: 5.4519e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51210 | training loss: 5.4517e-04 | validation loss: 1.0339e-04\n",
      "Epoch: 51220 | training loss: 5.4515e-04 | validation loss: 1.0339e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51230 | training loss: 5.4513e-04 | validation loss: 1.0339e-04\n",
      "Epoch: 51240 | training loss: 5.4510e-04 | validation loss: 1.0338e-04\n",
      "Epoch: 51250 | training loss: 5.4509e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 51260 | training loss: 5.4630e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 51270 | training loss: 5.4601e-04 | validation loss: 1.0524e-04\n",
      "Epoch: 51280 | training loss: 5.4512e-04 | validation loss: 1.0385e-04\n",
      "Epoch: 51290 | training loss: 5.4500e-04 | validation loss: 1.0329e-04\n",
      "Epoch: 51300 | training loss: 5.4500e-04 | validation loss: 1.0317e-04\n",
      "Epoch: 51310 | training loss: 5.4495e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 51320 | training loss: 5.4493e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51330 | training loss: 5.4515e-04 | validation loss: 1.0364e-04\n",
      "Epoch: 51340 | training loss: 5.5619e-04 | validation loss: 1.1183e-04\n",
      "Epoch: 51350 | training loss: 5.4977e-04 | validation loss: 1.0690e-04\n",
      "Epoch: 51360 | training loss: 5.4487e-04 | validation loss: 1.0338e-04\n",
      "Epoch: 51370 | training loss: 5.4539e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 51380 | training loss: 5.4480e-04 | validation loss: 1.0336e-04\n",
      "Epoch: 51390 | training loss: 5.4485e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 51400 | training loss: 5.4475e-04 | validation loss: 1.0336e-04\n",
      "Epoch: 51410 | training loss: 5.4473e-04 | validation loss: 1.0336e-04\n",
      "Epoch: 51420 | training loss: 5.4470e-04 | validation loss: 1.0336e-04\n",
      "Epoch: 51430 | training loss: 5.4468e-04 | validation loss: 1.0336e-04\n",
      "Epoch: 51440 | training loss: 5.4466e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51450 | training loss: 5.4463e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51460 | training loss: 5.4461e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51470 | training loss: 5.4459e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51480 | training loss: 5.4457e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51490 | training loss: 5.4454e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51500 | training loss: 5.4452e-04 | validation loss: 1.0334e-04\n",
      "Epoch: 51510 | training loss: 5.4450e-04 | validation loss: 1.0334e-04\n",
      "Epoch: 51520 | training loss: 5.4447e-04 | validation loss: 1.0334e-04\n",
      "Epoch: 51530 | training loss: 5.4446e-04 | validation loss: 1.0334e-04\n",
      "Epoch: 51540 | training loss: 5.4589e-04 | validation loss: 1.0435e-04\n",
      "Epoch: 51550 | training loss: 5.4661e-04 | validation loss: 1.0492e-04\n",
      "Epoch: 51560 | training loss: 5.4866e-04 | validation loss: 1.0637e-04\n",
      "Epoch: 51570 | training loss: 5.4602e-04 | validation loss: 1.0442e-04\n",
      "Epoch: 51580 | training loss: 5.4488e-04 | validation loss: 1.0359e-04\n",
      "Epoch: 51590 | training loss: 5.4445e-04 | validation loss: 1.0334e-04\n",
      "Epoch: 51600 | training loss: 5.4431e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51610 | training loss: 5.4428e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51620 | training loss: 5.4427e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 51630 | training loss: 5.4424e-04 | validation loss: 1.0333e-04\n",
      "Epoch: 51640 | training loss: 5.4421e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51650 | training loss: 5.4419e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51660 | training loss: 5.4417e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51670 | training loss: 5.4415e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51680 | training loss: 5.4413e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51690 | training loss: 5.4410e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51700 | training loss: 5.4408e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51710 | training loss: 5.4406e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51720 | training loss: 5.4404e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51730 | training loss: 5.4401e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51740 | training loss: 5.4399e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51750 | training loss: 5.4397e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51760 | training loss: 5.4395e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51770 | training loss: 5.4392e-04 | validation loss: 1.0334e-04\n",
      "Epoch: 51780 | training loss: 5.4405e-04 | validation loss: 1.0389e-04\n",
      "Epoch: 51790 | training loss: 5.4426e-04 | validation loss: 1.0430e-04\n",
      "Epoch: 51800 | training loss: 5.4480e-04 | validation loss: 1.0491e-04\n",
      "Epoch: 51810 | training loss: 5.4798e-04 | validation loss: 1.0690e-04\n",
      "Epoch: 51820 | training loss: 5.4394e-04 | validation loss: 1.0378e-04\n",
      "Epoch: 51830 | training loss: 5.4381e-04 | validation loss: 1.0349e-04\n",
      "Epoch: 51840 | training loss: 5.4381e-04 | validation loss: 1.0337e-04\n",
      "Epoch: 51850 | training loss: 5.4383e-04 | validation loss: 1.0338e-04\n",
      "Epoch: 51860 | training loss: 5.4377e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51870 | training loss: 5.4370e-04 | validation loss: 1.0329e-04\n",
      "Epoch: 51880 | training loss: 5.4369e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 51890 | training loss: 5.4368e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 51900 | training loss: 5.4381e-04 | validation loss: 1.0344e-04\n",
      "Epoch: 51910 | training loss: 5.4650e-04 | validation loss: 1.0550e-04\n",
      "Epoch: 51920 | training loss: 5.4403e-04 | validation loss: 1.0362e-04\n",
      "Epoch: 51930 | training loss: 5.4361e-04 | validation loss: 1.0329e-04\n",
      "Epoch: 51940 | training loss: 5.4355e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 51950 | training loss: 5.4353e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 51960 | training loss: 5.4351e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 51970 | training loss: 5.4349e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 51980 | training loss: 5.4347e-04 | validation loss: 1.0328e-04\n",
      "Epoch: 51990 | training loss: 5.4344e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 52000 | training loss: 5.4342e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 52010 | training loss: 5.4340e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 52020 | training loss: 5.4346e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 52030 | training loss: 5.4568e-04 | validation loss: 1.0488e-04\n",
      "Epoch: 52040 | training loss: 5.4468e-04 | validation loss: 1.0420e-04\n",
      "Epoch: 52050 | training loss: 5.4331e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 52060 | training loss: 5.4362e-04 | validation loss: 1.0352e-04\n",
      "Epoch: 52070 | training loss: 5.4350e-04 | validation loss: 1.0341e-04\n",
      "Epoch: 52080 | training loss: 5.4333e-04 | validation loss: 1.0333e-04\n",
      "Epoch: 52090 | training loss: 5.4325e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 52100 | training loss: 5.4321e-04 | validation loss: 1.0327e-04\n",
      "Epoch: 52110 | training loss: 5.4318e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 52120 | training loss: 5.4315e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 52130 | training loss: 5.4313e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 52140 | training loss: 5.4311e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 52150 | training loss: 5.4308e-04 | validation loss: 1.0324e-04\n",
      "Epoch: 52160 | training loss: 5.4306e-04 | validation loss: 1.0324e-04\n",
      "Epoch: 52170 | training loss: 5.4308e-04 | validation loss: 1.0326e-04\n",
      "Epoch: 52180 | training loss: 5.4583e-04 | validation loss: 1.0521e-04\n",
      "Epoch: 52190 | training loss: 5.4307e-04 | validation loss: 1.0329e-04\n",
      "Epoch: 52200 | training loss: 5.4562e-04 | validation loss: 1.0509e-04\n",
      "Epoch: 52210 | training loss: 5.4296e-04 | validation loss: 1.0319e-04\n",
      "Epoch: 52220 | training loss: 5.4328e-04 | validation loss: 1.0351e-04\n",
      "Epoch: 52230 | training loss: 5.4291e-04 | validation loss: 1.0326e-04\n",
      "Epoch: 52240 | training loss: 5.4293e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 52250 | training loss: 5.4287e-04 | validation loss: 1.0323e-04\n",
      "Epoch: 52260 | training loss: 5.4285e-04 | validation loss: 1.0324e-04\n",
      "Epoch: 52270 | training loss: 5.4283e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52280 | training loss: 5.4280e-04 | validation loss: 1.0323e-04\n",
      "Epoch: 52290 | training loss: 5.4278e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52300 | training loss: 5.4276e-04 | validation loss: 1.0323e-04\n",
      "Epoch: 52310 | training loss: 5.4274e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52320 | training loss: 5.4271e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52330 | training loss: 5.4269e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52340 | training loss: 5.4267e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52350 | training loss: 5.4265e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52360 | training loss: 5.4262e-04 | validation loss: 1.0323e-04\n",
      "Epoch: 52370 | training loss: 5.4261e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 52380 | training loss: 5.4371e-04 | validation loss: 1.0487e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52390 | training loss: 5.5446e-04 | validation loss: 1.1056e-04\n",
      "Epoch: 52400 | training loss: 5.4465e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 52410 | training loss: 5.4308e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 52420 | training loss: 5.4284e-04 | validation loss: 1.0393e-04\n",
      "Epoch: 52430 | training loss: 5.4250e-04 | validation loss: 1.0336e-04\n",
      "Epoch: 52440 | training loss: 5.4251e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 52450 | training loss: 5.4245e-04 | validation loss: 1.0314e-04\n",
      "Epoch: 52460 | training loss: 5.4241e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52470 | training loss: 5.4239e-04 | validation loss: 1.0323e-04\n",
      "Epoch: 52480 | training loss: 5.4237e-04 | validation loss: 1.0321e-04\n",
      "Epoch: 52490 | training loss: 5.4235e-04 | validation loss: 1.0319e-04\n",
      "Epoch: 52500 | training loss: 5.4233e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52510 | training loss: 5.4230e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52520 | training loss: 5.4228e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52530 | training loss: 5.4226e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52540 | training loss: 5.4224e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52550 | training loss: 5.4222e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52560 | training loss: 5.4220e-04 | validation loss: 1.0319e-04\n",
      "Epoch: 52570 | training loss: 5.4258e-04 | validation loss: 1.0354e-04\n",
      "Epoch: 52580 | training loss: 5.6143e-04 | validation loss: 1.1755e-04\n",
      "Epoch: 52590 | training loss: 5.4236e-04 | validation loss: 1.0337e-04\n",
      "Epoch: 52600 | training loss: 5.4247e-04 | validation loss: 1.0337e-04\n",
      "Epoch: 52610 | training loss: 5.4257e-04 | validation loss: 1.0347e-04\n",
      "Epoch: 52620 | training loss: 5.4233e-04 | validation loss: 1.0333e-04\n",
      "Epoch: 52630 | training loss: 5.4210e-04 | validation loss: 1.0320e-04\n",
      "Epoch: 52640 | training loss: 5.4203e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52650 | training loss: 5.4202e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 52660 | training loss: 5.4199e-04 | validation loss: 1.0317e-04\n",
      "Epoch: 52670 | training loss: 5.4197e-04 | validation loss: 1.0317e-04\n",
      "Epoch: 52680 | training loss: 5.4195e-04 | validation loss: 1.0317e-04\n",
      "Epoch: 52690 | training loss: 5.4193e-04 | validation loss: 1.0317e-04\n",
      "Epoch: 52700 | training loss: 5.4191e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52710 | training loss: 5.4188e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52720 | training loss: 5.4186e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52730 | training loss: 5.4184e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52740 | training loss: 5.4182e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52750 | training loss: 5.4180e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52760 | training loss: 5.4178e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52770 | training loss: 5.4176e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 52780 | training loss: 5.4173e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 52790 | training loss: 5.4171e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 52800 | training loss: 5.4169e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 52810 | training loss: 5.4167e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 52820 | training loss: 5.4165e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 52830 | training loss: 5.4168e-04 | validation loss: 1.0320e-04\n",
      "Epoch: 52840 | training loss: 5.5315e-04 | validation loss: 1.1179e-04\n",
      "Epoch: 52850 | training loss: 5.5114e-04 | validation loss: 1.1000e-04\n",
      "Epoch: 52860 | training loss: 5.4506e-04 | validation loss: 1.0562e-04\n",
      "Epoch: 52870 | training loss: 5.4272e-04 | validation loss: 1.0395e-04\n",
      "Epoch: 52880 | training loss: 5.4192e-04 | validation loss: 1.0340e-04\n",
      "Epoch: 52890 | training loss: 5.4164e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 52900 | training loss: 5.4154e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 52910 | training loss: 5.4148e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 52920 | training loss: 5.4145e-04 | validation loss: 1.0311e-04\n",
      "Epoch: 52930 | training loss: 5.4142e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 52940 | training loss: 5.4140e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 52950 | training loss: 5.4138e-04 | validation loss: 1.0314e-04\n",
      "Epoch: 52960 | training loss: 5.4136e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 52970 | training loss: 5.4134e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 52980 | training loss: 5.4132e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 52990 | training loss: 5.4130e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 53000 | training loss: 5.4128e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 53010 | training loss: 5.4125e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 53020 | training loss: 5.4123e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 53030 | training loss: 5.4121e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 53040 | training loss: 5.4119e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 53050 | training loss: 5.4117e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 53060 | training loss: 5.4115e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 53070 | training loss: 5.4113e-04 | validation loss: 1.0311e-04\n",
      "Epoch: 53080 | training loss: 5.4110e-04 | validation loss: 1.0311e-04\n",
      "Epoch: 53090 | training loss: 5.4108e-04 | validation loss: 1.0311e-04\n",
      "Epoch: 53100 | training loss: 5.4106e-04 | validation loss: 1.0311e-04\n",
      "Epoch: 53110 | training loss: 5.4104e-04 | validation loss: 1.0311e-04\n",
      "Epoch: 53120 | training loss: 5.4102e-04 | validation loss: 1.0310e-04\n",
      "Epoch: 53130 | training loss: 5.4100e-04 | validation loss: 1.0302e-04\n",
      "Epoch: 53140 | training loss: 5.4253e-04 | validation loss: 1.0250e-04\n",
      "Epoch: 53150 | training loss: 5.4803e-04 | validation loss: 1.0980e-04\n",
      "Epoch: 53160 | training loss: 5.4485e-04 | validation loss: 1.0637e-04\n",
      "Epoch: 53170 | training loss: 5.4174e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 53180 | training loss: 5.4175e-04 | validation loss: 1.0388e-04\n",
      "Epoch: 53190 | training loss: 5.4103e-04 | validation loss: 1.0338e-04\n",
      "Epoch: 53200 | training loss: 5.4089e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 53210 | training loss: 5.4087e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 53220 | training loss: 5.4081e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 53230 | training loss: 5.4079e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53240 | training loss: 5.4077e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53250 | training loss: 5.4075e-04 | validation loss: 1.0309e-04\n",
      "Epoch: 53260 | training loss: 5.4073e-04 | validation loss: 1.0309e-04\n",
      "Epoch: 53270 | training loss: 5.4071e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 53280 | training loss: 5.4069e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 53290 | training loss: 5.4067e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 53300 | training loss: 5.4065e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 53310 | training loss: 5.4062e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 53320 | training loss: 5.4060e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53330 | training loss: 5.4058e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53340 | training loss: 5.4056e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53350 | training loss: 5.4054e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53360 | training loss: 5.4052e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53370 | training loss: 5.4050e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 53380 | training loss: 5.4139e-04 | validation loss: 1.0379e-04\n",
      "Epoch: 53390 | training loss: 5.4950e-04 | validation loss: 1.0981e-04\n",
      "Epoch: 53400 | training loss: 5.4584e-04 | validation loss: 1.0714e-04\n",
      "Epoch: 53410 | training loss: 5.4206e-04 | validation loss: 1.0432e-04\n",
      "Epoch: 53420 | training loss: 5.4087e-04 | validation loss: 1.0344e-04\n",
      "Epoch: 53430 | training loss: 5.4048e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 53440 | training loss: 5.4036e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 53450 | training loss: 5.4034e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 53460 | training loss: 5.4033e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 53470 | training loss: 5.4030e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 53480 | training loss: 5.4028e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 53490 | training loss: 5.4026e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 53500 | training loss: 5.4024e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 53510 | training loss: 5.4022e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 53520 | training loss: 5.4020e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 53530 | training loss: 5.4018e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 53540 | training loss: 5.4016e-04 | validation loss: 1.0305e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53550 | training loss: 5.4013e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 53560 | training loss: 5.4011e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 53570 | training loss: 5.4009e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53580 | training loss: 5.4007e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53590 | training loss: 5.4005e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53600 | training loss: 5.4003e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53610 | training loss: 5.4001e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53620 | training loss: 5.3999e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53630 | training loss: 5.3997e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53640 | training loss: 5.3994e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 53650 | training loss: 5.3992e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 53660 | training loss: 5.3991e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 53670 | training loss: 5.4143e-04 | validation loss: 1.0408e-04\n",
      "Epoch: 53680 | training loss: 5.3996e-04 | validation loss: 1.0310e-04\n",
      "Epoch: 53690 | training loss: 5.4016e-04 | validation loss: 1.0328e-04\n",
      "Epoch: 53700 | training loss: 5.3989e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 53710 | training loss: 5.4009e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 53720 | training loss: 5.3999e-04 | validation loss: 1.0325e-04\n",
      "Epoch: 53730 | training loss: 5.3985e-04 | validation loss: 1.0314e-04\n",
      "Epoch: 53740 | training loss: 5.3978e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 53750 | training loss: 5.3974e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 53760 | training loss: 5.3971e-04 | validation loss: 1.0304e-04\n",
      "Epoch: 53770 | training loss: 5.3969e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 53780 | training loss: 5.3967e-04 | validation loss: 1.0302e-04\n",
      "Epoch: 53790 | training loss: 5.3965e-04 | validation loss: 1.0302e-04\n",
      "Epoch: 53800 | training loss: 5.3963e-04 | validation loss: 1.0302e-04\n",
      "Epoch: 53810 | training loss: 5.3961e-04 | validation loss: 1.0302e-04\n",
      "Epoch: 53820 | training loss: 5.3959e-04 | validation loss: 1.0301e-04\n",
      "Epoch: 53830 | training loss: 5.3957e-04 | validation loss: 1.0301e-04\n",
      "Epoch: 53840 | training loss: 5.3954e-04 | validation loss: 1.0301e-04\n",
      "Epoch: 53850 | training loss: 5.3952e-04 | validation loss: 1.0301e-04\n",
      "Epoch: 53860 | training loss: 5.3950e-04 | validation loss: 1.0301e-04\n",
      "Epoch: 53870 | training loss: 5.3948e-04 | validation loss: 1.0301e-04\n",
      "Epoch: 53880 | training loss: 5.3946e-04 | validation loss: 1.0301e-04\n",
      "Epoch: 53890 | training loss: 5.3944e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53900 | training loss: 5.3942e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53910 | training loss: 5.3940e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53920 | training loss: 5.3938e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53930 | training loss: 5.3936e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53940 | training loss: 5.3934e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53950 | training loss: 5.3932e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53960 | training loss: 5.3929e-04 | validation loss: 1.0299e-04\n",
      "Epoch: 53970 | training loss: 5.3927e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 53980 | training loss: 5.3925e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 53990 | training loss: 5.4116e-04 | validation loss: 1.0598e-04\n",
      "Epoch: 54000 | training loss: 5.3997e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 54010 | training loss: 5.3962e-04 | validation loss: 1.0297e-04\n",
      "Epoch: 54020 | training loss: 5.5311e-04 | validation loss: 1.1335e-04\n",
      "Epoch: 54030 | training loss: 5.4146e-04 | validation loss: 1.0506e-04\n",
      "Epoch: 54040 | training loss: 5.4013e-04 | validation loss: 1.0357e-04\n",
      "Epoch: 54050 | training loss: 5.3922e-04 | validation loss: 1.0302e-04\n",
      "Epoch: 54060 | training loss: 5.3927e-04 | validation loss: 1.0316e-04\n",
      "Epoch: 54070 | training loss: 5.3909e-04 | validation loss: 1.0297e-04\n",
      "Epoch: 54080 | training loss: 5.3906e-04 | validation loss: 1.0296e-04\n",
      "Epoch: 54090 | training loss: 5.3904e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 54100 | training loss: 5.3901e-04 | validation loss: 1.0299e-04\n",
      "Epoch: 54110 | training loss: 5.3899e-04 | validation loss: 1.0297e-04\n",
      "Epoch: 54120 | training loss: 5.3897e-04 | validation loss: 1.0296e-04\n",
      "Epoch: 54130 | training loss: 5.3895e-04 | validation loss: 1.0297e-04\n",
      "Epoch: 54140 | training loss: 5.3893e-04 | validation loss: 1.0297e-04\n",
      "Epoch: 54150 | training loss: 5.3891e-04 | validation loss: 1.0297e-04\n",
      "Epoch: 54160 | training loss: 5.3889e-04 | validation loss: 1.0296e-04\n",
      "Epoch: 54170 | training loss: 5.3887e-04 | validation loss: 1.0296e-04\n",
      "Epoch: 54180 | training loss: 5.3885e-04 | validation loss: 1.0296e-04\n",
      "Epoch: 54190 | training loss: 5.3883e-04 | validation loss: 1.0296e-04\n",
      "Epoch: 54200 | training loss: 5.3880e-04 | validation loss: 1.0296e-04\n",
      "Epoch: 54210 | training loss: 5.3880e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 54220 | training loss: 5.4013e-04 | validation loss: 1.0406e-04\n",
      "Epoch: 54230 | training loss: 5.4277e-04 | validation loss: 1.0600e-04\n",
      "Epoch: 54240 | training loss: 5.4309e-04 | validation loss: 1.0627e-04\n",
      "Epoch: 54250 | training loss: 5.3951e-04 | validation loss: 1.0359e-04\n",
      "Epoch: 54260 | training loss: 5.3871e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 54270 | training loss: 5.3871e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 54280 | training loss: 5.3871e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 54290 | training loss: 5.3864e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 54300 | training loss: 5.3861e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 54310 | training loss: 5.3859e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 54320 | training loss: 5.3857e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 54330 | training loss: 5.3855e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 54340 | training loss: 5.3853e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 54350 | training loss: 5.3851e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54360 | training loss: 5.3849e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54370 | training loss: 5.3847e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54380 | training loss: 5.3845e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54390 | training loss: 5.3843e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54400 | training loss: 5.3841e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54410 | training loss: 5.3839e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54420 | training loss: 5.3837e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54430 | training loss: 5.3835e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 54440 | training loss: 5.3832e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 54450 | training loss: 5.3830e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 54460 | training loss: 5.3828e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 54470 | training loss: 5.3826e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 54480 | training loss: 5.3867e-04 | validation loss: 1.0329e-04\n",
      "Epoch: 54490 | training loss: 5.6065e-04 | validation loss: 1.1962e-04\n",
      "Epoch: 54500 | training loss: 5.4490e-04 | validation loss: 1.0802e-04\n",
      "Epoch: 54510 | training loss: 5.4068e-04 | validation loss: 1.0485e-04\n",
      "Epoch: 54520 | training loss: 5.3903e-04 | validation loss: 1.0362e-04\n",
      "Epoch: 54530 | training loss: 5.3841e-04 | validation loss: 1.0314e-04\n",
      "Epoch: 54540 | training loss: 5.3820e-04 | validation loss: 1.0299e-04\n",
      "Epoch: 54550 | training loss: 5.3813e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 54560 | training loss: 5.3810e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54570 | training loss: 5.3807e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54580 | training loss: 5.3805e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 54590 | training loss: 5.3803e-04 | validation loss: 1.0292e-04\n",
      "Epoch: 54600 | training loss: 5.3801e-04 | validation loss: 1.0292e-04\n",
      "Epoch: 54610 | training loss: 5.3799e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54620 | training loss: 5.3797e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54630 | training loss: 5.3795e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54640 | training loss: 5.3793e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54650 | training loss: 5.3791e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54660 | training loss: 5.3789e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54670 | training loss: 5.3787e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54680 | training loss: 5.3785e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54690 | training loss: 5.3783e-04 | validation loss: 1.0291e-04\n",
      "Epoch: 54700 | training loss: 5.3781e-04 | validation loss: 1.0290e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54710 | training loss: 5.3779e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54720 | training loss: 5.3777e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54730 | training loss: 5.3775e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54740 | training loss: 5.3773e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54750 | training loss: 5.3771e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54760 | training loss: 5.3769e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54770 | training loss: 5.3767e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54780 | training loss: 5.3765e-04 | validation loss: 1.0290e-04\n",
      "Epoch: 54790 | training loss: 5.3764e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 54800 | training loss: 5.4068e-04 | validation loss: 1.0706e-04\n",
      "Epoch: 54810 | training loss: 5.3804e-04 | validation loss: 1.0309e-04\n",
      "Epoch: 54820 | training loss: 5.5493e-04 | validation loss: 1.1604e-04\n",
      "Epoch: 54830 | training loss: 5.3788e-04 | validation loss: 1.0380e-04\n",
      "Epoch: 54840 | training loss: 5.3841e-04 | validation loss: 1.0331e-04\n",
      "Epoch: 54850 | training loss: 5.3817e-04 | validation loss: 1.0307e-04\n",
      "Epoch: 54860 | training loss: 5.3760e-04 | validation loss: 1.0306e-04\n",
      "Epoch: 54870 | training loss: 5.3747e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 54880 | training loss: 5.3748e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 54890 | training loss: 5.3743e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 54900 | training loss: 5.3741e-04 | validation loss: 1.0289e-04\n",
      "Epoch: 54910 | training loss: 5.3739e-04 | validation loss: 1.0289e-04\n",
      "Epoch: 54920 | training loss: 5.3737e-04 | validation loss: 1.0288e-04\n",
      "Epoch: 54930 | training loss: 5.3735e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 54940 | training loss: 5.3733e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 54950 | training loss: 5.3731e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 54960 | training loss: 5.3729e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 54970 | training loss: 5.3727e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 54980 | training loss: 5.3725e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 54990 | training loss: 5.3723e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 55000 | training loss: 5.3721e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 55010 | training loss: 5.3719e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 55020 | training loss: 5.3717e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 55030 | training loss: 5.3715e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 55040 | training loss: 5.3713e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 55050 | training loss: 5.3713e-04 | validation loss: 1.0288e-04\n",
      "Epoch: 55060 | training loss: 5.3953e-04 | validation loss: 1.0476e-04\n",
      "Epoch: 55070 | training loss: 5.3731e-04 | validation loss: 1.0295e-04\n",
      "Epoch: 55080 | training loss: 5.3814e-04 | validation loss: 1.0368e-04\n",
      "Epoch: 55090 | training loss: 5.3771e-04 | validation loss: 1.0339e-04\n",
      "Epoch: 55100 | training loss: 5.3734e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 55110 | training loss: 5.3716e-04 | validation loss: 1.0300e-04\n",
      "Epoch: 55120 | training loss: 5.3705e-04 | validation loss: 1.0292e-04\n",
      "Epoch: 55130 | training loss: 5.3698e-04 | validation loss: 1.0288e-04\n",
      "Epoch: 55140 | training loss: 5.3694e-04 | validation loss: 1.0285e-04\n",
      "Epoch: 55150 | training loss: 5.3692e-04 | validation loss: 1.0285e-04\n",
      "Epoch: 55160 | training loss: 5.3691e-04 | validation loss: 1.0285e-04\n",
      "Epoch: 55170 | training loss: 5.3688e-04 | validation loss: 1.0285e-04\n",
      "Epoch: 55180 | training loss: 5.3687e-04 | validation loss: 1.0285e-04\n",
      "Epoch: 55190 | training loss: 5.3685e-04 | validation loss: 1.0285e-04\n",
      "Epoch: 55200 | training loss: 5.3683e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55210 | training loss: 5.3681e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55220 | training loss: 5.3679e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55230 | training loss: 5.3677e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55240 | training loss: 5.3675e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55250 | training loss: 5.3673e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55260 | training loss: 5.3671e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55270 | training loss: 5.3669e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 55280 | training loss: 5.3667e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55290 | training loss: 5.3665e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55300 | training loss: 5.3663e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55310 | training loss: 5.3661e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55320 | training loss: 5.3659e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55330 | training loss: 5.3657e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55340 | training loss: 5.3656e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55350 | training loss: 5.3916e-04 | validation loss: 1.0462e-04\n",
      "Epoch: 55360 | training loss: 5.3848e-04 | validation loss: 1.0440e-04\n",
      "Epoch: 55370 | training loss: 5.3658e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 55380 | training loss: 5.3672e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 55390 | training loss: 5.3671e-04 | validation loss: 1.0310e-04\n",
      "Epoch: 55400 | training loss: 5.3658e-04 | validation loss: 1.0299e-04\n",
      "Epoch: 55410 | training loss: 5.3647e-04 | validation loss: 1.0289e-04\n",
      "Epoch: 55420 | training loss: 5.3641e-04 | validation loss: 1.0285e-04\n",
      "Epoch: 55430 | training loss: 5.3638e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 55440 | training loss: 5.3636e-04 | validation loss: 1.0282e-04\n",
      "Epoch: 55450 | training loss: 5.3634e-04 | validation loss: 1.0282e-04\n",
      "Epoch: 55460 | training loss: 5.3632e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55470 | training loss: 5.3630e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55480 | training loss: 5.3628e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55490 | training loss: 5.3626e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55500 | training loss: 5.3624e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55510 | training loss: 5.3622e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55520 | training loss: 5.3620e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55530 | training loss: 5.3618e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55540 | training loss: 5.3617e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55550 | training loss: 5.3615e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55560 | training loss: 5.3613e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55570 | training loss: 5.3611e-04 | validation loss: 1.0280e-04\n",
      "Epoch: 55580 | training loss: 5.3609e-04 | validation loss: 1.0280e-04\n",
      "Epoch: 55590 | training loss: 5.3607e-04 | validation loss: 1.0280e-04\n",
      "Epoch: 55600 | training loss: 5.3605e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 55610 | training loss: 5.3622e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 55620 | training loss: 5.3602e-04 | validation loss: 1.0267e-04\n",
      "Epoch: 55630 | training loss: 5.3626e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 55640 | training loss: 5.3610e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 55650 | training loss: 5.3603e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 55660 | training loss: 5.3647e-04 | validation loss: 1.0308e-04\n",
      "Epoch: 55670 | training loss: 5.4455e-04 | validation loss: 1.0930e-04\n",
      "Epoch: 55680 | training loss: 5.3892e-04 | validation loss: 1.0474e-04\n",
      "Epoch: 55690 | training loss: 5.3654e-04 | validation loss: 1.0333e-04\n",
      "Epoch: 55700 | training loss: 5.3586e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55710 | training loss: 5.3585e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55720 | training loss: 5.3583e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55730 | training loss: 5.3580e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55740 | training loss: 5.3577e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55750 | training loss: 5.3575e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55760 | training loss: 5.3573e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 55770 | training loss: 5.3571e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55780 | training loss: 5.3569e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55790 | training loss: 5.3567e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 55800 | training loss: 5.3568e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 55810 | training loss: 5.3664e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 55820 | training loss: 5.4439e-04 | validation loss: 1.0943e-04\n",
      "Epoch: 55830 | training loss: 5.3568e-04 | validation loss: 1.0282e-04\n",
      "Epoch: 55840 | training loss: 5.3661e-04 | validation loss: 1.0346e-04\n",
      "Epoch: 55850 | training loss: 5.3565e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 55860 | training loss: 5.3561e-04 | validation loss: 1.0285e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55870 | training loss: 5.3557e-04 | validation loss: 1.0279e-04\n",
      "Epoch: 55880 | training loss: 5.3550e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 55890 | training loss: 5.3548e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 55900 | training loss: 5.3546e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55910 | training loss: 5.3544e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 55920 | training loss: 5.3542e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55930 | training loss: 5.3540e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55940 | training loss: 5.3538e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55950 | training loss: 5.3536e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55960 | training loss: 5.3534e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55970 | training loss: 5.3532e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55980 | training loss: 5.3530e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 55990 | training loss: 5.3529e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 56000 | training loss: 5.3617e-04 | validation loss: 1.0334e-04\n",
      "Epoch: 56010 | training loss: 5.4578e-04 | validation loss: 1.1021e-04\n",
      "Epoch: 56020 | training loss: 5.3831e-04 | validation loss: 1.0481e-04\n",
      "Epoch: 56030 | training loss: 5.3529e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56040 | training loss: 5.3529e-04 | validation loss: 1.0282e-04\n",
      "Epoch: 56050 | training loss: 5.3535e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 56060 | training loss: 5.3521e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 56070 | training loss: 5.3513e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 56080 | training loss: 5.3512e-04 | validation loss: 1.0273e-04\n",
      "Epoch: 56090 | training loss: 5.3509e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56100 | training loss: 5.3508e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 56110 | training loss: 5.3506e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56120 | training loss: 5.3504e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56130 | training loss: 5.3502e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56140 | training loss: 5.3500e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56150 | training loss: 5.3498e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56160 | training loss: 5.3496e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56170 | training loss: 5.3494e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56180 | training loss: 5.3492e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56190 | training loss: 5.3490e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56200 | training loss: 5.3488e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56210 | training loss: 5.3486e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 56220 | training loss: 5.3484e-04 | validation loss: 1.0279e-04\n",
      "Epoch: 56230 | training loss: 5.3518e-04 | validation loss: 1.0371e-04\n",
      "Epoch: 56240 | training loss: 5.3491e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 56250 | training loss: 5.3524e-04 | validation loss: 1.0356e-04\n",
      "Epoch: 56260 | training loss: 5.4423e-04 | validation loss: 1.0990e-04\n",
      "Epoch: 56270 | training loss: 5.3886e-04 | validation loss: 1.0612e-04\n",
      "Epoch: 56280 | training loss: 5.3523e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 56290 | training loss: 5.3489e-04 | validation loss: 1.0272e-04\n",
      "Epoch: 56300 | training loss: 5.3488e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 56310 | training loss: 5.3469e-04 | validation loss: 1.0266e-04\n",
      "Epoch: 56320 | training loss: 5.3465e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56330 | training loss: 5.3463e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56340 | training loss: 5.3461e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56350 | training loss: 5.3459e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56360 | training loss: 5.3457e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56370 | training loss: 5.3455e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56380 | training loss: 5.3453e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56390 | training loss: 5.3451e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56400 | training loss: 5.3449e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56410 | training loss: 5.3448e-04 | validation loss: 1.0272e-04\n",
      "Epoch: 56420 | training loss: 5.3452e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 56430 | training loss: 5.3827e-04 | validation loss: 1.0570e-04\n",
      "Epoch: 56440 | training loss: 5.3479e-04 | validation loss: 1.0289e-04\n",
      "Epoch: 56450 | training loss: 5.3697e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 56460 | training loss: 5.3449e-04 | validation loss: 1.0280e-04\n",
      "Epoch: 56470 | training loss: 5.3462e-04 | validation loss: 1.0284e-04\n",
      "Epoch: 56480 | training loss: 5.3437e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56490 | training loss: 5.3437e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 56500 | training loss: 5.3431e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56510 | training loss: 5.3429e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56520 | training loss: 5.3427e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56530 | training loss: 5.3425e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56540 | training loss: 5.3423e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56550 | training loss: 5.3421e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56560 | training loss: 5.3419e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56570 | training loss: 5.3417e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56580 | training loss: 5.3415e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 56590 | training loss: 5.3413e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 56600 | training loss: 5.3411e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 56610 | training loss: 5.3409e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 56620 | training loss: 5.3407e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 56630 | training loss: 5.3411e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56640 | training loss: 5.4134e-04 | validation loss: 1.0780e-04\n",
      "Epoch: 56650 | training loss: 5.4223e-04 | validation loss: 1.0895e-04\n",
      "Epoch: 56660 | training loss: 5.3456e-04 | validation loss: 1.0322e-04\n",
      "Epoch: 56670 | training loss: 5.3398e-04 | validation loss: 1.0272e-04\n",
      "Epoch: 56680 | training loss: 5.3407e-04 | validation loss: 1.0273e-04\n",
      "Epoch: 56690 | training loss: 5.3406e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 56700 | training loss: 5.3397e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56710 | training loss: 5.3391e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56720 | training loss: 5.3389e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 56730 | training loss: 5.3387e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 56740 | training loss: 5.3385e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56750 | training loss: 5.3383e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56760 | training loss: 5.3381e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56770 | training loss: 5.3380e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56780 | training loss: 5.3378e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56790 | training loss: 5.3376e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56800 | training loss: 5.3374e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 56810 | training loss: 5.3372e-04 | validation loss: 1.0267e-04\n",
      "Epoch: 56820 | training loss: 5.3370e-04 | validation loss: 1.0267e-04\n",
      "Epoch: 56830 | training loss: 5.3368e-04 | validation loss: 1.0267e-04\n",
      "Epoch: 56840 | training loss: 5.3366e-04 | validation loss: 1.0267e-04\n",
      "Epoch: 56850 | training loss: 5.3364e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 56860 | training loss: 5.3370e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 56870 | training loss: 5.3527e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 56880 | training loss: 5.3414e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 56890 | training loss: 5.3374e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 56900 | training loss: 5.3626e-04 | validation loss: 1.0480e-04\n",
      "Epoch: 56910 | training loss: 5.3424e-04 | validation loss: 1.0320e-04\n",
      "Epoch: 56920 | training loss: 5.3357e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 56930 | training loss: 5.3386e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 56940 | training loss: 5.3371e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 56950 | training loss: 5.3354e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 56960 | training loss: 5.3347e-04 | validation loss: 1.0267e-04\n",
      "Epoch: 56970 | training loss: 5.3343e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 56980 | training loss: 5.3340e-04 | validation loss: 1.0266e-04\n",
      "Epoch: 56990 | training loss: 5.3338e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 57000 | training loss: 5.3336e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 57010 | training loss: 5.3334e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 57020 | training loss: 5.3332e-04 | validation loss: 1.0265e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57030 | training loss: 5.3331e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57040 | training loss: 5.3346e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 57050 | training loss: 5.4240e-04 | validation loss: 1.0902e-04\n",
      "Epoch: 57060 | training loss: 5.3825e-04 | validation loss: 1.0650e-04\n",
      "Epoch: 57070 | training loss: 5.3350e-04 | validation loss: 1.0280e-04\n",
      "Epoch: 57080 | training loss: 5.3381e-04 | validation loss: 1.0302e-04\n",
      "Epoch: 57090 | training loss: 5.3323e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 57100 | training loss: 5.3323e-04 | validation loss: 1.0271e-04\n",
      "Epoch: 57110 | training loss: 5.3318e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 57120 | training loss: 5.3313e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57130 | training loss: 5.3312e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57140 | training loss: 5.3310e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57150 | training loss: 5.3308e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57160 | training loss: 5.3306e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57170 | training loss: 5.3304e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57180 | training loss: 5.3302e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57190 | training loss: 5.3300e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57200 | training loss: 5.3298e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57210 | training loss: 5.3296e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57220 | training loss: 5.3294e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57230 | training loss: 5.3295e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57240 | training loss: 5.3476e-04 | validation loss: 1.0386e-04\n",
      "Epoch: 57250 | training loss: 5.3491e-04 | validation loss: 1.0400e-04\n",
      "Epoch: 57260 | training loss: 5.3608e-04 | validation loss: 1.0478e-04\n",
      "Epoch: 57270 | training loss: 5.3288e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57280 | training loss: 5.3312e-04 | validation loss: 1.0287e-04\n",
      "Epoch: 57290 | training loss: 5.3293e-04 | validation loss: 1.0278e-04\n",
      "Epoch: 57300 | training loss: 5.3280e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57310 | training loss: 5.3280e-04 | validation loss: 1.0261e-04\n",
      "Epoch: 57320 | training loss: 5.3276e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 57330 | training loss: 5.3274e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57340 | training loss: 5.3272e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57350 | training loss: 5.3270e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57360 | training loss: 5.3269e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57370 | training loss: 5.3267e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57380 | training loss: 5.3265e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57390 | training loss: 5.3263e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57400 | training loss: 5.3261e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57410 | training loss: 5.3259e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57420 | training loss: 5.3257e-04 | validation loss: 1.0261e-04\n",
      "Epoch: 57430 | training loss: 5.3255e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57440 | training loss: 5.3254e-04 | validation loss: 1.0252e-04\n",
      "Epoch: 57450 | training loss: 5.3345e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 57460 | training loss: 5.3348e-04 | validation loss: 1.0448e-04\n",
      "Epoch: 57470 | training loss: 5.3316e-04 | validation loss: 1.0338e-04\n",
      "Epoch: 57480 | training loss: 5.4483e-04 | validation loss: 1.1202e-04\n",
      "Epoch: 57490 | training loss: 5.3301e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 57500 | training loss: 5.3363e-04 | validation loss: 1.0363e-04\n",
      "Epoch: 57510 | training loss: 5.3246e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 57520 | training loss: 5.3254e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 57530 | training loss: 5.3239e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57540 | training loss: 5.3235e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57550 | training loss: 5.3234e-04 | validation loss: 1.0261e-04\n",
      "Epoch: 57560 | training loss: 5.3232e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 57570 | training loss: 5.3230e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57580 | training loss: 5.3228e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57590 | training loss: 5.3226e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57600 | training loss: 5.3224e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57610 | training loss: 5.3222e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57620 | training loss: 5.3220e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 57630 | training loss: 5.3218e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 57640 | training loss: 5.3216e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 57650 | training loss: 5.3215e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 57660 | training loss: 5.3214e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 57670 | training loss: 5.3374e-04 | validation loss: 1.0391e-04\n",
      "Epoch: 57680 | training loss: 5.3494e-04 | validation loss: 1.0479e-04\n",
      "Epoch: 57690 | training loss: 5.3579e-04 | validation loss: 1.0548e-04\n",
      "Epoch: 57700 | training loss: 5.3229e-04 | validation loss: 1.0280e-04\n",
      "Epoch: 57710 | training loss: 5.3213e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 57720 | training loss: 5.3219e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 57730 | training loss: 5.3202e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 57740 | training loss: 5.3199e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 57750 | training loss: 5.3197e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 57760 | training loss: 5.3195e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57770 | training loss: 5.3193e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57780 | training loss: 5.3191e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57790 | training loss: 5.3189e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57800 | training loss: 5.3187e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57810 | training loss: 5.3186e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57820 | training loss: 5.3184e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57830 | training loss: 5.3182e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57840 | training loss: 5.3180e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57850 | training loss: 5.3178e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 57860 | training loss: 5.3176e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 57870 | training loss: 5.3174e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 57880 | training loss: 5.3172e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 57890 | training loss: 5.3170e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 57900 | training loss: 5.3169e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 57910 | training loss: 5.3167e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 57920 | training loss: 5.3394e-04 | validation loss: 1.0409e-04\n",
      "Epoch: 57930 | training loss: 5.3313e-04 | validation loss: 1.0383e-04\n",
      "Epoch: 57940 | training loss: 5.3193e-04 | validation loss: 1.0292e-04\n",
      "Epoch: 57950 | training loss: 5.3244e-04 | validation loss: 1.0333e-04\n",
      "Epoch: 57960 | training loss: 5.3222e-04 | validation loss: 1.0314e-04\n",
      "Epoch: 57970 | training loss: 5.3181e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 57980 | training loss: 5.3162e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 57990 | training loss: 5.3155e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 58000 | training loss: 5.3152e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 58010 | training loss: 5.3150e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 58020 | training loss: 5.3148e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 58030 | training loss: 5.3146e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 58040 | training loss: 5.3144e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58050 | training loss: 5.3142e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58060 | training loss: 5.3140e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58070 | training loss: 5.3139e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58080 | training loss: 5.3137e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58090 | training loss: 5.3135e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58100 | training loss: 5.3133e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58110 | training loss: 5.3131e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58120 | training loss: 5.3130e-04 | validation loss: 1.0255e-04\n",
      "Epoch: 58130 | training loss: 5.3128e-04 | validation loss: 1.0255e-04\n",
      "Epoch: 58140 | training loss: 5.3126e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 58150 | training loss: 5.3128e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 58160 | training loss: 5.3386e-04 | validation loss: 1.0627e-04\n",
      "Epoch: 58170 | training loss: 5.3147e-04 | validation loss: 1.0335e-04\n",
      "Epoch: 58180 | training loss: 5.3120e-04 | validation loss: 1.0272e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58190 | training loss: 5.3117e-04 | validation loss: 1.0255e-04\n",
      "Epoch: 58200 | training loss: 5.3115e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 58210 | training loss: 5.3114e-04 | validation loss: 1.0245e-04\n",
      "Epoch: 58220 | training loss: 5.3112e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 58230 | training loss: 5.3110e-04 | validation loss: 1.0250e-04\n",
      "Epoch: 58240 | training loss: 5.3108e-04 | validation loss: 1.0254e-04\n",
      "Epoch: 58250 | training loss: 5.3112e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 58260 | training loss: 5.3531e-04 | validation loss: 1.0540e-04\n",
      "Epoch: 58270 | training loss: 5.3203e-04 | validation loss: 1.0341e-04\n",
      "Epoch: 58280 | training loss: 5.3326e-04 | validation loss: 1.0408e-04\n",
      "Epoch: 58290 | training loss: 5.3146e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 58300 | training loss: 5.3105e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 58310 | training loss: 5.3106e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 58320 | training loss: 5.3094e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58330 | training loss: 5.3093e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58340 | training loss: 5.3090e-04 | validation loss: 1.0254e-04\n",
      "Epoch: 58350 | training loss: 5.3088e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58360 | training loss: 5.3086e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58370 | training loss: 5.3084e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58380 | training loss: 5.3083e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58390 | training loss: 5.3081e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58400 | training loss: 5.3079e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58410 | training loss: 5.3077e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58420 | training loss: 5.3075e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58430 | training loss: 5.3073e-04 | validation loss: 1.0252e-04\n",
      "Epoch: 58440 | training loss: 5.3072e-04 | validation loss: 1.0252e-04\n",
      "Epoch: 58450 | training loss: 5.3070e-04 | validation loss: 1.0252e-04\n",
      "Epoch: 58460 | training loss: 5.3068e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 58470 | training loss: 5.3128e-04 | validation loss: 1.0305e-04\n",
      "Epoch: 58480 | training loss: 5.4684e-04 | validation loss: 1.1475e-04\n",
      "Epoch: 58490 | training loss: 5.3169e-04 | validation loss: 1.0345e-04\n",
      "Epoch: 58500 | training loss: 5.3075e-04 | validation loss: 1.0264e-04\n",
      "Epoch: 58510 | training loss: 5.3101e-04 | validation loss: 1.0277e-04\n",
      "Epoch: 58520 | training loss: 5.3080e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 58530 | training loss: 5.3058e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 58540 | training loss: 5.3054e-04 | validation loss: 1.0254e-04\n",
      "Epoch: 58550 | training loss: 5.3053e-04 | validation loss: 1.0255e-04\n",
      "Epoch: 58560 | training loss: 5.3050e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58570 | training loss: 5.3049e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58580 | training loss: 5.3047e-04 | validation loss: 1.0252e-04\n",
      "Epoch: 58590 | training loss: 5.3045e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58600 | training loss: 5.3043e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58610 | training loss: 5.3041e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58620 | training loss: 5.3039e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58630 | training loss: 5.3038e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58640 | training loss: 5.3036e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58650 | training loss: 5.3034e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58660 | training loss: 5.3032e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58670 | training loss: 5.3030e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58680 | training loss: 5.3028e-04 | validation loss: 1.0250e-04\n",
      "Epoch: 58690 | training loss: 5.3027e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 58700 | training loss: 5.3047e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 58710 | training loss: 5.3028e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 58720 | training loss: 5.3124e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 58730 | training loss: 5.4025e-04 | validation loss: 1.0979e-04\n",
      "Epoch: 58740 | training loss: 5.3287e-04 | validation loss: 1.0397e-04\n",
      "Epoch: 58750 | training loss: 5.3019e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 58760 | training loss: 5.3035e-04 | validation loss: 1.0281e-04\n",
      "Epoch: 58770 | training loss: 5.3028e-04 | validation loss: 1.0266e-04\n",
      "Epoch: 58780 | training loss: 5.3015e-04 | validation loss: 1.0260e-04\n",
      "Epoch: 58790 | training loss: 5.3010e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58800 | training loss: 5.3007e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 58810 | training loss: 5.3005e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 58820 | training loss: 5.3003e-04 | validation loss: 1.0250e-04\n",
      "Epoch: 58830 | training loss: 5.3002e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 58840 | training loss: 5.3000e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 58850 | training loss: 5.2998e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 58860 | training loss: 5.2996e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 58870 | training loss: 5.2995e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 58880 | training loss: 5.3014e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 58890 | training loss: 5.4132e-04 | validation loss: 1.1044e-04\n",
      "Epoch: 58900 | training loss: 5.3551e-04 | validation loss: 1.0682e-04\n",
      "Epoch: 58910 | training loss: 5.2992e-04 | validation loss: 1.0254e-04\n",
      "Epoch: 58920 | training loss: 5.3045e-04 | validation loss: 1.0283e-04\n",
      "Epoch: 58930 | training loss: 5.2990e-04 | validation loss: 1.0250e-04\n",
      "Epoch: 58940 | training loss: 5.2989e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 58950 | training loss: 5.2980e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 58960 | training loss: 5.2980e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 58970 | training loss: 5.2977e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 58980 | training loss: 5.2975e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 58990 | training loss: 5.2973e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 59000 | training loss: 5.2971e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 59010 | training loss: 5.2970e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 59020 | training loss: 5.2968e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 59030 | training loss: 5.2966e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 59040 | training loss: 5.2964e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 59050 | training loss: 5.2962e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 59060 | training loss: 5.2961e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 59070 | training loss: 5.2959e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 59080 | training loss: 5.2957e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 59090 | training loss: 5.2993e-04 | validation loss: 1.0269e-04\n",
      "Epoch: 59100 | training loss: 5.4885e-04 | validation loss: 1.1617e-04\n",
      "Epoch: 59110 | training loss: 5.2955e-04 | validation loss: 1.0245e-04\n",
      "Epoch: 59120 | training loss: 5.3065e-04 | validation loss: 1.0338e-04\n",
      "Epoch: 59130 | training loss: 5.3020e-04 | validation loss: 1.0310e-04\n",
      "Epoch: 59140 | training loss: 5.2962e-04 | validation loss: 1.0266e-04\n",
      "Epoch: 59150 | training loss: 5.2945e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 59160 | training loss: 5.2946e-04 | validation loss: 1.0245e-04\n",
      "Epoch: 59170 | training loss: 5.2942e-04 | validation loss: 1.0245e-04\n",
      "Epoch: 59180 | training loss: 5.2940e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 59190 | training loss: 5.2938e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 59200 | training loss: 5.2936e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59210 | training loss: 5.2934e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59220 | training loss: 5.2933e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59230 | training loss: 5.2931e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59240 | training loss: 5.2929e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59250 | training loss: 5.2927e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59260 | training loss: 5.2925e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59270 | training loss: 5.2924e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59280 | training loss: 5.2922e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59290 | training loss: 5.2920e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59300 | training loss: 5.2918e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59310 | training loss: 5.2916e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 59320 | training loss: 5.2915e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 59330 | training loss: 5.2923e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 59340 | training loss: 5.2999e-04 | validation loss: 1.0418e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59350 | training loss: 5.3095e-04 | validation loss: 1.0484e-04\n",
      "Epoch: 59360 | training loss: 5.3701e-04 | validation loss: 1.0903e-04\n",
      "Epoch: 59370 | training loss: 5.2917e-04 | validation loss: 1.0245e-04\n",
      "Epoch: 59380 | training loss: 5.3022e-04 | validation loss: 1.0282e-04\n",
      "Epoch: 59390 | training loss: 5.2904e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 59400 | training loss: 5.2916e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 59410 | training loss: 5.2899e-04 | validation loss: 1.0250e-04\n",
      "Epoch: 59420 | training loss: 5.2898e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59430 | training loss: 5.2896e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59440 | training loss: 5.2894e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59450 | training loss: 5.2892e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59460 | training loss: 5.2890e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 59470 | training loss: 5.2888e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59480 | training loss: 5.2887e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59490 | training loss: 5.2885e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59500 | training loss: 5.2883e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59510 | training loss: 5.2881e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59520 | training loss: 5.2880e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 59530 | training loss: 5.2878e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59540 | training loss: 5.2890e-04 | validation loss: 1.0258e-04\n",
      "Epoch: 59550 | training loss: 5.3959e-04 | validation loss: 1.1073e-04\n",
      "Epoch: 59560 | training loss: 5.3545e-04 | validation loss: 1.0711e-04\n",
      "Epoch: 59570 | training loss: 5.2895e-04 | validation loss: 1.0256e-04\n",
      "Epoch: 59580 | training loss: 5.2905e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 59590 | training loss: 5.2895e-04 | validation loss: 1.0268e-04\n",
      "Epoch: 59600 | training loss: 5.2866e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 59610 | training loss: 5.2868e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59620 | training loss: 5.2862e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 59630 | training loss: 5.2861e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 59640 | training loss: 5.2859e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59650 | training loss: 5.2857e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 59660 | training loss: 5.2856e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 59670 | training loss: 5.2854e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59680 | training loss: 5.2852e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59690 | training loss: 5.2850e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59700 | training loss: 5.2849e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59710 | training loss: 5.2847e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59720 | training loss: 5.2845e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59730 | training loss: 5.2843e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59740 | training loss: 5.2841e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59750 | training loss: 5.2840e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59760 | training loss: 5.2838e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59770 | training loss: 5.2837e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 59780 | training loss: 5.2985e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 59790 | training loss: 5.2919e-04 | validation loss: 1.0309e-04\n",
      "Epoch: 59800 | training loss: 5.3025e-04 | validation loss: 1.0392e-04\n",
      "Epoch: 59810 | training loss: 5.2868e-04 | validation loss: 1.0272e-04\n",
      "Epoch: 59820 | training loss: 5.2831e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59830 | training loss: 5.2826e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 59840 | training loss: 5.2824e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 59850 | training loss: 5.2823e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59860 | training loss: 5.2821e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59870 | training loss: 5.2820e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59880 | training loss: 5.2818e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 59890 | training loss: 5.2816e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59900 | training loss: 5.2814e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59910 | training loss: 5.2813e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59920 | training loss: 5.2811e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59930 | training loss: 5.2809e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59940 | training loss: 5.2808e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59950 | training loss: 5.2806e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59960 | training loss: 5.2804e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 59970 | training loss: 5.2802e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 59980 | training loss: 5.2801e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 59990 | training loss: 5.2799e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 60000 | training loss: 5.2797e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 60010 | training loss: 5.2795e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 60020 | training loss: 5.2794e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 60030 | training loss: 5.2792e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 60040 | training loss: 5.2790e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 60050 | training loss: 5.2788e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 60060 | training loss: 5.2793e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 60070 | training loss: 5.2991e-04 | validation loss: 1.0551e-04\n",
      "Epoch: 60080 | training loss: 5.2869e-04 | validation loss: 1.0408e-04\n",
      "Epoch: 60090 | training loss: 5.2886e-04 | validation loss: 1.0373e-04\n",
      "Epoch: 60100 | training loss: 5.3754e-04 | validation loss: 1.0969e-04\n",
      "Epoch: 60110 | training loss: 5.2965e-04 | validation loss: 1.0410e-04\n",
      "Epoch: 60120 | training loss: 5.2779e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60130 | training loss: 5.2808e-04 | validation loss: 1.0245e-04\n",
      "Epoch: 60140 | training loss: 5.2785e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 60150 | training loss: 5.2772e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60160 | training loss: 5.2769e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60170 | training loss: 5.2768e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60180 | training loss: 5.2766e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60190 | training loss: 5.2764e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60200 | training loss: 5.2762e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60210 | training loss: 5.2761e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 60220 | training loss: 5.2759e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 60230 | training loss: 5.2757e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 60240 | training loss: 5.2756e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 60250 | training loss: 5.2763e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 60260 | training loss: 5.3376e-04 | validation loss: 1.0662e-04\n",
      "Epoch: 60270 | training loss: 5.3084e-04 | validation loss: 1.0503e-04\n",
      "Epoch: 60280 | training loss: 5.2865e-04 | validation loss: 1.0312e-04\n",
      "Epoch: 60290 | training loss: 5.2811e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 60300 | training loss: 5.2749e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 60310 | training loss: 5.2754e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 60320 | training loss: 5.2743e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60330 | training loss: 5.2741e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60340 | training loss: 5.2739e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60350 | training loss: 5.2737e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60360 | training loss: 5.2735e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60370 | training loss: 5.2733e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60380 | training loss: 5.2732e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60390 | training loss: 5.2730e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60400 | training loss: 5.2728e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60410 | training loss: 5.2726e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60420 | training loss: 5.2725e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60430 | training loss: 5.2723e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60440 | training loss: 5.2721e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60450 | training loss: 5.2720e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60460 | training loss: 5.2742e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 60470 | training loss: 5.4389e-04 | validation loss: 1.1418e-04\n",
      "Epoch: 60480 | training loss: 5.3016e-04 | validation loss: 1.0471e-04\n",
      "Epoch: 60490 | training loss: 5.2924e-04 | validation loss: 1.0407e-04\n",
      "Epoch: 60500 | training loss: 5.2734e-04 | validation loss: 1.0262e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60510 | training loss: 5.2712e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60520 | training loss: 5.2717e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 60530 | training loss: 5.2707e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 60540 | training loss: 5.2705e-04 | validation loss: 1.0237e-04\n",
      "Epoch: 60550 | training loss: 5.2703e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 60560 | training loss: 5.2701e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60570 | training loss: 5.2699e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60580 | training loss: 5.2698e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60590 | training loss: 5.2696e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60600 | training loss: 5.2694e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60610 | training loss: 5.2692e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60620 | training loss: 5.2691e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60630 | training loss: 5.2689e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60640 | training loss: 5.2687e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 60650 | training loss: 5.2686e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 60660 | training loss: 5.2684e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 60670 | training loss: 5.2682e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 60680 | training loss: 5.2680e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60690 | training loss: 5.2679e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 60700 | training loss: 5.2716e-04 | validation loss: 1.0320e-04\n",
      "Epoch: 60710 | training loss: 5.3947e-04 | validation loss: 1.1197e-04\n",
      "Epoch: 60720 | training loss: 5.3100e-04 | validation loss: 1.0438e-04\n",
      "Epoch: 60730 | training loss: 5.2766e-04 | validation loss: 1.0197e-04\n",
      "Epoch: 60740 | training loss: 5.2707e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 60750 | training loss: 5.2684e-04 | validation loss: 1.0252e-04\n",
      "Epoch: 60760 | training loss: 5.2670e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 60770 | training loss: 5.2668e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 60780 | training loss: 5.2664e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 60790 | training loss: 5.2662e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 60800 | training loss: 5.2660e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 60810 | training loss: 5.2659e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 60820 | training loss: 5.2657e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 60830 | training loss: 5.2655e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 60840 | training loss: 5.2654e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 60850 | training loss: 5.2652e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 60860 | training loss: 5.2650e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 60870 | training loss: 5.2649e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 60880 | training loss: 5.2647e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 60890 | training loss: 5.2645e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 60900 | training loss: 5.2643e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 60910 | training loss: 5.2643e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 60920 | training loss: 5.2847e-04 | validation loss: 1.0361e-04\n",
      "Epoch: 60930 | training loss: 5.2685e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 60940 | training loss: 5.3012e-04 | validation loss: 1.0485e-04\n",
      "Epoch: 60950 | training loss: 5.2773e-04 | validation loss: 1.0318e-04\n",
      "Epoch: 60960 | training loss: 5.2657e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 60970 | training loss: 5.2632e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 60980 | training loss: 5.2634e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 60990 | training loss: 5.2631e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 61000 | training loss: 5.2627e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61010 | training loss: 5.2626e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61020 | training loss: 5.2624e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61030 | training loss: 5.2622e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61040 | training loss: 5.2621e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61050 | training loss: 5.2619e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61060 | training loss: 5.2617e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61070 | training loss: 5.2616e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61080 | training loss: 5.2614e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61090 | training loss: 5.2612e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61100 | training loss: 5.2610e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61110 | training loss: 5.2609e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61120 | training loss: 5.2607e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61130 | training loss: 5.2605e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61140 | training loss: 5.2604e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61150 | training loss: 5.2602e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61160 | training loss: 5.2600e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61170 | training loss: 5.2602e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61180 | training loss: 5.3222e-04 | validation loss: 1.0659e-04\n",
      "Epoch: 61190 | training loss: 5.3454e-04 | validation loss: 1.0895e-04\n",
      "Epoch: 61200 | training loss: 5.2687e-04 | validation loss: 1.0313e-04\n",
      "Epoch: 61210 | training loss: 5.2604e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 61220 | training loss: 5.2591e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 61230 | training loss: 5.2590e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61240 | training loss: 5.2590e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61250 | training loss: 5.2588e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61260 | training loss: 5.2585e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61270 | training loss: 5.2582e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61280 | training loss: 5.2581e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61290 | training loss: 5.2579e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61300 | training loss: 5.2577e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61310 | training loss: 5.2576e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61320 | training loss: 5.2574e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61330 | training loss: 5.2573e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61340 | training loss: 5.2571e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61350 | training loss: 5.2569e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61360 | training loss: 5.2567e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61370 | training loss: 5.2566e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61380 | training loss: 5.2564e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61390 | training loss: 5.2562e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61400 | training loss: 5.2561e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61410 | training loss: 5.2559e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61420 | training loss: 5.2557e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61430 | training loss: 5.2555e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61440 | training loss: 5.2554e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61450 | training loss: 5.2552e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61460 | training loss: 5.2567e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 61470 | training loss: 5.5106e-04 | validation loss: 1.2158e-04\n",
      "Epoch: 61480 | training loss: 5.2553e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 61490 | training loss: 5.2550e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 61500 | training loss: 5.2558e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 61510 | training loss: 5.2554e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 61520 | training loss: 5.2546e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 61530 | training loss: 5.2541e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61540 | training loss: 5.2538e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61550 | training loss: 5.2536e-04 | validation loss: 1.0230e-04\n",
      "Epoch: 61560 | training loss: 5.2534e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61570 | training loss: 5.2533e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61580 | training loss: 5.2531e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61590 | training loss: 5.2530e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61600 | training loss: 5.2528e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61610 | training loss: 5.2526e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61620 | training loss: 5.2525e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61630 | training loss: 5.2523e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61640 | training loss: 5.2521e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61650 | training loss: 5.2520e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 61660 | training loss: 5.2518e-04 | validation loss: 1.0230e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61670 | training loss: 5.2520e-04 | validation loss: 1.0254e-04\n",
      "Epoch: 61680 | training loss: 5.2797e-04 | validation loss: 1.0618e-04\n",
      "Epoch: 61690 | training loss: 5.2572e-04 | validation loss: 1.0360e-04\n",
      "Epoch: 61700 | training loss: 5.2530e-04 | validation loss: 1.0294e-04\n",
      "Epoch: 61710 | training loss: 5.2517e-04 | validation loss: 1.0265e-04\n",
      "Epoch: 61720 | training loss: 5.2510e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 61730 | training loss: 5.2507e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 61740 | training loss: 5.2505e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 61750 | training loss: 5.2503e-04 | validation loss: 1.0228e-04\n",
      "Epoch: 61760 | training loss: 5.2501e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 61770 | training loss: 5.2500e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 61780 | training loss: 5.2521e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 61790 | training loss: 5.3861e-04 | validation loss: 1.1162e-04\n",
      "Epoch: 61800 | training loss: 5.3000e-04 | validation loss: 1.0621e-04\n",
      "Epoch: 61810 | training loss: 5.2572e-04 | validation loss: 1.0293e-04\n",
      "Epoch: 61820 | training loss: 5.2507e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61830 | training loss: 5.2515e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 61840 | training loss: 5.2488e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 61850 | training loss: 5.2490e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 61860 | training loss: 5.2485e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61870 | training loss: 5.2484e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61880 | training loss: 5.2482e-04 | validation loss: 1.0228e-04\n",
      "Epoch: 61890 | training loss: 5.2480e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61900 | training loss: 5.2479e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61910 | training loss: 5.2477e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61920 | training loss: 5.2475e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61930 | training loss: 5.2474e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61940 | training loss: 5.2472e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61950 | training loss: 5.2470e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61960 | training loss: 5.2469e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61970 | training loss: 5.2467e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61980 | training loss: 5.2465e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 61990 | training loss: 5.2463e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 62000 | training loss: 5.2463e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 62010 | training loss: 5.2702e-04 | validation loss: 1.0424e-04\n",
      "Epoch: 62020 | training loss: 5.2476e-04 | validation loss: 1.0224e-04\n",
      "Epoch: 62030 | training loss: 5.2568e-04 | validation loss: 1.0309e-04\n",
      "Epoch: 62040 | training loss: 5.2517e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 62050 | training loss: 5.2482e-04 | validation loss: 1.0252e-04\n",
      "Epoch: 62060 | training loss: 5.2466e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 62070 | training loss: 5.2458e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 62080 | training loss: 5.2452e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 62090 | training loss: 5.2448e-04 | validation loss: 1.0228e-04\n",
      "Epoch: 62100 | training loss: 5.2446e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62110 | training loss: 5.2444e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62120 | training loss: 5.2443e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62130 | training loss: 5.2441e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62140 | training loss: 5.2440e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62150 | training loss: 5.2438e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62160 | training loss: 5.2436e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62170 | training loss: 5.2435e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62180 | training loss: 5.2433e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62190 | training loss: 5.2431e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62200 | training loss: 5.2430e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62210 | training loss: 5.2428e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62220 | training loss: 5.2426e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62230 | training loss: 5.2425e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62240 | training loss: 5.2423e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62250 | training loss: 5.2421e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62260 | training loss: 5.2421e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 62270 | training loss: 5.2599e-04 | validation loss: 1.0507e-04\n",
      "Epoch: 62280 | training loss: 5.2551e-04 | validation loss: 1.0184e-04\n",
      "Epoch: 62290 | training loss: 5.2985e-04 | validation loss: 1.0505e-04\n",
      "Epoch: 62300 | training loss: 5.2519e-04 | validation loss: 1.0270e-04\n",
      "Epoch: 62310 | training loss: 5.2440e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 62320 | training loss: 5.2415e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62330 | training loss: 5.2408e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62340 | training loss: 5.2409e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62350 | training loss: 5.2406e-04 | validation loss: 1.0228e-04\n",
      "Epoch: 62360 | training loss: 5.2404e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62370 | training loss: 5.2402e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62380 | training loss: 5.2400e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62390 | training loss: 5.2409e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 62400 | training loss: 5.2832e-04 | validation loss: 1.0571e-04\n",
      "Epoch: 62410 | training loss: 5.2424e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 62420 | training loss: 5.2586e-04 | validation loss: 1.0381e-04\n",
      "Epoch: 62430 | training loss: 5.2415e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 62440 | training loss: 5.2398e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 62450 | training loss: 5.2399e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 62460 | training loss: 5.2389e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62470 | training loss: 5.2385e-04 | validation loss: 1.0224e-04\n",
      "Epoch: 62480 | training loss: 5.2384e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62490 | training loss: 5.2382e-04 | validation loss: 1.0224e-04\n",
      "Epoch: 62500 | training loss: 5.2380e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62510 | training loss: 5.2379e-04 | validation loss: 1.0224e-04\n",
      "Epoch: 62520 | training loss: 5.2377e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62530 | training loss: 5.2375e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62540 | training loss: 5.2374e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62550 | training loss: 5.2372e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62560 | training loss: 5.2373e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62570 | training loss: 5.2489e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 62580 | training loss: 5.3139e-04 | validation loss: 1.0757e-04\n",
      "Epoch: 62590 | training loss: 5.2409e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 62600 | training loss: 5.2462e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 62610 | training loss: 5.2380e-04 | validation loss: 1.0240e-04\n",
      "Epoch: 62620 | training loss: 5.2371e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 62630 | training loss: 5.2361e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62640 | training loss: 5.2360e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 62650 | training loss: 5.2356e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62660 | training loss: 5.2355e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62670 | training loss: 5.2353e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62680 | training loss: 5.2351e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62690 | training loss: 5.2350e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62700 | training loss: 5.2348e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62710 | training loss: 5.2346e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62720 | training loss: 5.2345e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62730 | training loss: 5.2343e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62740 | training loss: 5.2341e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62750 | training loss: 5.2340e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62760 | training loss: 5.2338e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 62770 | training loss: 5.2345e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 62780 | training loss: 5.3245e-04 | validation loss: 1.0925e-04\n",
      "Epoch: 62790 | training loss: 5.3133e-04 | validation loss: 1.0774e-04\n",
      "Epoch: 62800 | training loss: 5.2372e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 62810 | training loss: 5.2341e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 62820 | training loss: 5.2358e-04 | validation loss: 1.0251e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62830 | training loss: 5.2338e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 62840 | training loss: 5.2325e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62850 | training loss: 5.2325e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 62860 | training loss: 5.2322e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 62870 | training loss: 5.2321e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62880 | training loss: 5.2319e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 62890 | training loss: 5.2317e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 62900 | training loss: 5.2316e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 62910 | training loss: 5.2314e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 62920 | training loss: 5.2313e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 62930 | training loss: 5.2311e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 62940 | training loss: 5.2309e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 62950 | training loss: 5.2313e-04 | validation loss: 1.0195e-04\n",
      "Epoch: 62960 | training loss: 5.2503e-04 | validation loss: 1.0172e-04\n",
      "Epoch: 62970 | training loss: 5.2309e-04 | validation loss: 1.0197e-04\n",
      "Epoch: 62980 | training loss: 5.2310e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 62990 | training loss: 5.2309e-04 | validation loss: 1.0261e-04\n",
      "Epoch: 63000 | training loss: 5.2301e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 63010 | training loss: 5.2298e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63020 | training loss: 5.2300e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63030 | training loss: 5.2549e-04 | validation loss: 1.0431e-04\n",
      "Epoch: 63040 | training loss: 5.2333e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 63050 | training loss: 5.2591e-04 | validation loss: 1.0460e-04\n",
      "Epoch: 63060 | training loss: 5.2290e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63070 | training loss: 5.2324e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 63080 | training loss: 5.2290e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63090 | training loss: 5.2290e-04 | validation loss: 1.0226e-04\n",
      "Epoch: 63100 | training loss: 5.2284e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63110 | training loss: 5.2283e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63120 | training loss: 5.2281e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63130 | training loss: 5.2279e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63140 | training loss: 5.2277e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63150 | training loss: 5.2276e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63160 | training loss: 5.2274e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63170 | training loss: 5.2272e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63180 | training loss: 5.2271e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63190 | training loss: 5.2269e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63200 | training loss: 5.2268e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63210 | training loss: 5.2266e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63220 | training loss: 5.2264e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63230 | training loss: 5.2263e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63240 | training loss: 5.2262e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63250 | training loss: 5.2479e-04 | validation loss: 1.0399e-04\n",
      "Epoch: 63260 | training loss: 5.2260e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 63270 | training loss: 5.2379e-04 | validation loss: 1.0315e-04\n",
      "Epoch: 63280 | training loss: 5.2309e-04 | validation loss: 1.0266e-04\n",
      "Epoch: 63290 | training loss: 5.2274e-04 | validation loss: 1.0241e-04\n",
      "Epoch: 63300 | training loss: 5.2262e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 63310 | training loss: 5.2256e-04 | validation loss: 1.0228e-04\n",
      "Epoch: 63320 | training loss: 5.2251e-04 | validation loss: 1.0224e-04\n",
      "Epoch: 63330 | training loss: 5.2248e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63340 | training loss: 5.2246e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63350 | training loss: 5.2244e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63360 | training loss: 5.2243e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63370 | training loss: 5.2241e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63380 | training loss: 5.2239e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63390 | training loss: 5.2238e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63400 | training loss: 5.2236e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63410 | training loss: 5.2235e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63420 | training loss: 5.2233e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63430 | training loss: 5.2232e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63440 | training loss: 5.2230e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63450 | training loss: 5.2228e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63460 | training loss: 5.2227e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63470 | training loss: 5.2225e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63480 | training loss: 5.2224e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 63490 | training loss: 5.2237e-04 | validation loss: 1.0179e-04\n",
      "Epoch: 63500 | training loss: 5.2248e-04 | validation loss: 1.0173e-04\n",
      "Epoch: 63510 | training loss: 5.2276e-04 | validation loss: 1.0166e-04\n",
      "Epoch: 63520 | training loss: 5.2244e-04 | validation loss: 1.0183e-04\n",
      "Epoch: 63530 | training loss: 5.2269e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 63540 | training loss: 5.2765e-04 | validation loss: 1.0643e-04\n",
      "Epoch: 63550 | training loss: 5.2294e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 63560 | training loss: 5.2243e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 63570 | training loss: 5.2220e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63580 | training loss: 5.2209e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63590 | training loss: 5.2206e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63600 | training loss: 5.2207e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63610 | training loss: 5.2203e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63620 | training loss: 5.2202e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 63630 | training loss: 5.2202e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63640 | training loss: 5.2219e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 63650 | training loss: 5.2636e-04 | validation loss: 1.0568e-04\n",
      "Epoch: 63660 | training loss: 5.2202e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63670 | training loss: 5.2231e-04 | validation loss: 1.0251e-04\n",
      "Epoch: 63680 | training loss: 5.2229e-04 | validation loss: 1.0236e-04\n",
      "Epoch: 63690 | training loss: 5.2208e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 63700 | training loss: 5.2196e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 63710 | training loss: 5.2189e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 63720 | training loss: 5.2186e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63730 | training loss: 5.2184e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63740 | training loss: 5.2182e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63750 | training loss: 5.2181e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63760 | training loss: 5.2179e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63770 | training loss: 5.2182e-04 | validation loss: 1.0222e-04\n",
      "Epoch: 63780 | training loss: 5.2322e-04 | validation loss: 1.0339e-04\n",
      "Epoch: 63790 | training loss: 5.2725e-04 | validation loss: 1.0648e-04\n",
      "Epoch: 63800 | training loss: 5.2182e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 63810 | training loss: 5.2227e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 63820 | training loss: 5.2201e-04 | validation loss: 1.0244e-04\n",
      "Epoch: 63830 | training loss: 5.2170e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63840 | training loss: 5.2166e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63850 | training loss: 5.2165e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63860 | training loss: 5.2163e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 63870 | training loss: 5.2162e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63880 | training loss: 5.2160e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63890 | training loss: 5.2158e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 63900 | training loss: 5.2157e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63910 | training loss: 5.2155e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63920 | training loss: 5.2154e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 63930 | training loss: 5.2153e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 63940 | training loss: 5.2179e-04 | validation loss: 1.0243e-04\n",
      "Epoch: 63950 | training loss: 5.3383e-04 | validation loss: 1.1163e-04\n",
      "Epoch: 63960 | training loss: 5.2635e-04 | validation loss: 1.0547e-04\n",
      "Epoch: 63970 | training loss: 5.2153e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 63980 | training loss: 5.2203e-04 | validation loss: 1.0269e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63990 | training loss: 5.2144e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 64000 | training loss: 5.2149e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 64010 | training loss: 5.2140e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 64020 | training loss: 5.2138e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 64030 | training loss: 5.2137e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 64040 | training loss: 5.2135e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 64050 | training loss: 5.2133e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64060 | training loss: 5.2132e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64070 | training loss: 5.2130e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64080 | training loss: 5.2128e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 64090 | training loss: 5.2128e-04 | validation loss: 1.0227e-04\n",
      "Epoch: 64100 | training loss: 5.2224e-04 | validation loss: 1.0401e-04\n",
      "Epoch: 64110 | training loss: 5.2203e-04 | validation loss: 1.0156e-04\n",
      "Epoch: 64120 | training loss: 5.2123e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 64130 | training loss: 5.2134e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 64140 | training loss: 5.2205e-04 | validation loss: 1.0310e-04\n",
      "Epoch: 64150 | training loss: 5.2908e-04 | validation loss: 1.0834e-04\n",
      "Epoch: 64160 | training loss: 5.2358e-04 | validation loss: 1.0365e-04\n",
      "Epoch: 64170 | training loss: 5.2156e-04 | validation loss: 1.0248e-04\n",
      "Epoch: 64180 | training loss: 5.2114e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 64190 | training loss: 5.2111e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 64200 | training loss: 5.2110e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64210 | training loss: 5.2108e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 64220 | training loss: 5.2107e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 64230 | training loss: 5.2105e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64240 | training loss: 5.2103e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64250 | training loss: 5.2102e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64260 | training loss: 5.2100e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64270 | training loss: 5.2101e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64280 | training loss: 5.2197e-04 | validation loss: 1.0274e-04\n",
      "Epoch: 64290 | training loss: 5.2995e-04 | validation loss: 1.0835e-04\n",
      "Epoch: 64300 | training loss: 5.2153e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 64310 | training loss: 5.2144e-04 | validation loss: 1.0259e-04\n",
      "Epoch: 64320 | training loss: 5.2126e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 64330 | training loss: 5.2090e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 64340 | training loss: 5.2090e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64350 | training loss: 5.2088e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64360 | training loss: 5.2085e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64370 | training loss: 5.2083e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64380 | training loss: 5.2082e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64390 | training loss: 5.2080e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64400 | training loss: 5.2078e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64410 | training loss: 5.2077e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64420 | training loss: 5.2075e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64430 | training loss: 5.2074e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 64440 | training loss: 5.2073e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64450 | training loss: 5.2119e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 64460 | training loss: 5.3507e-04 | validation loss: 1.1314e-04\n",
      "Epoch: 64470 | training loss: 5.2252e-04 | validation loss: 1.0332e-04\n",
      "Epoch: 64480 | training loss: 5.2175e-04 | validation loss: 1.0275e-04\n",
      "Epoch: 64490 | training loss: 5.2075e-04 | validation loss: 1.0225e-04\n",
      "Epoch: 64500 | training loss: 5.2080e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 64510 | training loss: 5.2064e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 64520 | training loss: 5.2061e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 64530 | training loss: 5.2059e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 64540 | training loss: 5.2057e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64550 | training loss: 5.2055e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64560 | training loss: 5.2054e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64570 | training loss: 5.2052e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64580 | training loss: 5.2051e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64590 | training loss: 5.2049e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64600 | training loss: 5.2047e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 64610 | training loss: 5.2050e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 64620 | training loss: 5.2282e-04 | validation loss: 1.0555e-04\n",
      "Epoch: 64630 | training loss: 5.2043e-04 | validation loss: 1.0220e-04\n",
      "Epoch: 64640 | training loss: 5.2053e-04 | validation loss: 1.0181e-04\n",
      "Epoch: 64650 | training loss: 5.2063e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 64660 | training loss: 5.2408e-04 | validation loss: 1.0496e-04\n",
      "Epoch: 64670 | training loss: 5.2040e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 64680 | training loss: 5.2066e-04 | validation loss: 1.0233e-04\n",
      "Epoch: 64690 | training loss: 5.2079e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 64700 | training loss: 5.2054e-04 | validation loss: 1.0231e-04\n",
      "Epoch: 64710 | training loss: 5.2038e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64720 | training loss: 5.2032e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64730 | training loss: 5.2029e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 64740 | training loss: 5.2026e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 64750 | training loss: 5.2024e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 64760 | training loss: 5.2023e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64770 | training loss: 5.2021e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64780 | training loss: 5.2020e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64790 | training loss: 5.2029e-04 | validation loss: 1.0214e-04\n",
      "Epoch: 64800 | training loss: 5.2408e-04 | validation loss: 1.0470e-04\n",
      "Epoch: 64810 | training loss: 5.2017e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64820 | training loss: 5.2159e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 64830 | training loss: 5.2065e-04 | validation loss: 1.0257e-04\n",
      "Epoch: 64840 | training loss: 5.2010e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 64850 | training loss: 5.2014e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 64860 | training loss: 5.2011e-04 | validation loss: 1.0215e-04\n",
      "Epoch: 64870 | training loss: 5.2007e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64880 | training loss: 5.2005e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 64890 | training loss: 5.2003e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64900 | training loss: 5.2001e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64910 | training loss: 5.2000e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64920 | training loss: 5.1998e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64930 | training loss: 5.1997e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64940 | training loss: 5.1995e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 64950 | training loss: 5.1994e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 64960 | training loss: 5.2037e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 64970 | training loss: 5.3358e-04 | validation loss: 1.1168e-04\n",
      "Epoch: 64980 | training loss: 5.2266e-04 | validation loss: 1.0431e-04\n",
      "Epoch: 64990 | training loss: 5.2043e-04 | validation loss: 1.0263e-04\n",
      "Epoch: 65000 | training loss: 5.2020e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 65010 | training loss: 5.1990e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65020 | training loss: 5.1990e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 65030 | training loss: 5.1981e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 65040 | training loss: 5.1980e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65050 | training loss: 5.1979e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 65060 | training loss: 5.1977e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 65070 | training loss: 5.1975e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 65080 | training loss: 5.1974e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 65090 | training loss: 5.1972e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 65100 | training loss: 5.1971e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 65110 | training loss: 5.1969e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 65120 | training loss: 5.1967e-04 | validation loss: 1.0209e-04\n",
      "Epoch: 65130 | training loss: 5.1966e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65140 | training loss: 5.1966e-04 | validation loss: 1.0196e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65150 | training loss: 5.2129e-04 | validation loss: 1.0151e-04\n",
      "Epoch: 65160 | training loss: 5.2192e-04 | validation loss: 1.0484e-04\n",
      "Epoch: 65170 | training loss: 5.2538e-04 | validation loss: 1.0708e-04\n",
      "Epoch: 65180 | training loss: 5.2019e-04 | validation loss: 1.0311e-04\n",
      "Epoch: 65190 | training loss: 5.1971e-04 | validation loss: 1.0239e-04\n",
      "Epoch: 65200 | training loss: 5.1980e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 65210 | training loss: 5.1965e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 65220 | training loss: 5.1956e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 65230 | training loss: 5.1952e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65240 | training loss: 5.1950e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65250 | training loss: 5.1948e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65260 | training loss: 5.1946e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65270 | training loss: 5.1945e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65280 | training loss: 5.1943e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65290 | training loss: 5.1942e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65300 | training loss: 5.1941e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65310 | training loss: 5.1988e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 65320 | training loss: 5.3259e-04 | validation loss: 1.1127e-04\n",
      "Epoch: 65330 | training loss: 5.2203e-04 | validation loss: 1.0422e-04\n",
      "Epoch: 65340 | training loss: 5.1978e-04 | validation loss: 1.0247e-04\n",
      "Epoch: 65350 | training loss: 5.1973e-04 | validation loss: 1.0229e-04\n",
      "Epoch: 65360 | training loss: 5.1933e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65370 | training loss: 5.1937e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 65380 | training loss: 5.1929e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65390 | training loss: 5.1927e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65400 | training loss: 5.1925e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65410 | training loss: 5.1924e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65420 | training loss: 5.1922e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65430 | training loss: 5.1921e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65440 | training loss: 5.1919e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65450 | training loss: 5.1918e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65460 | training loss: 5.1916e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65470 | training loss: 5.1915e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65480 | training loss: 5.1913e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65490 | training loss: 5.1912e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65500 | training loss: 5.1920e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 65510 | training loss: 5.2878e-04 | validation loss: 1.0959e-04\n",
      "Epoch: 65520 | training loss: 5.2680e-04 | validation loss: 1.0739e-04\n",
      "Epoch: 65530 | training loss: 5.1938e-04 | validation loss: 1.0218e-04\n",
      "Epoch: 65540 | training loss: 5.1925e-04 | validation loss: 1.0223e-04\n",
      "Epoch: 65550 | training loss: 5.1936e-04 | validation loss: 1.0238e-04\n",
      "Epoch: 65560 | training loss: 5.1907e-04 | validation loss: 1.0217e-04\n",
      "Epoch: 65570 | training loss: 5.1901e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65580 | training loss: 5.1900e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65590 | training loss: 5.1897e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65600 | training loss: 5.1896e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65610 | training loss: 5.1894e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65620 | training loss: 5.1892e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65630 | training loss: 5.1891e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65640 | training loss: 5.1889e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65650 | training loss: 5.1888e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65660 | training loss: 5.1886e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65670 | training loss: 5.1885e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65680 | training loss: 5.1883e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65690 | training loss: 5.1882e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65700 | training loss: 5.1880e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65710 | training loss: 5.1879e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 65720 | training loss: 5.1877e-04 | validation loss: 1.0207e-04\n",
      "Epoch: 65730 | training loss: 5.1876e-04 | validation loss: 1.0211e-04\n",
      "Epoch: 65740 | training loss: 5.1919e-04 | validation loss: 1.0303e-04\n",
      "Epoch: 65750 | training loss: 5.2695e-04 | validation loss: 1.0672e-04\n",
      "Epoch: 65760 | training loss: 5.2341e-04 | validation loss: 1.0520e-04\n",
      "Epoch: 65770 | training loss: 5.1949e-04 | validation loss: 1.0163e-04\n",
      "Epoch: 65780 | training loss: 5.1931e-04 | validation loss: 1.0267e-04\n",
      "Epoch: 65790 | training loss: 5.1872e-04 | validation loss: 1.0235e-04\n",
      "Epoch: 65800 | training loss: 5.1874e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 65810 | training loss: 5.1866e-04 | validation loss: 1.0196e-04\n",
      "Epoch: 65820 | training loss: 5.1863e-04 | validation loss: 1.0208e-04\n",
      "Epoch: 65830 | training loss: 5.1862e-04 | validation loss: 1.0210e-04\n",
      "Epoch: 65840 | training loss: 5.1860e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65850 | training loss: 5.1858e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 65860 | training loss: 5.1857e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 65870 | training loss: 5.1855e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65880 | training loss: 5.1854e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65890 | training loss: 5.1852e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65900 | training loss: 5.1851e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65910 | training loss: 5.1849e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65920 | training loss: 5.1848e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65930 | training loss: 5.1846e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 65940 | training loss: 5.1850e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 65950 | training loss: 5.2365e-04 | validation loss: 1.0622e-04\n",
      "Epoch: 65960 | training loss: 5.2148e-04 | validation loss: 1.0403e-04\n",
      "Epoch: 65970 | training loss: 5.1936e-04 | validation loss: 1.0286e-04\n",
      "Epoch: 65980 | training loss: 5.1946e-04 | validation loss: 1.0298e-04\n",
      "Epoch: 65990 | training loss: 5.1850e-04 | validation loss: 1.0219e-04\n",
      "Epoch: 66000 | training loss: 5.1839e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66010 | training loss: 5.1840e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 66020 | training loss: 5.1833e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66030 | training loss: 5.1832e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 66040 | training loss: 5.1830e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66050 | training loss: 5.1829e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66060 | training loss: 5.1828e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 66070 | training loss: 5.1826e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66080 | training loss: 5.1825e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66090 | training loss: 5.1823e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66100 | training loss: 5.1822e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66110 | training loss: 5.1820e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66120 | training loss: 5.1819e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66130 | training loss: 5.1817e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66140 | training loss: 5.1816e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66150 | training loss: 5.1814e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66160 | training loss: 5.1813e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66170 | training loss: 5.1812e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 66180 | training loss: 5.1891e-04 | validation loss: 1.0276e-04\n",
      "Epoch: 66190 | training loss: 5.3121e-04 | validation loss: 1.1213e-04\n",
      "Epoch: 66200 | training loss: 5.2240e-04 | validation loss: 1.0551e-04\n",
      "Epoch: 66210 | training loss: 5.1869e-04 | validation loss: 1.0262e-04\n",
      "Epoch: 66220 | training loss: 5.1807e-04 | validation loss: 1.0212e-04\n",
      "Epoch: 66230 | training loss: 5.1804e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 66240 | training loss: 5.1806e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 66250 | training loss: 5.1803e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66260 | training loss: 5.1799e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66270 | training loss: 5.1797e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66280 | training loss: 5.1796e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66290 | training loss: 5.1794e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66300 | training loss: 5.1793e-04 | validation loss: 1.0203e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66310 | training loss: 5.1791e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66320 | training loss: 5.1790e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66330 | training loss: 5.1788e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66340 | training loss: 5.1787e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66350 | training loss: 5.1785e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66360 | training loss: 5.1784e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66370 | training loss: 5.1782e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66380 | training loss: 5.1781e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66390 | training loss: 5.1779e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66400 | training loss: 5.1778e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66410 | training loss: 5.1776e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66420 | training loss: 5.1775e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66430 | training loss: 5.1773e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66440 | training loss: 5.1772e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66450 | training loss: 5.1783e-04 | validation loss: 1.0213e-04\n",
      "Epoch: 66460 | training loss: 5.3916e-04 | validation loss: 1.1819e-04\n",
      "Epoch: 66470 | training loss: 5.1892e-04 | validation loss: 1.0242e-04\n",
      "Epoch: 66480 | training loss: 5.1816e-04 | validation loss: 1.0216e-04\n",
      "Epoch: 66490 | training loss: 5.1773e-04 | validation loss: 1.0178e-04\n",
      "Epoch: 66500 | training loss: 5.1773e-04 | validation loss: 1.0171e-04\n",
      "Epoch: 66510 | training loss: 5.1770e-04 | validation loss: 1.0177e-04\n",
      "Epoch: 66520 | training loss: 5.1765e-04 | validation loss: 1.0185e-04\n",
      "Epoch: 66530 | training loss: 5.1761e-04 | validation loss: 1.0193e-04\n",
      "Epoch: 66540 | training loss: 5.1758e-04 | validation loss: 1.0197e-04\n",
      "Epoch: 66550 | training loss: 5.1756e-04 | validation loss: 1.0199e-04\n",
      "Epoch: 66560 | training loss: 5.1755e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 66570 | training loss: 5.1753e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66580 | training loss: 5.1752e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66590 | training loss: 5.1751e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66600 | training loss: 5.1749e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66610 | training loss: 5.1748e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66620 | training loss: 5.1746e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66630 | training loss: 5.1745e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66640 | training loss: 5.1743e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66650 | training loss: 5.1742e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66660 | training loss: 5.1741e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66670 | training loss: 5.1739e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66680 | training loss: 5.1738e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66690 | training loss: 5.1736e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66700 | training loss: 5.1735e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66710 | training loss: 5.1733e-04 | validation loss: 1.0203e-04\n",
      "Epoch: 66720 | training loss: 5.1732e-04 | validation loss: 1.0205e-04\n",
      "Epoch: 66730 | training loss: 5.1750e-04 | validation loss: 1.0253e-04\n",
      "Epoch: 66740 | training loss: 5.3569e-04 | validation loss: 1.1672e-04\n",
      "Epoch: 66750 | training loss: 5.1801e-04 | validation loss: 1.0246e-04\n",
      "Epoch: 66760 | training loss: 5.1932e-04 | validation loss: 1.0232e-04\n",
      "Epoch: 66770 | training loss: 5.1772e-04 | validation loss: 1.0221e-04\n",
      "Epoch: 66780 | training loss: 5.1730e-04 | validation loss: 1.0234e-04\n",
      "Epoch: 66790 | training loss: 5.1726e-04 | validation loss: 1.0206e-04\n",
      "Epoch: 66800 | training loss: 5.1723e-04 | validation loss: 1.0197e-04\n",
      "Epoch: 66810 | training loss: 5.1719e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66820 | training loss: 5.1718e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66830 | training loss: 5.1716e-04 | validation loss: 1.0204e-04\n",
      "Epoch: 66840 | training loss: 5.1715e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66850 | training loss: 5.1713e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66860 | training loss: 5.1712e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66870 | training loss: 5.1710e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66880 | training loss: 5.1709e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66890 | training loss: 5.1708e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66900 | training loss: 5.1706e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66910 | training loss: 5.1705e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 66920 | training loss: 5.1703e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66930 | training loss: 5.1702e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66940 | training loss: 5.1700e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66950 | training loss: 5.1699e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66960 | training loss: 5.1697e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 66970 | training loss: 5.1699e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 66980 | training loss: 5.2281e-04 | validation loss: 1.0582e-04\n",
      "Epoch: 66990 | training loss: 5.2468e-04 | validation loss: 1.0816e-04\n",
      "Epoch: 67000 | training loss: 5.1744e-04 | validation loss: 1.0249e-04\n",
      "Epoch: 67010 | training loss: 5.1692e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 67020 | training loss: 5.1690e-04 | validation loss: 1.0196e-04\n",
      "Epoch: 67030 | training loss: 5.1691e-04 | validation loss: 1.0199e-04\n",
      "Epoch: 67040 | training loss: 5.1691e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 67050 | training loss: 5.1687e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 67060 | training loss: 5.1684e-04 | validation loss: 1.0200e-04\n",
      "Epoch: 67070 | training loss: 5.1682e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 67080 | training loss: 5.1681e-04 | validation loss: 1.0202e-04\n",
      "Epoch: 67090 | training loss: 5.1679e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 67100 | training loss: 5.1678e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 67110 | training loss: 5.1676e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 67120 | training loss: 5.1675e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 67130 | training loss: 5.1674e-04 | validation loss: 1.0201e-04\n",
      "Epoch: 67140 | training loss: 5.1672e-04 | validation loss: 1.0201e-04\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(1, Nepochs):\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Compute the residual of the initial stress value based on the initial elastic strain value (hyperparameter)\n",
    "    ueps_e_0 = NICE_network.DeNormalize(NICE_network.e0, NICE_network.prm_ee)\n",
    "    stress0 = NICE_network.stress(ueps_e_0)\n",
    "\n",
    "    # Make predictions\n",
    "    pred_svars, pred_stress, pred_diss = NICE_network.integrate(dstrain_tv, ueps_e_0, t, np.hstack((ntrain, nval)))\n",
    "\n",
    "    # Compute training loss\n",
    "    training_loss_stress = MSE(NICE_network.Normalize(pred_stress[:, ntrain], prm_s),\n",
    "                               NICE_network.Normalize(stress_tv[:, ntrain], prm_s))\n",
    "    training_loss_r0 = MSE(NICE_network.Normalize(stress0, prm_s),\n",
    "                           NICE_network.Normalize(stress_tv[0], prm_s))\n",
    "    norm_d = torch.max(torch.abs(pred_diss)).detach()\n",
    "    training_loss_dissipation = MSE(NICE_network.relu(-pred_diss[:, ntrain]) / norm_d,\n",
    "                                    pred_diss[:, ntrain].detach() * 0)\n",
    "\n",
    "    # L2 regularization term\n",
    "    l_reg = torch.tensor(0., requires_grad=True)\n",
    "    for name, param in NICE_network.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            l_reg = l_reg + pow(param, 2).sum()\n",
    "\n",
    "    # Compute the overall training loss\n",
    "    training_loss = (torch.mean(training_loss_stress)\n",
    "                     + torch.mean(training_loss_r0)\n",
    "                     + torch.mean(training_loss_dissipation)\n",
    "                     + w_reg * l_reg\n",
    "                     )\n",
    "\n",
    "    # Backpropagate loss and perform optimizer step\n",
    "    training_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Learning rate scheduler step\n",
    "    if scheduler.get_last_lr()[0] > 1.e-4:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Compute validation loss\n",
    "    validation_loss_stress = MSE(NICE_network.Normalize(pred_stress[:, nval], prm_s),\n",
    "                                 NICE_network.Normalize(stress_tv[:, nval], prm_s))\n",
    "    validation_loss_dissipation = MSE(NICE_network.relu(-pred_diss[:, nval]) / norm_d,\n",
    "                                      pred_diss[:, nval].detach() * 0)\n",
    "    validation_loss = torch.mean(validation_loss_stress) + torch.mean(validation_loss_dissipation)\n",
    "\n",
    "    # Store loss values\n",
    "    training_loss_value = training_loss.item()\n",
    "    validation_loss_value = validation_loss.item()\n",
    "    training_loss_hist.append(training_loss_value)\n",
    "    validation_loss_value_hist.append(validation_loss_value)\n",
    "\n",
    "    # Print loss information\n",
    "    if not epoch % verbose_frequency:\n",
    "        print(f\"Epoch: {epoch}\"\n",
    "              + f\" | training loss: {training_loss_value:.4e}\"\n",
    "              + f\" | validation loss: {validation_loss_value:.4e}\")\n",
    "\n",
    "    # Check for early stopping criterion\n",
    "    early_stopping(validation_loss_value, NICE_network)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        NICE_network.load_state_dict(torch.load(checkpoint_path))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3297cf",
   "metadata": {},
   "source": [
    "#### 4.3 Training and validation set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf71b20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE stress:  tensor(0.0058, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Define time array for evaluation\n",
    "t = prm_dt * torch.linspace(0., data_size - 1, data_size).to(device)\n",
    "\n",
    "# Get the number of initial conditions\n",
    "number_IC = stress_tv.shape[1]\n",
    "\n",
    "# Find initial elastic strain using root finding\n",
    "initial_elastic_strain = root(NICE_network.find_elastic_strain,\n",
    "                              args=(stress_tv[0].reshape(-1, 2)),\n",
    "                              x0=np.zeros((24, 2)),\n",
    "                              tol=1e-12)\n",
    "\n",
    "# Convert the result to a torch tensor\n",
    "eps_e_0 = torch.from_numpy(initial_elastic_strain.x.reshape(-1, 2))\n",
    "\n",
    "# De-normalize the initial elastic strain\n",
    "ueps_e_0 = NICE_network.DeNormalize(eps_e_0, NICE_network.prm_ee)\n",
    "\n",
    "# Inference mode: make predictions\n",
    "pred_svars, pred_stress, pred_diss = NICE_network.integrate(dstrain_tv, ueps_e_0, t, np.hstack((ntrain, nval)))\n",
    "\n",
    "# Evaluate the Mean Absolute Error (MAE) for stress\n",
    "loss = torch.nn.L1Loss()\n",
    "MAE_stress = loss(NICE_network.Normalize(pred_stress, prm_s), NICE_network.Normalize(stress_tv[:, :, :dim], prm_s))\n",
    "\n",
    "# Print the MAE for stress\n",
    "print(\"MAE stress: \", MAE_stress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b18e759",
   "metadata": {},
   "source": [
    "#### 4.4 Test set evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b48e571c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE stress:  tensor(0.0048, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Get the number of initial conditions for the test set\n",
    "number_IC = stress_test.shape[1]\n",
    "\n",
    "# Define time array for evaluation\n",
    "t = prm_dt * torch.linspace(0., data_size - 1, data_size).to(device)\n",
    "\n",
    "# Initialize interpolation for the test set\n",
    "NICE_network.init_interp(dstrain_test, t)\n",
    "\n",
    "# Find initial elastic strain using root finding\n",
    "initial_elastic_strain = root(NICE_network.find_elastic_strain,\n",
    "                              args=(stress_test[0].reshape(-1, 2)),\n",
    "                              x0=np.zeros((number_IC, 2)),\n",
    "                              tol=1e-12)\n",
    "\n",
    "# Convert the result to a torch tensor\n",
    "eps_e_0 = torch.from_numpy(initial_elastic_strain.x.reshape(-1, 2))\n",
    "\n",
    "# De-normalize the initial elastic strain\n",
    "ueps_e_0 = NICE_network.DeNormalize(eps_e_0, NICE_network.prm_ee)\n",
    "\n",
    "# Create an array for the number of initial conditions in the test set\n",
    "Ntest = np.arange(0, dstrain_test.shape[1])\n",
    "\n",
    "# Inference mode: make predictions\n",
    "NICE_network.inference = True\n",
    "pred_svars, pred_stress, pred_diss = NICE_network.integrate(dstrain_test, ueps_e_0, t, Ntest)\n",
    "\n",
    "# Evaluate the Mean Absolute Error (MAE) for stress\n",
    "MAE_stress = loss(NICE_network.Normalize(pred_stress, prm_s), NICE_network.Normalize(stress_test[:, :, :dim], prm_s))\n",
    "\n",
    "# Print the MAE for stress\n",
    "print(\"MAE stress: \", MAE_stress)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7df4300",
   "metadata": {},
   "source": [
    "### 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5042e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the inference dataset\n",
    "file = './dataset/benchmark1_data_inference_DrainedTriaxial'\n",
    "# file = '../CModel/reference_data/DP_DT_rec6'#DP_CyDTp_recall'\n",
    "\n",
    "# Loading data from the specified file using pickle\n",
    "with open(file, 'rb') as f_obj:\n",
    "    data = pickle.load(f_obj)\n",
    "\n",
    "# Unpacking data into individual variables\n",
    "[stress_t, strain_t, svars_e_t, svars_p_t,\n",
    " stress_tdt, strain_tdt, svars_e_tdt, svars_p_tdt, _, _, dt, n_reset] = data\n",
    "\n",
    "# Setting batch_time and data_size based on the values from the inference dataset\n",
    "batch_time = n_reset\n",
    "data_size = n_reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d7d4382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the incremental stress, strain, and elastic state variables\n",
    "dstress = stress_tdt - stress_t\n",
    "dstrain = strain_tdt - strain_t\n",
    "dsvars_e = svars_e_tdt - svars_e_t\n",
    "\n",
    "# Scaling the incremental stress, strain, and elastic state variables by the time step\n",
    "dstress /= prm_dt\n",
    "dstrain /= prm_dt\n",
    "dsvars_e /= prm_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "271b82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping strain, incremental strain, elastic strain, and stress data arrays for better organization\n",
    "strain_t = np.reshape(strain_t, (batch_time, -1, dim), order='F')\n",
    "dstrain = np.reshape(dstrain, (batch_time, -1, dim), order='F')\n",
    "el_strain_t = np.reshape(svars_e_t, (batch_time, -1, dim), order='F')\n",
    "stress_t = np.reshape(stress_t, (batch_time, -1, dim), order='F')\n",
    "\n",
    "# Updating data_size based on the reshaped strain_t array\n",
    "data_size = strain_t.shape[0]\n",
    "\n",
    "# Calculating the number of initial conditions\n",
    "number_IC = strain_t.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ede6901e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set NICE network to inference mode\n",
    "NICE_network.inference = True\n",
    "\n",
    "# Create a time array for inference\n",
    "t = torch.arange(0, prm_dt * data_size, prm_dt)\n",
    "\n",
    "# Concatenate stress and elastic strain for input data\n",
    "y = torch.cat((torch.from_numpy(np.float64(stress_t)), torch.from_numpy(np.float64(el_strain_t))), -1).to(device)\n",
    "\n",
    "# Convert incremental strain and stress to torch tensors and move to the specified device\n",
    "arg = torch.from_numpy(np.float64(dstrain)).to(device)\n",
    "sigma = torch.from_numpy(np.float64(stress_t)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d56018f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize interpolation for incremental strain and time\n",
    "NICE_network.init_interp(arg, t)\n",
    "\n",
    "# Create an array of indices\n",
    "idx = np.arange(0, arg.shape[1])\n",
    "\n",
    "# Find initial elastic strain using root finding\n",
    "sol = root(NICE_network.find_elastic_strain, args=(sigma[0].reshape(-1, 2)),\n",
    "           x0=np.zeros((number_IC, dim)),\n",
    "           tol=1e-12)\n",
    "\n",
    "# Convert the result to a torch tensor\n",
    "eps_e_0 = torch.from_numpy(sol.x.reshape(-1, 2))\n",
    "\n",
    "# De-normalize the initial elastic strain\n",
    "ueps_e_0 = NICE_network.DeNormalize(eps_e_0, NICE_network.prm_ee)\n",
    "\n",
    "# Inference mode: make predictions\n",
    "pred_svars, pred_stress, pred_diss = NICE_network.integrate(arg[:], ueps_e_0, t[:], idx)\n",
    "\n",
    "# Convert predictions to NumPy arrays\n",
    "pred_svars = pred_svars.cpu().detach().numpy()\n",
    "pred_stress = pred_stress.cpu().detach().numpy()\n",
    "pred_diss = pred_diss.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f954c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure for the plot\n",
    "fig = plt.figure(dpi=100, figsize=(4, 3.), tight_layout=True)\n",
    "\n",
    "# Create a subplot\n",
    "ax = fig.subplots(1)\n",
    "\n",
    "# Plot reference stress points\n",
    "for i in np.arange(sigma.shape[1]):\n",
    "    ax.plot(y[:, i, 0].cpu().detach() / 1e+3, y[:, i, 1].cpu().detach() / 1e+3,\n",
    "            marker='o', markerfacecolor='white', linestyle='-',\n",
    "            color='black', alpha=0.2, linewidth=3, markersize=0, label='ref')\n",
    "\n",
    "# Plot predicted stress points\n",
    "for i in np.arange(pred_stress.shape[1]):\n",
    "    ax.plot(pred_stress[:, i, 0] / 1e+3, pred_stress[:, i, 1] / 1e+3, alpha=1, linewidth=2, color=colorb,\n",
    "            markersize=0, markeredgewidth=0.0, marker='.')\n",
    "\n",
    "# Set labels and grid\n",
    "ax.set_ylabel('$q$ (MPa)')\n",
    "ax.set_xlabel('$p$ (MPa)')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb836cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure for the plot\n",
    "fig = plt.figure(dpi=100, figsize=(4, 3.), tight_layout=True)\n",
    "\n",
    "# Create a subplot\n",
    "ax = fig.subplots(1)\n",
    "\n",
    "# Plot reference stress points against strain\n",
    "for i in np.arange(sigma.shape[1]):\n",
    "    ax.plot(strain_t[:, i, 1] * 1e+5, y[:, i, 1].cpu().detach() / 1e+3,\n",
    "            marker='o', markerfacecolor='white', linestyle='-',\n",
    "            color='black', alpha=0.2, linewidth=3, markersize=0, label='ref')\n",
    "\n",
    "# Plot predicted stress points against strain\n",
    "for i in np.arange(pred_stress.shape[1]):\n",
    "    ax.plot(strain_t[:, i, 1] * 1e+5, pred_stress[:, i, 1] / 1e+3, alpha=1, linewidth=2, color=colorb,\n",
    "            markersize=0, markeredgewidth=0.0, marker='.')\n",
    "\n",
    "# Set labels and grid\n",
    "ax.set_ylabel('$q$ (MPa)')\n",
    "ax.set_xlabel('$\\\\varepsilon_s$ (%)')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bff2da79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a figure for the plot\n",
    "fig = plt.figure(dpi=100, figsize=(4, 3.), tight_layout=True)\n",
    "\n",
    "# Create a subplot\n",
    "ax = fig.subplots(1)\n",
    "\n",
    "# Plot reference stress points against volumetric strain\n",
    "for i in np.arange(sigma.shape[1]):\n",
    "    ax.plot(strain_t[:, i, 0] * 1e+5, y[:, i, 0].cpu().detach() / 1e+3,\n",
    "            marker='o', markerfacecolor='white', linestyle='-',\n",
    "            color='black', alpha=0.2, linewidth=3, markersize=0, label='ref')\n",
    "\n",
    "# Plot predicted stress points against volumetric strain\n",
    "for i in np.arange(pred_stress.shape[1]):\n",
    "    ax.plot(strain_t[:, i, 0] * 1e+5, pred_stress[:, i, 0] / 1e+3, alpha=1, linewidth=2, color=colorb,\n",
    "            markersize=0, markeredgewidth=0.0, marker='.')\n",
    "\n",
    "# Set labels and grid\n",
    "ax.set_ylabel('$p$ (MPa)')\n",
    "ax.set_xlabel('$\\\\varepsilon_v$ (%)')\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8b43b5",
   "metadata": {},
   "source": [
    "### 6. Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "160eac1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for saving the NICE network state dictionary\n",
    "PATH = './saved/[state]NICE_benchmark1'\n",
    "\n",
    "# Save the state dictionary of the NICE network\n",
    "torch.save(NICE_network.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2bc4dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path for saving the normalization parameters\n",
    "params_path = './saved/[params]NICE_benchmark1'\n",
    "\n",
    "# Save the normalization parameters using pickle\n",
    "with open(params_path, 'wb') as f_obj:\n",
    "    pickle.dump(norm_params, f_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a460ccd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
